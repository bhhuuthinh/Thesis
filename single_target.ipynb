{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Prepare</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ijcai2016_taobao_1.csv', sep=r',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>sel_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>cat_ID</th>\n",
       "      <th>act_ID</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>647747</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183647</td>\n",
       "      <td>9525</td>\n",
       "      <td>578730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    use_ID  sel_ID   ite_ID  cat_ID  act_ID      time\n",
       "0  1980536    9666  1450952       1       0  20150826\n",
       "1  1980536    9666  1450952       1       0  20150826\n",
       "2   647747    9666  1450952       1       0  20150915\n",
       "3  1980536    9666  1450952       1       0  20150823\n",
       "4   183647    9525   578730       1       0  20150711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>sel_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>cat_ID</th>\n",
       "      <th>act_ID</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1024665.8052680527</td>\n",
       "      <td>4550.214902149021</td>\n",
       "      <td>1203661.2412924129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1009310093100931</td>\n",
       "      <td>20150830.19217192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>596919.0583544845</td>\n",
       "      <td>2805.703221327739</td>\n",
       "      <td>688457.0158119791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3012388556068006</td>\n",
       "      <td>116.58427140128536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>505223.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>594459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1023194.0</td>\n",
       "      <td>4562.0</td>\n",
       "      <td>1250255.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1542806.0</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>1784092.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2063567.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>2353171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20151130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   use_ID             sel_ID              ite_ID   cat_ID  \\\n",
       "count             99999.0            99999.0             99999.0  99999.0   \n",
       "mean   1024665.8052680527  4550.214902149021  1203661.2412924129      1.0   \n",
       "std     596919.0583544845  2805.703221327739   688457.0158119791      0.0   \n",
       "min                  13.0               60.0              2017.0      1.0   \n",
       "25%              505223.0             2258.0            594459.0      1.0   \n",
       "50%             1023194.0             4562.0           1250255.0      1.0   \n",
       "75%             1542806.0             6792.0           1784092.0      1.0   \n",
       "max             2063567.0             9995.0           2353171.0      1.0   \n",
       "\n",
       "                   act_ID                time  \n",
       "count             99999.0             99999.0  \n",
       "mean   0.1009310093100931   20150830.19217192  \n",
       "std    0.3012388556068006  116.58427140128536  \n",
       "min                   0.0          20150701.0  \n",
       "25%                   0.0          20150720.0  \n",
       "50%                   0.0          20150813.0  \n",
       "75%                   0.0          20150916.0  \n",
       "max                   1.0          20151130.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().apply(lambda s: s.apply('{0}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_click = df[['use_ID', 'ite_ID', 'act_ID']].loc[df['act_ID'] == 0]\n",
    "data_click = data_click.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy = df[['use_ID', 'ite_ID', 'act_ID']].loc[df['act_ID'] == 1]\n",
    "data_buy = data_buy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>click</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980536</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>647747</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183647</td>\n",
       "      <td>578730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723956</td>\n",
       "      <td>28301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1781938</td>\n",
       "      <td>28301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    use_ID   ite_ID  click  buy\n",
       "0  1980536  1450952      1  0.0\n",
       "1   647747  1450952      1  0.0\n",
       "2   183647   578730      1  0.0\n",
       "3   723956    28301      1  0.0\n",
       "4  1781938    28301      1  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge = pd.merge(data_click, data_buy, left_on=['use_ID','ite_ID'], right_on=['use_ID','ite_ID'], how = 'left')\n",
    "data_merge.columns = ['use_ID', 'ite_ID', 'click', 'buy']\n",
    "data_merge['click'] = data_merge['click'].replace(0, 1)\n",
    "data_merge['buy'] = data_merge['buy'].fillna(0)\n",
    "\n",
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66802, 3), (8391, 3), (66802, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_click.shape , data_buy.shape, data_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64808, 4), (1994, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.loc[data_merge['buy'] == 0].shape, data_merge.loc[data_merge['buy'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data splitting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_merge.iloc[:, 0:-2].values\n",
    "# y = data_merge.iloc[:,2:4].values\n",
    "y = data_merge.iloc[:,3:4].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40080, 2) (13361, 2) (13361, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40080, 1) (13361, 1) (13361, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2353172, 2353172)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = 2353171+1\n",
    "num_items = 2353171+1\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Config</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "\n",
    "layers = [30,20]\n",
    "reg_layers=[0, 0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 10e-4\n",
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), \n",
    "    input_length=None)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', \n",
    "    embeddings_regularizer = l2(reg_layers[0]), \n",
    "    input_length=None)\n",
    "\n",
    "user_embedding = Embedding_User(inputs[:,0])\n",
    "item_embedding = Embedding_Item(inputs[:,1])\n",
    "\n",
    "user_latent = Flatten(name = 'user_latent')(user_embedding)\n",
    "item_latent = Flatten(name = 'item_latent')(item_embedding)\n",
    "\n",
    "vector = tf.keras.layers.Multiply()([user_latent, item_latent])\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'click_prediction')(vector)\n",
    "\n",
    "outputs = click_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None,)]            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_latent (Flatten)           (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "item_latent (Flatten)           (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64)           0           user_latent[0][0]                \n",
      "                                                                 item_latent[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            65          multiply[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 301,206,081\n",
      "Trainable params: 301,206,081\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model2 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model2.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6852 - accuracy: 0.9668 - mse: 0.2460 - val_loss: 0.6808 - val_accuracy: 0.9711 - val_mse: 0.2438\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6780 - accuracy: 0.9701 - mse: 0.2424 - val_loss: 0.6754 - val_accuracy: 0.9711 - val_mse: 0.2411\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6733 - accuracy: 0.9701 - mse: 0.2401 - val_loss: 0.6713 - val_accuracy: 0.9711 - val_mse: 0.2391\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6696 - accuracy: 0.9701 - mse: 0.2382 - val_loss: 0.6679 - val_accuracy: 0.9711 - val_mse: 0.2374\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6664 - accuracy: 0.9701 - mse: 0.2366 - val_loss: 0.6648 - val_accuracy: 0.9711 - val_mse: 0.2358\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6635 - accuracy: 0.9701 - mse: 0.2352 - val_loss: 0.6621 - val_accuracy: 0.9711 - val_mse: 0.2345\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6609 - accuracy: 0.9701 - mse: 0.2339 - val_loss: 0.6596 - val_accuracy: 0.9711 - val_mse: 0.2332\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.9701 - mse: 0.2327 - val_loss: 0.6573 - val_accuracy: 0.9711 - val_mse: 0.2321\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6563 - accuracy: 0.9701 - mse: 0.2316 - val_loss: 0.6552 - val_accuracy: 0.9711 - val_mse: 0.2310\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6542 - accuracy: 0.9701 - mse: 0.2305 - val_loss: 0.6531 - val_accuracy: 0.9711 - val_mse: 0.2300\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6522 - accuracy: 0.9701 - mse: 0.2296 - val_loss: 0.6512 - val_accuracy: 0.9711 - val_mse: 0.2290\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.9701 - mse: 0.2286 - val_loss: 0.6493 - val_accuracy: 0.9711 - val_mse: 0.2281\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6486 - accuracy: 0.9701 - mse: 0.2277 - val_loss: 0.6476 - val_accuracy: 0.9711 - val_mse: 0.2272\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6468 - accuracy: 0.9701 - mse: 0.2269 - val_loss: 0.6459 - val_accuracy: 0.9711 - val_mse: 0.2264\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6452 - accuracy: 0.9701 - mse: 0.2260 - val_loss: 0.6443 - val_accuracy: 0.9711 - val_mse: 0.2256\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6436 - accuracy: 0.9701 - mse: 0.2252 - val_loss: 0.6427 - val_accuracy: 0.9711 - val_mse: 0.2248\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6421 - accuracy: 0.9701 - mse: 0.2245 - val_loss: 0.6412 - val_accuracy: 0.9711 - val_mse: 0.2241\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6406 - accuracy: 0.9701 - mse: 0.2237 - val_loss: 0.6397 - val_accuracy: 0.9711 - val_mse: 0.2233\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6391 - accuracy: 0.9701 - mse: 0.2230 - val_loss: 0.6383 - val_accuracy: 0.9711 - val_mse: 0.2226\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6377 - accuracy: 0.9701 - mse: 0.2223 - val_loss: 0.6369 - val_accuracy: 0.9711 - val_mse: 0.2219\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.9701 - mse: 0.2217 - val_loss: 0.6356 - val_accuracy: 0.9711 - val_mse: 0.2213\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.9701 - mse: 0.2210 - val_loss: 0.6343 - val_accuracy: 0.9711 - val_mse: 0.2206\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6338 - accuracy: 0.9701 - mse: 0.2203 - val_loss: 0.6330 - val_accuracy: 0.9711 - val_mse: 0.2200\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.9701 - mse: 0.2197 - val_loss: 0.6317 - val_accuracy: 0.9711 - val_mse: 0.2193\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.9701 - mse: 0.2191 - val_loss: 0.6305 - val_accuracy: 0.9711 - val_mse: 0.2187\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6301 - accuracy: 0.9701 - mse: 0.2185 - val_loss: 0.6293 - val_accuracy: 0.9711 - val_mse: 0.2181\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.9701 - mse: 0.2179 - val_loss: 0.6282 - val_accuracy: 0.9711 - val_mse: 0.2176\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6277 - accuracy: 0.9701 - mse: 0.2174 - val_loss: 0.6270 - val_accuracy: 0.9711 - val_mse: 0.2170\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.9701 - mse: 0.2168 - val_loss: 0.6259 - val_accuracy: 0.9711 - val_mse: 0.2164\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6255 - accuracy: 0.9701 - mse: 0.2162 - val_loss: 0.6248 - val_accuracy: 0.9711 - val_mse: 0.2159\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6244 - accuracy: 0.9701 - mse: 0.2157 - val_loss: 0.6237 - val_accuracy: 0.9711 - val_mse: 0.2154\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6233 - accuracy: 0.9701 - mse: 0.2152 - val_loss: 0.6227 - val_accuracy: 0.9711 - val_mse: 0.2148\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6223 - accuracy: 0.9701 - mse: 0.2146 - val_loss: 0.6216 - val_accuracy: 0.9711 - val_mse: 0.2143\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6213 - accuracy: 0.9701 - mse: 0.2141 - val_loss: 0.6206 - val_accuracy: 0.9711 - val_mse: 0.2138\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6203 - accuracy: 0.9701 - mse: 0.2136 - val_loss: 0.6196 - val_accuracy: 0.9711 - val_mse: 0.2133\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6193 - accuracy: 0.9701 - mse: 0.2131 - val_loss: 0.6186 - val_accuracy: 0.9711 - val_mse: 0.2128\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.9701 - mse: 0.2126 - val_loss: 0.6176 - val_accuracy: 0.9711 - val_mse: 0.2123\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6173 - accuracy: 0.9701 - mse: 0.2122 - val_loss: 0.6167 - val_accuracy: 0.9711 - val_mse: 0.2118\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.9701 - mse: 0.2117 - val_loss: 0.6157 - val_accuracy: 0.9711 - val_mse: 0.2114\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6154 - accuracy: 0.9701 - mse: 0.2112 - val_loss: 0.6148 - val_accuracy: 0.9711 - val_mse: 0.2109\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6145 - accuracy: 0.9701 - mse: 0.2108 - val_loss: 0.6139 - val_accuracy: 0.9711 - val_mse: 0.2105\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6136 - accuracy: 0.9701 - mse: 0.2103 - val_loss: 0.6130 - val_accuracy: 0.9711 - val_mse: 0.2100\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6127 - accuracy: 0.9701 - mse: 0.2099 - val_loss: 0.6121 - val_accuracy: 0.9711 - val_mse: 0.2096\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6118 - accuracy: 0.9701 - mse: 0.2094 - val_loss: 0.6112 - val_accuracy: 0.9711 - val_mse: 0.2091\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6109 - accuracy: 0.9701 - mse: 0.2090 - val_loss: 0.6103 - val_accuracy: 0.9711 - val_mse: 0.2087\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6101 - accuracy: 0.9701 - mse: 0.2086 - val_loss: 0.6094 - val_accuracy: 0.9711 - val_mse: 0.2083\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6092 - accuracy: 0.9701 - mse: 0.2081 - val_loss: 0.6086 - val_accuracy: 0.9711 - val_mse: 0.2078\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6084 - accuracy: 0.9701 - mse: 0.2077 - val_loss: 0.6078 - val_accuracy: 0.9711 - val_mse: 0.2074\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6075 - accuracy: 0.9701 - mse: 0.2073 - val_loss: 0.6069 - val_accuracy: 0.9711 - val_mse: 0.2070\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6067 - accuracy: 0.9701 - mse: 0.2069 - val_loss: 0.6061 - val_accuracy: 0.9711 - val_mse: 0.2066\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6059 - accuracy: 0.9701 - mse: 0.2065 - val_loss: 0.6053 - val_accuracy: 0.9711 - val_mse: 0.2062\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6051 - accuracy: 0.9701 - mse: 0.2061 - val_loss: 0.6045 - val_accuracy: 0.9711 - val_mse: 0.2058\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6043 - accuracy: 0.9701 - mse: 0.2057 - val_loss: 0.6037 - val_accuracy: 0.9711 - val_mse: 0.2054\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6035 - accuracy: 0.9701 - mse: 0.2053 - val_loss: 0.6029 - val_accuracy: 0.9711 - val_mse: 0.2050\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6027 - accuracy: 0.9701 - mse: 0.2049 - val_loss: 0.6021 - val_accuracy: 0.9711 - val_mse: 0.2047\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6020 - accuracy: 0.9701 - mse: 0.2046 - val_loss: 0.6014 - val_accuracy: 0.9711 - val_mse: 0.2043\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6012 - accuracy: 0.9701 - mse: 0.2042 - val_loss: 0.6006 - val_accuracy: 0.9711 - val_mse: 0.2039\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6004 - accuracy: 0.9701 - mse: 0.2038 - val_loss: 0.5999 - val_accuracy: 0.9711 - val_mse: 0.2035\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5997 - accuracy: 0.9701 - mse: 0.2034 - val_loss: 0.5991 - val_accuracy: 0.9711 - val_mse: 0.2032\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5990 - accuracy: 0.9701 - mse: 0.2031 - val_loss: 0.5984 - val_accuracy: 0.9711 - val_mse: 0.2028\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5982 - accuracy: 0.9701 - mse: 0.2027 - val_loss: 0.5977 - val_accuracy: 0.9711 - val_mse: 0.2024\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5975 - accuracy: 0.9701 - mse: 0.2024 - val_loss: 0.5969 - val_accuracy: 0.9711 - val_mse: 0.2021\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5968 - accuracy: 0.9701 - mse: 0.2020 - val_loss: 0.5962 - val_accuracy: 0.9711 - val_mse: 0.2017\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5961 - accuracy: 0.9701 - mse: 0.2017 - val_loss: 0.5955 - val_accuracy: 0.9711 - val_mse: 0.2014\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.9701 - mse: 0.2013 - val_loss: 0.5948 - val_accuracy: 0.9711 - val_mse: 0.2010\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.9701 - mse: 0.2010 - val_loss: 0.5941 - val_accuracy: 0.9711 - val_mse: 0.2007\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.9701 - mse: 0.2006 - val_loss: 0.5934 - val_accuracy: 0.9711 - val_mse: 0.2003\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5933 - accuracy: 0.9701 - mse: 0.2003 - val_loss: 0.5927 - val_accuracy: 0.9711 - val_mse: 0.2000\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.9701 - mse: 0.1999 - val_loss: 0.5921 - val_accuracy: 0.9711 - val_mse: 0.1997\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.9701 - mse: 0.1996 - val_loss: 0.5914 - val_accuracy: 0.9711 - val_mse: 0.1993\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.9701 - mse: 0.1993 - val_loss: 0.5907 - val_accuracy: 0.9711 - val_mse: 0.1990\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.9701 - mse: 0.1990 - val_loss: 0.5901 - val_accuracy: 0.9711 - val_mse: 0.1987\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5900 - accuracy: 0.9701 - mse: 0.1986 - val_loss: 0.5894 - val_accuracy: 0.9711 - val_mse: 0.1984\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5893 - accuracy: 0.9701 - mse: 0.1983 - val_loss: 0.5887 - val_accuracy: 0.9711 - val_mse: 0.1980\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5887 - accuracy: 0.9701 - mse: 0.1980 - val_loss: 0.5881 - val_accuracy: 0.9711 - val_mse: 0.1977\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5880 - accuracy: 0.9701 - mse: 0.1977 - val_loss: 0.5875 - val_accuracy: 0.9711 - val_mse: 0.1974\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5874 - accuracy: 0.9701 - mse: 0.1974 - val_loss: 0.5868 - val_accuracy: 0.9711 - val_mse: 0.1971\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.9701 - mse: 0.1970 - val_loss: 0.5862 - val_accuracy: 0.9711 - val_mse: 0.1968\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5861 - accuracy: 0.9701 - mse: 0.1967 - val_loss: 0.5856 - val_accuracy: 0.9711 - val_mse: 0.1965\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5855 - accuracy: 0.9701 - mse: 0.1964 - val_loss: 0.5849 - val_accuracy: 0.9711 - val_mse: 0.1962\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5849 - accuracy: 0.9701 - mse: 0.1961 - val_loss: 0.5843 - val_accuracy: 0.9711 - val_mse: 0.1959\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5843 - accuracy: 0.9701 - mse: 0.1958 - val_loss: 0.5837 - val_accuracy: 0.9711 - val_mse: 0.1956\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5837 - accuracy: 0.9701 - mse: 0.1955 - val_loss: 0.5831 - val_accuracy: 0.9711 - val_mse: 0.1953\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5831 - accuracy: 0.9701 - mse: 0.1952 - val_loss: 0.5825 - val_accuracy: 0.9711 - val_mse: 0.1950\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5825 - accuracy: 0.9701 - mse: 0.1949 - val_loss: 0.5819 - val_accuracy: 0.9711 - val_mse: 0.1947\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5819 - accuracy: 0.9701 - mse: 0.1946 - val_loss: 0.5813 - val_accuracy: 0.9711 - val_mse: 0.1944\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.9701 - mse: 0.1944 - val_loss: 0.5807 - val_accuracy: 0.9711 - val_mse: 0.1941\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5807 - accuracy: 0.9701 - mse: 0.1941 - val_loss: 0.5801 - val_accuracy: 0.9711 - val_mse: 0.1938\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.9701 - mse: 0.1938 - val_loss: 0.5796 - val_accuracy: 0.9711 - val_mse: 0.1935\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5795 - accuracy: 0.9701 - mse: 0.1935 - val_loss: 0.5790 - val_accuracy: 0.9711 - val_mse: 0.1932\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5789 - accuracy: 0.9701 - mse: 0.1932 - val_loss: 0.5784 - val_accuracy: 0.9711 - val_mse: 0.1929\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5784 - accuracy: 0.9701 - mse: 0.1929 - val_loss: 0.5778 - val_accuracy: 0.9711 - val_mse: 0.1927\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5778 - accuracy: 0.9701 - mse: 0.1926 - val_loss: 0.5773 - val_accuracy: 0.9711 - val_mse: 0.1924\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5772 - accuracy: 0.9701 - mse: 0.1924 - val_loss: 0.5767 - val_accuracy: 0.9711 - val_mse: 0.1921\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5767 - accuracy: 0.9701 - mse: 0.1921 - val_loss: 0.5761 - val_accuracy: 0.9711 - val_mse: 0.1918\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5761 - accuracy: 0.9701 - mse: 0.1918 - val_loss: 0.5756 - val_accuracy: 0.9711 - val_mse: 0.1916\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5756 - accuracy: 0.9701 - mse: 0.1916 - val_loss: 0.5750 - val_accuracy: 0.9711 - val_mse: 0.1913\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5750 - accuracy: 0.9701 - mse: 0.1913 - val_loss: 0.5745 - val_accuracy: 0.9711 - val_mse: 0.1910\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5745 - accuracy: 0.9701 - mse: 0.1910 - val_loss: 0.5739 - val_accuracy: 0.9711 - val_mse: 0.1907\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5739 - accuracy: 0.9701 - mse: 0.1907 - val_loss: 0.5734 - val_accuracy: 0.9711 - val_mse: 0.1905\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train,\n",
    "                      validation_data = (x_val, y_val),\n",
    "                      batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent, item_latent], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, kernel_initializer='lecun_uniform', name = 'click_prediction')(vector)\n",
    "\n",
    "outputs = click_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 128)]        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 30)           3870        tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 20)           620         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            21          layer_1_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 301,210,527\n",
      "Trainable params: 301,210,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model3 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model3.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\"])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6756 - accuracy: 0.9088 - mse: 0.2412 - val_loss: 0.6614 - val_accuracy: 0.9711 - val_mse: 0.2341\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6502 - accuracy: 0.9701 - mse: 0.2286 - val_loss: 0.6394 - val_accuracy: 0.9711 - val_mse: 0.2232\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6294 - accuracy: 0.9701 - mse: 0.2182 - val_loss: 0.6194 - val_accuracy: 0.9711 - val_mse: 0.2132\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6099 - accuracy: 0.9701 - mse: 0.2085 - val_loss: 0.6003 - val_accuracy: 0.9711 - val_mse: 0.2037\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5912 - accuracy: 0.9701 - mse: 0.1992 - val_loss: 0.5817 - val_accuracy: 0.9711 - val_mse: 0.1946\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5729 - accuracy: 0.9701 - mse: 0.1902 - val_loss: 0.5635 - val_accuracy: 0.9711 - val_mse: 0.1857\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.9701 - mse: 0.1814 - val_loss: 0.5456 - val_accuracy: 0.9711 - val_mse: 0.1769\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5371 - accuracy: 0.9701 - mse: 0.1728 - val_loss: 0.5279 - val_accuracy: 0.9711 - val_mse: 0.1684\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.9701 - mse: 0.1644 - val_loss: 0.5104 - val_accuracy: 0.9711 - val_mse: 0.1600\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.9701 - mse: 0.1561 - val_loss: 0.4930 - val_accuracy: 0.9711 - val_mse: 0.1518\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.9701 - mse: 0.1480 - val_loss: 0.4759 - val_accuracy: 0.9711 - val_mse: 0.1437\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4680 - accuracy: 0.9701 - mse: 0.1401 - val_loss: 0.4590 - val_accuracy: 0.9711 - val_mse: 0.1359\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.9701 - mse: 0.1324 - val_loss: 0.4423 - val_accuracy: 0.9711 - val_mse: 0.1283\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.9701 - mse: 0.1249 - val_loss: 0.4260 - val_accuracy: 0.9711 - val_mse: 0.1210\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.9701 - mse: 0.1178 - val_loss: 0.4100 - val_accuracy: 0.9711 - val_mse: 0.1140\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.9701 - mse: 0.1109 - val_loss: 0.3945 - val_accuracy: 0.9711 - val_mse: 0.1072\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3876 - accuracy: 0.9701 - mse: 0.1044 - val_loss: 0.3794 - val_accuracy: 0.9711 - val_mse: 0.1009\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3729 - accuracy: 0.9701 - mse: 0.0982 - val_loss: 0.3648 - val_accuracy: 0.9711 - val_mse: 0.0948\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.9701 - mse: 0.0924 - val_loss: 0.3508 - val_accuracy: 0.9711 - val_mse: 0.0891\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.9701 - mse: 0.0869 - val_loss: 0.3373 - val_accuracy: 0.9711 - val_mse: 0.0838\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.9701 - mse: 0.0818 - val_loss: 0.3244 - val_accuracy: 0.9711 - val_mse: 0.0789\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.9701 - mse: 0.0770 - val_loss: 0.3122 - val_accuracy: 0.9711 - val_mse: 0.0743\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.9701 - mse: 0.0727 - val_loss: 0.3005 - val_accuracy: 0.9711 - val_mse: 0.0701\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9701 - mse: 0.0686 - val_loss: 0.2895 - val_accuracy: 0.9711 - val_mse: 0.0662\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2854 - accuracy: 0.9701 - mse: 0.0649 - val_loss: 0.2791 - val_accuracy: 0.9711 - val_mse: 0.0626\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.9701 - mse: 0.0615 - val_loss: 0.2693 - val_accuracy: 0.9711 - val_mse: 0.0594\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.9701 - mse: 0.0584 - val_loss: 0.2601 - val_accuracy: 0.9711 - val_mse: 0.0564\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.9701 - mse: 0.0556 - val_loss: 0.2515 - val_accuracy: 0.9711 - val_mse: 0.0537\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.9701 - mse: 0.0531 - val_loss: 0.2434 - val_accuracy: 0.9711 - val_mse: 0.0513\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2409 - accuracy: 0.9701 - mse: 0.0508 - val_loss: 0.2358 - val_accuracy: 0.9711 - val_mse: 0.0491\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2337 - accuracy: 0.9701 - mse: 0.0487 - val_loss: 0.2287 - val_accuracy: 0.9711 - val_mse: 0.0471\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2269 - accuracy: 0.9701 - mse: 0.0468 - val_loss: 0.2221 - val_accuracy: 0.9711 - val_mse: 0.0453\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2205 - accuracy: 0.9701 - mse: 0.0451 - val_loss: 0.2160 - val_accuracy: 0.9711 - val_mse: 0.0437\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2146 - accuracy: 0.9701 - mse: 0.0436 - val_loss: 0.2103 - val_accuracy: 0.9711 - val_mse: 0.0422\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9701 - mse: 0.0422 - val_loss: 0.2049 - val_accuracy: 0.9711 - val_mse: 0.0409\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2041 - accuracy: 0.9701 - mse: 0.0409 - val_loss: 0.2000 - val_accuracy: 0.9711 - val_mse: 0.0397\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1993 - accuracy: 0.9701 - mse: 0.0398 - val_loss: 0.1954 - val_accuracy: 0.9711 - val_mse: 0.0386\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9701 - mse: 0.0388 - val_loss: 0.1911 - val_accuracy: 0.9711 - val_mse: 0.0376\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1908 - accuracy: 0.9701 - mse: 0.0379 - val_loss: 0.1871 - val_accuracy: 0.9711 - val_mse: 0.0368\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.9701 - mse: 0.0371 - val_loss: 0.1834 - val_accuracy: 0.9711 - val_mse: 0.0360\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1834 - accuracy: 0.9701 - mse: 0.0363 - val_loss: 0.1799 - val_accuracy: 0.9711 - val_mse: 0.0353\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9701 - mse: 0.0357 - val_loss: 0.1767 - val_accuracy: 0.9711 - val_mse: 0.0346\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9701 - mse: 0.0351 - val_loss: 0.1737 - val_accuracy: 0.9711 - val_mse: 0.0341\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9701 - mse: 0.0345 - val_loss: 0.1709 - val_accuracy: 0.9711 - val_mse: 0.0335\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1716 - accuracy: 0.9701 - mse: 0.0341 - val_loss: 0.1684 - val_accuracy: 0.9711 - val_mse: 0.0331\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9701 - mse: 0.0336 - val_loss: 0.1660 - val_accuracy: 0.9711 - val_mse: 0.0326\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9701 - mse: 0.0332 - val_loss: 0.1637 - val_accuracy: 0.9711 - val_mse: 0.0323\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1647 - accuracy: 0.9701 - mse: 0.0329 - val_loss: 0.1616 - val_accuracy: 0.9711 - val_mse: 0.0319\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9701 - mse: 0.0325 - val_loss: 0.1597 - val_accuracy: 0.9711 - val_mse: 0.0316\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9701 - mse: 0.0322 - val_loss: 0.1579 - val_accuracy: 0.9711 - val_mse: 0.0313\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9701 - mse: 0.0320 - val_loss: 0.1562 - val_accuracy: 0.9711 - val_mse: 0.0310\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9701 - mse: 0.0317 - val_loss: 0.1546 - val_accuracy: 0.9711 - val_mse: 0.0308\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9701 - mse: 0.0315 - val_loss: 0.1532 - val_accuracy: 0.9711 - val_mse: 0.0306\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1546 - accuracy: 0.9701 - mse: 0.0313 - val_loss: 0.1518 - val_accuracy: 0.9711 - val_mse: 0.0304\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9701 - mse: 0.0311 - val_loss: 0.1505 - val_accuracy: 0.9711 - val_mse: 0.0302\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9701 - mse: 0.0309 - val_loss: 0.1493 - val_accuracy: 0.9711 - val_mse: 0.0300\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9701 - mse: 0.0308 - val_loss: 0.1482 - val_accuracy: 0.9711 - val_mse: 0.0299\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9701 - mse: 0.0306 - val_loss: 0.1472 - val_accuracy: 0.9711 - val_mse: 0.0298\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1489 - accuracy: 0.9701 - mse: 0.0305 - val_loss: 0.1462 - val_accuracy: 0.9711 - val_mse: 0.0296\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1480 - accuracy: 0.9701 - mse: 0.0304 - val_loss: 0.1453 - val_accuracy: 0.9711 - val_mse: 0.0295\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1472 - accuracy: 0.9701 - mse: 0.0303 - val_loss: 0.1444 - val_accuracy: 0.9711 - val_mse: 0.0294\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1463 - accuracy: 0.9701 - mse: 0.0302 - val_loss: 0.1436 - val_accuracy: 0.9711 - val_mse: 0.0293\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1456 - accuracy: 0.9701 - mse: 0.0301 - val_loss: 0.1429 - val_accuracy: 0.9711 - val_mse: 0.0292\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9701 - mse: 0.0300 - val_loss: 0.1422 - val_accuracy: 0.9711 - val_mse: 0.0291\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1442 - accuracy: 0.9701 - mse: 0.0299 - val_loss: 0.1415 - val_accuracy: 0.9711 - val_mse: 0.0291\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9701 - mse: 0.0299 - val_loss: 0.1409 - val_accuracy: 0.9711 - val_mse: 0.0290\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9701 - mse: 0.0298 - val_loss: 0.1403 - val_accuracy: 0.9711 - val_mse: 0.0289\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1398 - val_accuracy: 0.9711 - val_mse: 0.0289\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1419 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1393 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1388 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1410 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1384 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1379 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1375 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1371 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1394 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1368 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1365 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1361 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1385 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1358 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1382 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1356 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1379 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1353 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1350 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1348 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1346 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1344 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1342 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1340 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1338 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1336 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1361 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1335 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1333 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1358 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1332 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1330 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1329 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1328 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1326 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1325 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1324 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1323 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1348 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1322 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1321 - val_accuracy: 0.9711 - val_mse: 0.0281\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train, y_train, \n",
    "                      validation_data = (x_val, y_val),\n",
    "                      batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = (int)(64/3)\n",
    "\n",
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "Embedding_User2 = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding2',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent[:,j:64], item_latent[:,j:64]], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "vector_gmf = tf.keras.layers.Multiply()([user_latent[:,0:j], user_latent[:,0:j]])\n",
    "\n",
    "concat_layer = tf.concat([vector, vector_gmf], -1)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'click_prediction')(concat_layer)\n",
    "outputs = click_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           item_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 43)]         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None, 43)]         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 86)]         0           tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 30)           2610        tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 21)]         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 21)]         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 20)           620         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 21)           0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 41)]         0           layer_1_1[0][0]                  \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            42          tf_op_layer_concat_2[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 301,209,288\n",
      "Trainable params: 301,209,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model4 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model4.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\"])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.9371 - mse: 0.2404 - val_loss: 0.6602 - val_accuracy: 0.9711 - val_mse: 0.2335\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6495 - accuracy: 0.9701 - mse: 0.2282 - val_loss: 0.6386 - val_accuracy: 0.9711 - val_mse: 0.2228\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.9701 - mse: 0.2178 - val_loss: 0.6182 - val_accuracy: 0.9711 - val_mse: 0.2126\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6086 - accuracy: 0.9701 - mse: 0.2079 - val_loss: 0.5984 - val_accuracy: 0.9711 - val_mse: 0.2028\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.9701 - mse: 0.1982 - val_loss: 0.5789 - val_accuracy: 0.9711 - val_mse: 0.1932\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5697 - accuracy: 0.9701 - mse: 0.1887 - val_loss: 0.5597 - val_accuracy: 0.9711 - val_mse: 0.1838\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5507 - accuracy: 0.9701 - mse: 0.1794 - val_loss: 0.5408 - val_accuracy: 0.9711 - val_mse: 0.1746\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5319 - accuracy: 0.9701 - mse: 0.1703 - val_loss: 0.5220 - val_accuracy: 0.9711 - val_mse: 0.1655\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.9701 - mse: 0.1614 - val_loss: 0.5035 - val_accuracy: 0.9711 - val_mse: 0.1567\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4949 - accuracy: 0.9701 - mse: 0.1527 - val_loss: 0.4852 - val_accuracy: 0.9711 - val_mse: 0.1481\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4769 - accuracy: 0.9701 - mse: 0.1442 - val_loss: 0.4672 - val_accuracy: 0.9711 - val_mse: 0.1397\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.9701 - mse: 0.1360 - val_loss: 0.4496 - val_accuracy: 0.9711 - val_mse: 0.1316\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4417 - accuracy: 0.9701 - mse: 0.1280 - val_loss: 0.4323 - val_accuracy: 0.9711 - val_mse: 0.1238\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4246 - accuracy: 0.9701 - mse: 0.1204 - val_loss: 0.4154 - val_accuracy: 0.9711 - val_mse: 0.1163\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.9701 - mse: 0.1131 - val_loss: 0.3990 - val_accuracy: 0.9711 - val_mse: 0.1092\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3920 - accuracy: 0.9701 - mse: 0.1062 - val_loss: 0.3831 - val_accuracy: 0.9711 - val_mse: 0.1024\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.9701 - mse: 0.0997 - val_loss: 0.3678 - val_accuracy: 0.9711 - val_mse: 0.0961\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.9701 - mse: 0.0935 - val_loss: 0.3531 - val_accuracy: 0.9711 - val_mse: 0.0901\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.9701 - mse: 0.0878 - val_loss: 0.3390 - val_accuracy: 0.9711 - val_mse: 0.0845\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.9701 - mse: 0.0824 - val_loss: 0.3256 - val_accuracy: 0.9711 - val_mse: 0.0793\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.9701 - mse: 0.0774 - val_loss: 0.3128 - val_accuracy: 0.9711 - val_mse: 0.0745\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3079 - accuracy: 0.9701 - mse: 0.0729 - val_loss: 0.3007 - val_accuracy: 0.9711 - val_mse: 0.0701\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.9701 - mse: 0.0687 - val_loss: 0.2892 - val_accuracy: 0.9711 - val_mse: 0.0661\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9701 - mse: 0.0648 - val_loss: 0.2784 - val_accuracy: 0.9711 - val_mse: 0.0624\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.9701 - mse: 0.0613 - val_loss: 0.2682 - val_accuracy: 0.9711 - val_mse: 0.0590\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.9701 - mse: 0.0581 - val_loss: 0.2587 - val_accuracy: 0.9711 - val_mse: 0.0560\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.9701 - mse: 0.0552 - val_loss: 0.2498 - val_accuracy: 0.9711 - val_mse: 0.0532\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2471 - accuracy: 0.9701 - mse: 0.0526 - val_loss: 0.2414 - val_accuracy: 0.9711 - val_mse: 0.0507\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.9701 - mse: 0.0502 - val_loss: 0.2336 - val_accuracy: 0.9711 - val_mse: 0.0485\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.9701 - mse: 0.0481 - val_loss: 0.2263 - val_accuracy: 0.9711 - val_mse: 0.0464\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2247 - accuracy: 0.9701 - mse: 0.0462 - val_loss: 0.2196 - val_accuracy: 0.9711 - val_mse: 0.0446\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9701 - mse: 0.0445 - val_loss: 0.2133 - val_accuracy: 0.9711 - val_mse: 0.0430\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2121 - accuracy: 0.9701 - mse: 0.0429 - val_loss: 0.2074 - val_accuracy: 0.9711 - val_mse: 0.0415\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2065 - accuracy: 0.9701 - mse: 0.0415 - val_loss: 0.2020 - val_accuracy: 0.9711 - val_mse: 0.0402\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9701 - mse: 0.0403 - val_loss: 0.1969 - val_accuracy: 0.9711 - val_mse: 0.0390\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9701 - mse: 0.0392 - val_loss: 0.1922 - val_accuracy: 0.9711 - val_mse: 0.0379\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1920 - accuracy: 0.9701 - mse: 0.0382 - val_loss: 0.1879 - val_accuracy: 0.9711 - val_mse: 0.0369\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1879 - accuracy: 0.9701 - mse: 0.0373 - val_loss: 0.1838 - val_accuracy: 0.9711 - val_mse: 0.0361\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1841 - accuracy: 0.9701 - mse: 0.0365 - val_loss: 0.1801 - val_accuracy: 0.9711 - val_mse: 0.0353\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9701 - mse: 0.0358 - val_loss: 0.1766 - val_accuracy: 0.9711 - val_mse: 0.0346\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.9701 - mse: 0.0351 - val_loss: 0.1734 - val_accuracy: 0.9711 - val_mse: 0.0340\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1741 - accuracy: 0.9701 - mse: 0.0345 - val_loss: 0.1705 - val_accuracy: 0.9711 - val_mse: 0.0335\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9701 - mse: 0.0340 - val_loss: 0.1677 - val_accuracy: 0.9711 - val_mse: 0.0330\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.9701 - mse: 0.0335 - val_loss: 0.1652 - val_accuracy: 0.9711 - val_mse: 0.0325\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9701 - mse: 0.0331 - val_loss: 0.1628 - val_accuracy: 0.9711 - val_mse: 0.0321\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9701 - mse: 0.0327 - val_loss: 0.1606 - val_accuracy: 0.9711 - val_mse: 0.0317\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9701 - mse: 0.0324 - val_loss: 0.1585 - val_accuracy: 0.9711 - val_mse: 0.0314\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9701 - mse: 0.0321 - val_loss: 0.1566 - val_accuracy: 0.9711 - val_mse: 0.0311\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9701 - mse: 0.0318 - val_loss: 0.1549 - val_accuracy: 0.9711 - val_mse: 0.0308\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9701 - mse: 0.0316 - val_loss: 0.1533 - val_accuracy: 0.9711 - val_mse: 0.0306\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1550 - accuracy: 0.9701 - mse: 0.0313 - val_loss: 0.1517 - val_accuracy: 0.9711 - val_mse: 0.0304\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9701 - mse: 0.0311 - val_loss: 0.1503 - val_accuracy: 0.9711 - val_mse: 0.0302\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9701 - mse: 0.0309 - val_loss: 0.1490 - val_accuracy: 0.9711 - val_mse: 0.0300\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9701 - mse: 0.0308 - val_loss: 0.1478 - val_accuracy: 0.9711 - val_mse: 0.0298\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9701 - mse: 0.0306 - val_loss: 0.1467 - val_accuracy: 0.9711 - val_mse: 0.0297\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9701 - mse: 0.0305 - val_loss: 0.1456 - val_accuracy: 0.9711 - val_mse: 0.0296\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9701 - mse: 0.0304 - val_loss: 0.1446 - val_accuracy: 0.9711 - val_mse: 0.0294\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9701 - mse: 0.0302 - val_loss: 0.1437 - val_accuracy: 0.9711 - val_mse: 0.0293\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9701 - mse: 0.0301 - val_loss: 0.1429 - val_accuracy: 0.9711 - val_mse: 0.0292\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9701 - mse: 0.0300 - val_loss: 0.1421 - val_accuracy: 0.9711 - val_mse: 0.0291\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1444 - accuracy: 0.9701 - mse: 0.0300 - val_loss: 0.1413 - val_accuracy: 0.9711 - val_mse: 0.0290\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9701 - mse: 0.0299 - val_loss: 0.1406 - val_accuracy: 0.9711 - val_mse: 0.0290\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9701 - mse: 0.0298 - val_loss: 0.1400 - val_accuracy: 0.9711 - val_mse: 0.0289\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1394 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1419 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1388 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1383 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1408 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1378 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1404 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1373 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1399 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1369 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1365 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1391 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1361 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1358 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1354 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1351 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1378 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1348 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1375 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1345 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1343 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1340 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1338 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1336 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1334 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1332 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1360 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1330 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1358 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1328 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1357 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1327 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1325 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1324 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1322 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1321 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1320 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1348 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1319 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1318 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1316 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1315 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1344 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1314 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1343 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1314 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1342 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1313 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1312 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1311 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1340 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1310 - val_accuracy: 0.9711 - val_mse: 0.0281\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train, y_train,\n",
    "                      validation_data = (x_val, y_val),\n",
    "                      batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>My Method</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "Embedding_User2 = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding2',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1, trainable=True)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent, item_latent], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "vector_gmf = tf.keras.layers.Multiply()([user_latent, user_latent])\n",
    "\n",
    "concat_layer = tf.concat([vector, vector_gmf], -1)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'click_prediction')(concat_layer)\n",
    "outputs = click_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None,)]            0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None,)]            0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           item_embedding[2][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 128)]        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 30)           3870        tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 20)           620         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 64)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 84)]         0           layer_1_1[0][0]                  \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            85          tf_op_layer_concat_4[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 301,210,591\n",
      "Trainable params: 301,210,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model5 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model5.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\"])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6753 - accuracy: 0.9654 - mse: 0.2411 - val_loss: 0.6643 - val_accuracy: 0.9711 - val_mse: 0.2356\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6548 - accuracy: 0.9701 - mse: 0.2308 - val_loss: 0.6450 - val_accuracy: 0.9711 - val_mse: 0.2260\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6359 - accuracy: 0.9701 - mse: 0.2214 - val_loss: 0.6262 - val_accuracy: 0.9711 - val_mse: 0.2166\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.6172 - accuracy: 0.9701 - mse: 0.2121 - val_loss: 0.6076 - val_accuracy: 0.9711 - val_mse: 0.2073\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5986 - accuracy: 0.9701 - mse: 0.2029 - val_loss: 0.5890 - val_accuracy: 0.9711 - val_mse: 0.1982\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.9701 - mse: 0.1938 - val_loss: 0.5705 - val_accuracy: 0.9711 - val_mse: 0.1891\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5617 - accuracy: 0.9701 - mse: 0.1847 - val_loss: 0.5520 - val_accuracy: 0.9711 - val_mse: 0.1800\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5433 - accuracy: 0.9701 - mse: 0.1758 - val_loss: 0.5336 - val_accuracy: 0.9711 - val_mse: 0.1711\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.9701 - mse: 0.1669 - val_loss: 0.5152 - val_accuracy: 0.9711 - val_mse: 0.1623\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.9701 - mse: 0.1581 - val_loss: 0.4968 - val_accuracy: 0.9711 - val_mse: 0.1535\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.9701 - mse: 0.1495 - val_loss: 0.4785 - val_accuracy: 0.9711 - val_mse: 0.1449\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.9701 - mse: 0.1410 - val_loss: 0.4604 - val_accuracy: 0.9711 - val_mse: 0.1365\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4521 - accuracy: 0.9701 - mse: 0.1328 - val_loss: 0.4425 - val_accuracy: 0.9711 - val_mse: 0.1284\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.9701 - mse: 0.1248 - val_loss: 0.4249 - val_accuracy: 0.9711 - val_mse: 0.1205\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.9701 - mse: 0.1171 - val_loss: 0.4078 - val_accuracy: 0.9711 - val_mse: 0.1130\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.9701 - mse: 0.1098 - val_loss: 0.3912 - val_accuracy: 0.9711 - val_mse: 0.1058\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3839 - accuracy: 0.9701 - mse: 0.1028 - val_loss: 0.3751 - val_accuracy: 0.9711 - val_mse: 0.0990\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.9701 - mse: 0.0963 - val_loss: 0.3596 - val_accuracy: 0.9711 - val_mse: 0.0927\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.9701 - mse: 0.0901 - val_loss: 0.3447 - val_accuracy: 0.9711 - val_mse: 0.0867\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.9701 - mse: 0.0844 - val_loss: 0.3306 - val_accuracy: 0.9711 - val_mse: 0.0812\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.9701 - mse: 0.0791 - val_loss: 0.3171 - val_accuracy: 0.9711 - val_mse: 0.0761\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.9701 - mse: 0.0743 - val_loss: 0.3043 - val_accuracy: 0.9711 - val_mse: 0.0714\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9701 - mse: 0.0698 - val_loss: 0.2923 - val_accuracy: 0.9711 - val_mse: 0.0672\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9701 - mse: 0.0657 - val_loss: 0.2810 - val_accuracy: 0.9711 - val_mse: 0.0633\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9701 - mse: 0.0620 - val_loss: 0.2703 - val_accuracy: 0.9711 - val_mse: 0.0597\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2667 - accuracy: 0.9701 - mse: 0.0587 - val_loss: 0.2604 - val_accuracy: 0.9711 - val_mse: 0.0565\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9701 - mse: 0.0556 - val_loss: 0.2511 - val_accuracy: 0.9711 - val_mse: 0.0536\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2481 - accuracy: 0.9701 - mse: 0.0529 - val_loss: 0.2424 - val_accuracy: 0.9711 - val_mse: 0.0510\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.9701 - mse: 0.0504 - val_loss: 0.2343 - val_accuracy: 0.9711 - val_mse: 0.0486\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2321 - accuracy: 0.9701 - mse: 0.0482 - val_loss: 0.2268 - val_accuracy: 0.9711 - val_mse: 0.0465\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.2248 - accuracy: 0.9701 - mse: 0.0462 - val_loss: 0.2198 - val_accuracy: 0.9711 - val_mse: 0.0446\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9701 - mse: 0.0445 - val_loss: 0.2133 - val_accuracy: 0.9711 - val_mse: 0.0430\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.2120 - accuracy: 0.9701 - mse: 0.0429 - val_loss: 0.2073 - val_accuracy: 0.9711 - val_mse: 0.0414\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9701 - mse: 0.0414 - val_loss: 0.2017 - val_accuracy: 0.9711 - val_mse: 0.0401\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9701 - mse: 0.0402 - val_loss: 0.1966 - val_accuracy: 0.9711 - val_mse: 0.0389\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.9701 - mse: 0.0390 - val_loss: 0.1918 - val_accuracy: 0.9711 - val_mse: 0.0378\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9701 - mse: 0.0380 - val_loss: 0.1874 - val_accuracy: 0.9711 - val_mse: 0.0368\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1872 - accuracy: 0.9701 - mse: 0.0371 - val_loss: 0.1833 - val_accuracy: 0.9711 - val_mse: 0.0360\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9701 - mse: 0.0363 - val_loss: 0.1795 - val_accuracy: 0.9711 - val_mse: 0.0352\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9701 - mse: 0.0356 - val_loss: 0.1760 - val_accuracy: 0.9711 - val_mse: 0.0345\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1764 - accuracy: 0.9701 - mse: 0.0349 - val_loss: 0.1728 - val_accuracy: 0.9711 - val_mse: 0.0339\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9701 - mse: 0.0344 - val_loss: 0.1698 - val_accuracy: 0.9711 - val_mse: 0.0333\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9701 - mse: 0.0338 - val_loss: 0.1670 - val_accuracy: 0.9711 - val_mse: 0.0328\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9701 - mse: 0.0334 - val_loss: 0.1645 - val_accuracy: 0.9711 - val_mse: 0.0324\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9701 - mse: 0.0330 - val_loss: 0.1621 - val_accuracy: 0.9711 - val_mse: 0.0320\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9701 - mse: 0.0326 - val_loss: 0.1599 - val_accuracy: 0.9711 - val_mse: 0.0316\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1610 - accuracy: 0.9701 - mse: 0.0323 - val_loss: 0.1579 - val_accuracy: 0.9711 - val_mse: 0.0313\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9701 - mse: 0.0319 - val_loss: 0.1560 - val_accuracy: 0.9711 - val_mse: 0.0310\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9701 - mse: 0.0317 - val_loss: 0.1542 - val_accuracy: 0.9711 - val_mse: 0.0307\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9701 - mse: 0.0314 - val_loss: 0.1526 - val_accuracy: 0.9711 - val_mse: 0.0305\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1541 - accuracy: 0.9701 - mse: 0.0312 - val_loss: 0.1511 - val_accuracy: 0.9711 - val_mse: 0.0303\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9701 - mse: 0.0310 - val_loss: 0.1497 - val_accuracy: 0.9711 - val_mse: 0.0301\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9701 - mse: 0.0308 - val_loss: 0.1484 - val_accuracy: 0.9711 - val_mse: 0.0299\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9701 - mse: 0.0307 - val_loss: 0.1472 - val_accuracy: 0.9711 - val_mse: 0.0298\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9701 - mse: 0.0305 - val_loss: 0.1461 - val_accuracy: 0.9711 - val_mse: 0.0296\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1480 - accuracy: 0.9701 - mse: 0.0304 - val_loss: 0.1451 - val_accuracy: 0.9711 - val_mse: 0.0295\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1470 - accuracy: 0.9701 - mse: 0.0303 - val_loss: 0.1441 - val_accuracy: 0.9711 - val_mse: 0.0294\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9701 - mse: 0.0301 - val_loss: 0.1432 - val_accuracy: 0.9711 - val_mse: 0.0293\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9701 - mse: 0.0300 - val_loss: 0.1424 - val_accuracy: 0.9711 - val_mse: 0.0292\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9701 - mse: 0.0300 - val_loss: 0.1416 - val_accuracy: 0.9711 - val_mse: 0.0291\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9701 - mse: 0.0299 - val_loss: 0.1409 - val_accuracy: 0.9711 - val_mse: 0.0290\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9701 - mse: 0.0298 - val_loss: 0.1402 - val_accuracy: 0.9711 - val_mse: 0.0289\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1395 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9701 - mse: 0.0297 - val_loss: 0.1390 - val_accuracy: 0.9711 - val_mse: 0.0288\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1384 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9701 - mse: 0.0296 - val_loss: 0.1379 - val_accuracy: 0.9711 - val_mse: 0.0287\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1374 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9701 - mse: 0.0295 - val_loss: 0.1370 - val_accuracy: 0.9711 - val_mse: 0.0286\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1394 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1366 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9701 - mse: 0.0294 - val_loss: 0.1362 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1358 - val_accuracy: 0.9711 - val_mse: 0.0285\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1382 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1354 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1379 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1351 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9701 - mse: 0.0293 - val_loss: 0.1348 - val_accuracy: 0.9711 - val_mse: 0.0284\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1345 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1343 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1368 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1340 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9701 - mse: 0.0292 - val_loss: 0.1338 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1336 - val_accuracy: 0.9711 - val_mse: 0.0283\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1361 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1334 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1332 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1358 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1330 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1328 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1354 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1326 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9701 - mse: 0.0291 - val_loss: 0.1325 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1323 - val_accuracy: 0.9711 - val_mse: 0.0282\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1322 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1348 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1321 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1319 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1318 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1317 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1344 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1316 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1343 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1315 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1342 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1314 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1313 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1340 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1312 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1312 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9701 - mse: 0.0290 - val_loss: 0.1311 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1338 - accuracy: 0.9701 - mse: 0.0289 - val_loss: 0.1310 - val_accuracy: 0.9711 - val_mse: 0.0281\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 1s 3ms/step - loss: 0.1337 - accuracy: 0.9701 - mse: 0.0289 - val_loss: 0.1309 - val_accuracy: 0.9711 - val_mse: 0.0281\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(x_train, y_train,\n",
    "                      validation_data = (x_val, y_val),\n",
    "                      batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history2.history['mse'],'-.')\n",
    "plt.plot(history3.history['mse'],'-+')\n",
    "plt.plot(history4.history['mse'],'-')\n",
    "plt.plot(history5.history['mse'],'-')\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.grid()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['GMF', 'MLP', 'NeuMF', 'My'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "# plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history2.history['val_mse'],'-.')\n",
    "plt.plot(history3.history['val_mse'],'-+')\n",
    "plt.plot(history4.history['val_mse'],'-')\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.title('Taobao Dataset')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['GMF', 'MLP', 'NeuMF'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = ['GMF', 'MLP', 'NeuMF']\n",
    "\n",
    "energy = [\n",
    "    65\n",
    "    , 2801\n",
    "    , 1982\n",
    "]\n",
    "\n",
    "# Plot the bar graph\n",
    "plot = plt.bar(labels, energy, color='green')\n",
    "\n",
    "# Add the data value on head of the bar\n",
    "for value in plot:\n",
    "    height = value.get_height()\n",
    "    plt.text(value.get_x()+value.get_width()/2.,1.002*height,'%d'%int(height),ha='center',va='bottom')\n",
    "plt.xlabel(\"Method\")\n",
    "plt.ylabel(\"MSE\")\n",
    "# Display the graph on the screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.9693 - mse: 0.1907\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9693 - mse: 0.0298\n",
      "418/418 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9693 - mse: 0.0297\n"
     ]
    }
   ],
   "source": [
    "test1 = model2.evaluate(x_test, y_test)\n",
    "test2 = model3.evaluate(x_test, y_test)\n",
    "test3 = model4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19072198867797852 0.029772626236081123 0.029742861166596413\n"
     ]
    }
   ],
   "source": [
    "print(test1[2], test2[2], test3[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19048172235488892, 0.028142251074314117, 0.02806362695991993]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = [\n",
    "#     history.history['root_mean_squared_error'][99]\n",
    "    history2.history['val_mse'][99]\n",
    "    , history3.history['val_mse'][99]\n",
    "    , history4.history['val_mse'][99]\n",
    "]\n",
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data_merge['ite_ID'].unique())\n",
    "u = np.full((n, ), 1)\n",
    "i = np.arange(n)\n",
    "testsss = np.stack((u, i), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5461, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.predict(testsss).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03157367"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(model3.predict(testsss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
