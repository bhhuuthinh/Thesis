{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
<<<<<<< HEAD
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
=======
    "import tensorflow as tf"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset\\\\ijcai2016_taobao_1.csv', sep=r',', engine='python')"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ijcai2016_taobao_1.csv', sep=r',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>sel_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>cat_ID</th>\n",
       "      <th>act_ID</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>647747</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980536</td>\n",
       "      <td>9666</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183647</td>\n",
       "      <td>9525</td>\n",
       "      <td>578730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20150711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    use_ID  sel_ID   ite_ID  cat_ID  act_ID      time\n",
       "0  1980536    9666  1450952       1       0  20150826\n",
       "1  1980536    9666  1450952       1       0  20150826\n",
       "2   647747    9666  1450952       1       0  20150915\n",
       "3  1980536    9666  1450952       1       0  20150823\n",
       "4   183647    9525   578730       1       0  20150711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>sel_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>cat_ID</th>\n",
       "      <th>act_ID</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1024665.8052680527</td>\n",
       "      <td>4550.214902149021</td>\n",
       "      <td>1203661.2412924129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1009310093100931</td>\n",
       "      <td>20150830.19217192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>596919.0583544845</td>\n",
       "      <td>2805.703221327739</td>\n",
       "      <td>688457.0158119791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3012388556068006</td>\n",
       "      <td>116.58427140128536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>505223.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>594459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1023194.0</td>\n",
       "      <td>4562.0</td>\n",
       "      <td>1250255.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1542806.0</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>1784092.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2063567.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>2353171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20151130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   use_ID             sel_ID              ite_ID   cat_ID  \\\n",
       "count             99999.0            99999.0             99999.0  99999.0   \n",
       "mean   1024665.8052680527  4550.214902149021  1203661.2412924129      1.0   \n",
       "std     596919.0583544845  2805.703221327739   688457.0158119791      0.0   \n",
       "min                  13.0               60.0              2017.0      1.0   \n",
       "25%              505223.0             2258.0            594459.0      1.0   \n",
       "50%             1023194.0             4562.0           1250255.0      1.0   \n",
       "75%             1542806.0             6792.0           1784092.0      1.0   \n",
       "max             2063567.0             9995.0           2353171.0      1.0   \n",
       "\n",
       "                   act_ID                time  \n",
       "count             99999.0             99999.0  \n",
       "mean   0.1009310093100931   20150830.19217192  \n",
       "std    0.3012388556068006  116.58427140128536  \n",
       "min                   0.0          20150701.0  \n",
       "25%                   0.0          20150720.0  \n",
       "50%                   0.0          20150813.0  \n",
       "75%                   0.0          20150916.0  \n",
       "max                   1.0          20151130.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().apply(lambda s: s.apply('{0}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   "metadata": {},
   "outputs": [],
   "source": [
    "data_click = df[['use_ID', 'ite_ID', 'act_ID']].loc[df['act_ID'] == 0]\n",
    "data_click = data_click.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_buy = df[['use_ID', 'ite_ID', 'act_ID']].loc[df['act_ID'] == 1]\n",
    "data_buy = data_buy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_ID</th>\n",
       "      <th>ite_ID</th>\n",
       "      <th>click</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980536</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>647747</td>\n",
       "      <td>1450952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183647</td>\n",
       "      <td>578730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>723956</td>\n",
       "      <td>28301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1781938</td>\n",
       "      <td>28301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    use_ID   ite_ID  click  buy\n",
       "0  1980536  1450952      1  0.0\n",
       "1   647747  1450952      1  0.0\n",
       "2   183647   578730      1  0.0\n",
       "3   723956    28301      1  0.0\n",
       "4  1781938    28301      1  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge = pd.merge(data_click, data_buy, left_on=['use_ID','ite_ID'], right_on=['use_ID','ite_ID'], how = 'left')\n",
    "data_merge.columns = ['use_ID', 'ite_ID', 'click', 'buy']\n",
    "data_merge['click'] = data_merge['click'].replace(0, 1)\n",
    "data_merge['buy'] = data_merge['buy'].fillna(0)\n",
    "\n",
    "data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66802, 3), (8391, 3), (66802, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_click.shape , data_buy.shape, data_merge.shape"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user = df.use_ID.unique()\n",
    "list_item = df.ite_ID.unique()\n",
    "count_user = len(list_user)\n",
    "count_item = len(list_item)\n",
    "count_user, count_item"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64808, 4), (1994, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merge.loc[data_merge['buy'] == 0].shape, data_merge.loc[data_merge['buy'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_merge.iloc[:, 0:-2].values\n",
    "y = data_merge.iloc[:,2:4].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a6d60450fa61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_click\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_click\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_click\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(data_click)) < 0.8\n",
    "train = data_click[msk]\n",
    "test = data_click[~msk]"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40080, 2) (13361, 2) (13361, 2)\n"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b7cc2e67d346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(x_train.shape, x_test.shape, x_val.shape)"
=======
    "train.shape, test.shape"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2353172, 2353172)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = 2353171+1\n",
    "num_items = 2353171+1\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call back"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-34b0f4ba511e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = train.iloc[:, 0:-1]\n",
    "y_train = train.iloc[:,2]\n",
    "\n",
    "x_test = test.iloc[:, 0:-1]\n",
    "y_test = test.iloc[:,2]"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "\n",
    "layers = [20,10]\n",
    "reg_layers=[0,0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 10e-4\n",
    "\n",
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent, item_latent], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, kernel_initializer='lecun_uniform', name = 'click_prediction')(vector)\n",
    "\n",
    "vector2 = tf.concat([user_latent, item_latent], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_2_%d' %idx)\n",
    "    vector2 = layer(vector2)\n",
    "\n",
    "cascading = vector2 + click_prediction\n",
    "\n",
    "buy_prediction = Dense(1, activation='sigmoid',use_bias=True, kernel_initializer='lecun_uniform', name = 'buy_prediction')(cascading)\n",
    "\n",
    "outputs = tf.concat([click_prediction, buy_prediction], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None,)]            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 128)]        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 20)           2580        tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 128)]        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 10)           210         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_0 (Dense)               (None, 20)           2580        tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            11          layer_1_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_1 (Dense)               (None, 10)           210         layer_2_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 10)]         0           layer_2_1[0][0]                  \n",
      "                                                                 click_prediction[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "buy_prediction (Dense)          (None, 1)            11          tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_2 (TensorFlo [(None, 2)]          0           click_prediction[0][0]           \n",
      "                                                                 buy_prediction[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 301,211,618\n",
      "Trainable params: 301,211,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\",tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_click.head()"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "192/201 [===========================>..] - ETA: 0s - loss: 0.5878 - accuracy: 1.0000 - mse: 0.1983 - root_mean_squared_error: 0.4453End epoch 0 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 1.0000 - mse: 0.1979 - root_mean_squared_error: 0.4448\n",
      "Epoch 2/100\n",
      "154/201 [=====================>........] - ETA: 0s - loss: 0.5563 - accuracy: 1.0000 - mse: 0.1834 - root_mean_squared_error: 0.4282End epoch 1 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 987us/step - loss: 0.5530 - accuracy: 1.0000 - mse: 0.1818 - root_mean_squared_error: 0.4264\n",
      "Epoch 3/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.5324 - accuracy: 1.0000 - mse: 0.1723 - root_mean_squared_error: 0.4151End epoch 2 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.5304 - accuracy: 1.0000 - mse: 0.1714 - root_mean_squared_error: 0.4140\n",
      "Epoch 4/100\n",
      "167/201 [=======================>......] - ETA: 0s - loss: 0.5136 - accuracy: 1.0000 - mse: 0.1638 - root_mean_squared_error: 0.4048End epoch 3 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.5122 - accuracy: 1.0000 - mse: 0.1632 - root_mean_squared_error: 0.4040\n",
      "Epoch 5/100\n",
      "156/201 [======================>.......] - ETA: 0s - loss: 0.4983 - accuracy: 1.0000 - mse: 0.1571 - root_mean_squared_error: 0.3963End epoch 4 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.4966 - accuracy: 1.0000 - mse: 0.1563 - root_mean_squared_error: 0.3954\n",
      "Epoch 6/100\n",
      "164/201 [=======================>......] - ETA: 0s - loss: 0.4840 - accuracy: 1.0000 - mse: 0.1508 - root_mean_squared_error: 0.3883End epoch 5 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4827 - accuracy: 1.0000 - mse: 0.1503 - root_mean_squared_error: 0.3876\n",
      "Epoch 7/100\n",
      "167/201 [=======================>......] - ETA: 0s - loss: 0.4708 - accuracy: 1.0000 - mse: 0.1451 - root_mean_squared_error: 0.3809End epoch 6 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.4700 - accuracy: 1.0000 - mse: 0.1448 - root_mean_squared_error: 0.3805\n",
      "Epoch 8/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.4595 - accuracy: 1.0000 - mse: 0.1403 - root_mean_squared_error: 0.3746End epoch 7 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.4583 - accuracy: 1.0000 - mse: 0.1398 - root_mean_squared_error: 0.3739\n",
      "Epoch 9/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.4486 - accuracy: 1.0000 - mse: 0.1357 - root_mean_squared_error: 0.3684End epoch 8 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.4473 - accuracy: 1.0000 - mse: 0.1352 - root_mean_squared_error: 0.3676\n",
      "Epoch 10/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.4379 - accuracy: 1.0000 - mse: 0.1312 - root_mean_squared_error: 0.3623End epoch 9 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.4369 - accuracy: 1.0000 - mse: 0.1308 - root_mean_squared_error: 0.3617\n",
      "Epoch 11/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.4283 - accuracy: 1.0000 - mse: 0.1273 - root_mean_squared_error: 0.3568End epoch 10 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4271 - accuracy: 1.0000 - mse: 0.1268 - root_mean_squared_error: 0.3560\n",
      "Epoch 12/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.4186 - accuracy: 1.0000 - mse: 0.1233 - root_mean_squared_error: 0.3511End epoch 11 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4177 - accuracy: 1.0000 - mse: 0.1229 - root_mean_squared_error: 0.3506\n",
      "Epoch 13/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.4099 - accuracy: 1.0000 - mse: 0.1197 - root_mean_squared_error: 0.3460End epoch 12 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.4088 - accuracy: 1.0000 - mse: 0.1193 - root_mean_squared_error: 0.3454\n",
      "Epoch 14/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.4013 - accuracy: 1.0000 - mse: 0.1163 - root_mean_squared_error: 0.3410End epoch 13 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4002 - accuracy: 1.0000 - mse: 0.1158 - root_mean_squared_error: 0.3403\n",
      "Epoch 15/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.3927 - accuracy: 1.0000 - mse: 0.1128 - root_mean_squared_error: 0.3358End epoch 14 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.3920 - accuracy: 1.0000 - mse: 0.1125 - root_mean_squared_error: 0.3354\n",
      "Epoch 16/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.3843 - accuracy: 1.0000 - mse: 0.1094 - root_mean_squared_error: 0.3307End epoch 15 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.3841 - accuracy: 1.0000 - mse: 0.1093 - root_mean_squared_error: 0.3307\n",
      "Epoch 17/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.3766 - accuracy: 1.0000 - mse: 0.1064 - root_mean_squared_error: 0.3261End epoch 16 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.3765 - accuracy: 1.0000 - mse: 0.1063 - root_mean_squared_error: 0.3260\n",
      "Epoch 18/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.3695 - accuracy: 1.0000 - mse: 0.1035 - root_mean_squared_error: 0.3217End epoch 17 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.3691 - accuracy: 1.0000 - mse: 0.1034 - root_mean_squared_error: 0.3215\n",
      "Epoch 19/100\n",
      "165/201 [=======================>......] - ETA: 0s - loss: 0.3626 - accuracy: 1.0000 - mse: 0.1008 - root_mean_squared_error: 0.3175End epoch 18 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.3620 - accuracy: 1.0000 - mse: 0.1006 - root_mean_squared_error: 0.3172\n",
      "Epoch 20/100\n",
      "166/201 [=======================>......] - ETA: 0s - loss: 0.3552 - accuracy: 1.0000 - mse: 0.0979 - root_mean_squared_error: 0.3129End epoch 19 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.3552 - accuracy: 1.0000 - mse: 0.0979 - root_mean_squared_error: 0.3129\n",
      "Epoch 21/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.3497 - accuracy: 1.0000 - mse: 0.0958 - root_mean_squared_error: 0.3094End epoch 20 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.3485 - accuracy: 1.0000 - mse: 0.0953 - root_mean_squared_error: 0.3087\n",
      "Epoch 22/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.3430 - accuracy: 1.0000 - mse: 0.0931 - root_mean_squared_error: 0.3052End epoch 21 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.3421 - accuracy: 1.0000 - mse: 0.0928 - root_mean_squared_error: 0.3046\n",
      "Epoch 23/100\n",
      "164/201 [=======================>......] - ETA: 0s - loss: 0.3374 - accuracy: 1.0000 - mse: 0.0909 - root_mean_squared_error: 0.3016End epoch 22 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.3358 - accuracy: 1.0000 - mse: 0.0904 - root_mean_squared_error: 0.3006\n",
      "Epoch 24/100\n",
      "164/201 [=======================>......] - ETA: 0s - loss: 0.3305 - accuracy: 1.0000 - mse: 0.0883 - root_mean_squared_error: 0.2971End epoch 23 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.3298 - accuracy: 1.0000 - mse: 0.0880 - root_mean_squared_error: 0.2967\n",
      "Epoch 25/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.3243 - accuracy: 1.0000 - mse: 0.0859 - root_mean_squared_error: 0.2930End epoch 24 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.3239 - accuracy: 1.0000 - mse: 0.0857 - root_mean_squared_error: 0.2928\n",
      "Epoch 26/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.3186 - accuracy: 1.0000 - mse: 0.0837 - root_mean_squared_error: 0.2893End epoch 25 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.3182 - accuracy: 1.0000 - mse: 0.0835 - root_mean_squared_error: 0.2890\n",
      "Epoch 27/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.3132 - accuracy: 1.0000 - mse: 0.0816 - root_mean_squared_error: 0.2857End epoch 26 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.3126 - accuracy: 1.0000 - mse: 0.0814 - root_mean_squared_error: 0.2853\n",
      "Epoch 28/100\n",
      "151/201 [=====================>........] - ETA: 0s - loss: 0.3086 - accuracy: 1.0000 - mse: 0.0799 - root_mean_squared_error: 0.2826End epoch 27 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 1.0000 - mse: 0.0794 - root_mean_squared_error: 0.2817\n",
      "Epoch 29/100\n",
      "165/201 [=======================>......] - ETA: 0s - loss: 0.3021 - accuracy: 1.0000 - mse: 0.0774 - root_mean_squared_error: 0.2782End epoch 28 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.3020 - accuracy: 1.0000 - mse: 0.0773 - root_mean_squared_error: 0.2781\n",
      "Epoch 30/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.2969 - accuracy: 1.0000 - mse: 0.0754 - root_mean_squared_error: 0.2746End epoch 29 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2969 - accuracy: 1.0000 - mse: 0.0754 - root_mean_squared_error: 0.2746\n",
      "Epoch 31/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.2918 - accuracy: 1.0000 - mse: 0.0735 - root_mean_squared_error: 0.2711End epoch 30 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.2919 - accuracy: 1.0000 - mse: 0.0735 - root_mean_squared_error: 0.2711\n",
      "Epoch 32/100\n",
      "165/201 [=======================>......] - ETA: 0s - loss: 0.2876 - accuracy: 1.0000 - mse: 0.0719 - root_mean_squared_error: 0.2681End epoch 31 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.2870 - accuracy: 1.0000 - mse: 0.0717 - root_mean_squared_error: 0.2677\n",
      "Epoch 33/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.2831 - accuracy: 1.0000 - mse: 0.0702 - root_mean_squared_error: 0.2650End epoch 32 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.2823 - accuracy: 1.0000 - mse: 0.0699 - root_mean_squared_error: 0.2644\n",
      "Epoch 34/100\n",
      "164/201 [=======================>......] - ETA: 0s - loss: 0.2782 - accuracy: 1.0000 - mse: 0.0684 - root_mean_squared_error: 0.2614End epoch 33 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.2777 - accuracy: 1.0000 - mse: 0.0682 - root_mean_squared_error: 0.2611\n",
      "Epoch 35/100\n",
      "155/201 [======================>.......] - ETA: 0s - loss: 0.2738 - accuracy: 1.0000 - mse: 0.0667 - root_mean_squared_error: 0.2583End epoch 34 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.2732 - accuracy: 1.0000 - mse: 0.0665 - root_mean_squared_error: 0.2579\n",
      "Epoch 36/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.2693 - accuracy: 1.0000 - mse: 0.0650 - root_mean_squared_error: 0.2550End epoch 35 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2688 - accuracy: 1.0000 - mse: 0.0649 - root_mean_squared_error: 0.2547\n",
      "Epoch 37/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.2654 - accuracy: 1.0000 - mse: 0.0636 - root_mean_squared_error: 0.2522End epoch 36 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.2646 - accuracy: 1.0000 - mse: 0.0633 - root_mean_squared_error: 0.2516\n",
      "Epoch 38/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.2608 - accuracy: 1.0000 - mse: 0.0619 - root_mean_squared_error: 0.2488End epoch 37 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2604 - accuracy: 1.0000 - mse: 0.0618 - root_mean_squared_error: 0.2485\n",
      "Epoch 39/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.2572 - accuracy: 1.0000 - mse: 0.0606 - root_mean_squared_error: 0.2461End epoch 38 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.2564 - accuracy: 1.0000 - mse: 0.0603 - root_mean_squared_error: 0.2455\n",
      "Epoch 40/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.2517 - accuracy: 1.0000 - mse: 0.0586 - root_mean_squared_error: 0.2420End epoch 39 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.2524 - accuracy: 1.0000 - mse: 0.0588 - root_mean_squared_error: 0.2426\n",
      "Epoch 41/100\n",
      "166/201 [=======================>......] - ETA: 0s - loss: 0.2485 - accuracy: 1.0000 - mse: 0.0574 - root_mean_squared_error: 0.2396End epoch 40 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.2486 - accuracy: 1.0000 - mse: 0.0574 - root_mean_squared_error: 0.2397\n",
      "Epoch 42/100\n",
      "155/201 [======================>.......] - ETA: 0s - loss: 0.2445 - accuracy: 1.0000 - mse: 0.0560 - root_mean_squared_error: 0.2366End epoch 41 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 982us/step - loss: 0.2448 - accuracy: 1.0000 - mse: 0.0561 - root_mean_squared_error: 0.2368\n",
      "Epoch 43/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.2421 - accuracy: 1.0000 - mse: 0.0551 - root_mean_squared_error: 0.2347End epoch 42 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2412 - accuracy: 1.0000 - mse: 0.0548 - root_mean_squared_error: 0.2340\n",
      "Epoch 44/100\n",
      "156/201 [======================>.......] - ETA: 0s - loss: 0.2379 - accuracy: 1.0000 - mse: 0.0536 - root_mean_squared_error: 0.2316End epoch 43 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.2376 - accuracy: 1.0000 - mse: 0.0535 - root_mean_squared_error: 0.2313\n",
      "Epoch 45/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.2357 - accuracy: 1.0000 - mse: 0.0528 - root_mean_squared_error: 0.2298End epoch 44 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.2341 - accuracy: 1.0000 - mse: 0.0523 - root_mean_squared_error: 0.2286\n",
      "Epoch 46/100\n",
      "156/201 [======================>.......] - ETA: 0s - loss: 0.2308 - accuracy: 1.0000 - mse: 0.0511 - root_mean_squared_error: 0.2260End epoch 45 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.2308 - accuracy: 1.0000 - mse: 0.0511 - root_mean_squared_error: 0.2260\n",
      "Epoch 47/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.2273 - accuracy: 1.0000 - mse: 0.0499 - root_mean_squared_error: 0.2233End epoch 46 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2275 - accuracy: 1.0000 - mse: 0.0499 - root_mean_squared_error: 0.2234\n",
      "Epoch 48/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.2255 - accuracy: 1.0000 - mse: 0.0492 - root_mean_squared_error: 0.2218End epoch 47 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.2242 - accuracy: 1.0000 - mse: 0.0488 - root_mean_squared_error: 0.2209\n",
      "Epoch 49/100\n",
      "156/201 [======================>.......] - ETA: 0s - loss: 0.2210 - accuracy: 1.0000 - mse: 0.0477 - root_mean_squared_error: 0.2183End epoch 48 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.2211 - accuracy: 1.0000 - mse: 0.0477 - root_mean_squared_error: 0.2184\n",
      "Epoch 50/100\n",
      "165/201 [=======================>......] - ETA: 0s - loss: 0.2177 - accuracy: 1.0000 - mse: 0.0465 - root_mean_squared_error: 0.2158End epoch 49 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2180 - accuracy: 1.0000 - mse: 0.0467 - root_mean_squared_error: 0.2160\n",
      "Epoch 51/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.2147 - accuracy: 1.0000 - mse: 0.0455 - root_mean_squared_error: 0.2134End epoch 50 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.2151 - accuracy: 1.0000 - mse: 0.0456 - root_mean_squared_error: 0.2136\n",
      "Epoch 52/100\n",
      "156/201 [======================>.......] - ETA: 0s - loss: 0.2118 - accuracy: 1.0000 - mse: 0.0446 - root_mean_squared_error: 0.2111End epoch 51 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.2121 - accuracy: 1.0000 - mse: 0.0447 - root_mean_squared_error: 0.2113\n",
      "Epoch 53/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.2096 - accuracy: 1.0000 - mse: 0.0438 - root_mean_squared_error: 0.2093End epoch 52 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.2093 - accuracy: 1.0000 - mse: 0.0437 - root_mean_squared_error: 0.2090\n",
      "Epoch 54/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.2060 - accuracy: 1.0000 - mse: 0.0426 - root_mean_squared_error: 0.2064End epoch 53 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.2065 - accuracy: 1.0000 - mse: 0.0428 - root_mean_squared_error: 0.2068\n",
      "Epoch 55/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.2041 - accuracy: 1.0000 - mse: 0.0420 - root_mean_squared_error: 0.2048End epoch 54 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.2038 - accuracy: 1.0000 - mse: 0.0419 - root_mean_squared_error: 0.2046\n",
      "Epoch 56/100\n",
      "162/201 [=======================>......] - ETA: 0s - loss: 0.2016 - accuracy: 1.0000 - mse: 0.0412 - root_mean_squared_error: 0.2029End epoch 55 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2012 - accuracy: 1.0000 - mse: 0.0410 - root_mean_squared_error: 0.2025\n",
      "Epoch 57/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.1999 - accuracy: 1.0000 - mse: 0.0406 - root_mean_squared_error: 0.2014End epoch 56 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1986 - accuracy: 1.0000 - mse: 0.0402 - root_mean_squared_error: 0.2004\n",
      "Epoch 58/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1960 - accuracy: 1.0000 - mse: 0.0393 - root_mean_squared_error: 0.1983End epoch 57 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1961 - accuracy: 1.0000 - mse: 0.0394 - root_mean_squared_error: 0.1984\n",
      "Epoch 59/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.1937 - accuracy: 1.0000 - mse: 0.0386 - root_mean_squared_error: 0.1965End epoch 58 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.1937 - accuracy: 1.0000 - mse: 0.0386 - root_mean_squared_error: 0.1964\n",
      "Epoch 60/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1914 - accuracy: 1.0000 - mse: 0.0379 - root_mean_squared_error: 0.1946End epoch 59 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1913 - accuracy: 1.0000 - mse: 0.0378 - root_mean_squared_error: 0.1945\n",
      "Epoch 61/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1888 - accuracy: 1.0000 - mse: 0.0370 - root_mean_squared_error: 0.1925End epoch 60 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1889 - accuracy: 1.0000 - mse: 0.0371 - root_mean_squared_error: 0.1926\n",
      "Epoch 62/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.1863 - accuracy: 1.0000 - mse: 0.0363 - root_mean_squared_error: 0.1904End epoch 61 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 982us/step - loss: 0.1867 - accuracy: 1.0000 - mse: 0.0364 - root_mean_squared_error: 0.1908\n",
      "Epoch 63/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1850 - accuracy: 1.0000 - mse: 0.0359 - root_mean_squared_error: 0.1894End epoch 62 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1844 - accuracy: 1.0000 - mse: 0.0357 - root_mean_squared_error: 0.1889\n",
      "Epoch 64/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1834 - accuracy: 1.0000 - mse: 0.0354 - root_mean_squared_error: 0.1881End epoch 63 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1823 - accuracy: 1.0000 - mse: 0.0350 - root_mean_squared_error: 0.1872\n",
      "Epoch 65/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1798 - accuracy: 1.0000 - mse: 0.0343 - root_mean_squared_error: 0.1852End epoch 64 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1802 - accuracy: 1.0000 - mse: 0.0344 - root_mean_squared_error: 0.1855\n",
      "Epoch 66/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1782 - accuracy: 1.0000 - mse: 0.0338 - root_mean_squared_error: 0.1839End epoch 65 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1781 - accuracy: 1.0000 - mse: 0.0338 - root_mean_squared_error: 0.1838\n",
      "Epoch 67/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.1764 - accuracy: 1.0000 - mse: 0.0333 - root_mean_squared_error: 0.1824End epoch 66 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1761 - accuracy: 1.0000 - mse: 0.0332 - root_mean_squared_error: 0.1822\n",
      "Epoch 68/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1740 - accuracy: 1.0000 - mse: 0.0326 - root_mean_squared_error: 0.1804End epoch 67 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1741 - accuracy: 1.0000 - mse: 0.0326 - root_mean_squared_error: 0.1806\n",
      "Epoch 69/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1725 - accuracy: 1.0000 - mse: 0.0321 - root_mean_squared_error: 0.1793End epoch 68 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1722 - accuracy: 1.0000 - mse: 0.0320 - root_mean_squared_error: 0.1790\n",
      "Epoch 70/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1704 - accuracy: 1.0000 - mse: 0.0315 - root_mean_squared_error: 0.1776End epoch 69 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1703 - accuracy: 1.0000 - mse: 0.0315 - root_mean_squared_error: 0.1775\n",
      "Epoch 71/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1686 - accuracy: 1.0000 - mse: 0.0310 - root_mean_squared_error: 0.1761End epoch 70 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1685 - accuracy: 1.0000 - mse: 0.0310 - root_mean_squared_error: 0.1760\n",
      "Epoch 72/100\n",
      "153/201 [=====================>........] - ETA: 0s - loss: 0.1665 - accuracy: 1.0000 - mse: 0.0304 - root_mean_squared_error: 0.1744End epoch 71 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 992us/step - loss: 0.1667 - accuracy: 1.0000 - mse: 0.0305 - root_mean_squared_error: 0.1746\n",
      "Epoch 73/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1651 - accuracy: 1.0000 - mse: 0.0300 - root_mean_squared_error: 0.1733End epoch 72 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1649 - accuracy: 1.0000 - mse: 0.0300 - root_mean_squared_error: 0.1731\n",
      "Epoch 74/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.1625 - accuracy: 1.0000 - mse: 0.0293 - root_mean_squared_error: 0.1712End epoch 73 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1632 - accuracy: 1.0000 - mse: 0.0295 - root_mean_squared_error: 0.1718\n",
      "Epoch 75/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1622 - accuracy: 1.0000 - mse: 0.0292 - root_mean_squared_error: 0.1710End epoch 74 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1615 - accuracy: 1.0000 - mse: 0.0291 - root_mean_squared_error: 0.1704\n",
      "Epoch 76/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1601 - accuracy: 1.0000 - mse: 0.0287 - root_mean_squared_error: 0.1693End epoch 75 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1599 - accuracy: 1.0000 - mse: 0.0286 - root_mean_squared_error: 0.1691\n",
      "Epoch 77/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1576 - accuracy: 1.0000 - mse: 0.0280 - root_mean_squared_error: 0.1672End epoch 76 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1583 - accuracy: 1.0000 - mse: 0.0282 - root_mean_squared_error: 0.1679\n",
      "Epoch 78/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.1561 - accuracy: 1.0000 - mse: 0.0276 - root_mean_squared_error: 0.1661End epoch 77 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1567 - accuracy: 1.0000 - mse: 0.0278 - root_mean_squared_error: 0.1666\n",
      "Epoch 79/100\n",
      "194/201 [===========================>..] - ETA: 0s - loss: 0.1554 - accuracy: 1.0000 - mse: 0.0274 - root_mean_squared_error: 0.1656End epoch 78 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 1.0000 - mse: 0.0274 - root_mean_squared_error: 0.1654\n",
      "Epoch 80/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1535 - accuracy: 1.0000 - mse: 0.0269 - root_mean_squared_error: 0.1640End epoch 79 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1537 - accuracy: 1.0000 - mse: 0.0270 - root_mean_squared_error: 0.1643\n",
      "Epoch 81/100\n",
      "165/201 [=======================>......] - ETA: 0s - loss: 0.1531 - accuracy: 1.0000 - mse: 0.0269 - root_mean_squared_error: 0.1639End epoch 80 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1523 - accuracy: 1.0000 - mse: 0.0266 - root_mean_squared_error: 0.1631\n",
      "Epoch 82/100\n",
      "155/201 [======================>.......] - ETA: 0s - loss: 0.1499 - accuracy: 1.0000 - mse: 0.0260 - root_mean_squared_error: 0.1612End epoch 81 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 987us/step - loss: 0.1509 - accuracy: 1.0000 - mse: 0.0262 - root_mean_squared_error: 0.1620\n",
      "Epoch 83/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1493 - accuracy: 1.0000 - mse: 0.0258 - root_mean_squared_error: 0.1607End epoch 82 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1495 - accuracy: 1.0000 - mse: 0.0259 - root_mean_squared_error: 0.1609\n",
      "Epoch 84/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1490 - accuracy: 1.0000 - mse: 0.0258 - root_mean_squared_error: 0.1607End epoch 83 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1481 - accuracy: 1.0000 - mse: 0.0256 - root_mean_squared_error: 0.1599\n",
      "Epoch 85/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1467 - accuracy: 1.0000 - mse: 0.0252 - root_mean_squared_error: 0.1588End epoch 84 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1468 - accuracy: 1.0000 - mse: 0.0252 - root_mean_squared_error: 0.1589\n",
      "Epoch 86/100\n",
      "154/201 [=====================>........] - ETA: 0s - loss: 0.1433 - accuracy: 1.0000 - mse: 0.0243 - root_mean_squared_error: 0.1559End epoch 85 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 992us/step - loss: 0.1455 - accuracy: 1.0000 - mse: 0.0249 - root_mean_squared_error: 0.1579\n",
      "Epoch 87/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1451 - accuracy: 1.0000 - mse: 0.0249 - root_mean_squared_error: 0.1577End epoch 86 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1442 - accuracy: 1.0000 - mse: 0.0246 - root_mean_squared_error: 0.1569\n",
      "Epoch 88/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1432 - accuracy: 1.0000 - mse: 0.0244 - root_mean_squared_error: 0.1562End epoch 87 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1429 - accuracy: 1.0000 - mse: 0.0243 - root_mean_squared_error: 0.1560\n",
      "Epoch 89/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.1411 - accuracy: 1.0000 - mse: 0.0239 - root_mean_squared_error: 0.1545End epoch 88 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1417 - accuracy: 1.0000 - mse: 0.0240 - root_mean_squared_error: 0.1550\n",
      "Epoch 90/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1394 - accuracy: 1.0000 - mse: 0.0234 - root_mean_squared_error: 0.1531End epoch 89 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1405 - accuracy: 1.0000 - mse: 0.0238 - root_mean_squared_error: 0.1541\n",
      "Epoch 91/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1387 - accuracy: 1.0000 - mse: 0.0233 - root_mean_squared_error: 0.1527End epoch 90 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1394 - accuracy: 1.0000 - mse: 0.0235 - root_mean_squared_error: 0.1533\n",
      "Epoch 92/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1379 - accuracy: 1.0000 - mse: 0.0231 - root_mean_squared_error: 0.1521End epoch 91 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1382 - accuracy: 1.0000 - mse: 0.0232 - root_mean_squared_error: 0.1524\n",
      "Epoch 93/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000 - mse: 0.0232 - root_mean_squared_error: 0.1524End epoch 92 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1371 - accuracy: 1.0000 - mse: 0.0230 - root_mean_squared_error: 0.1516\n",
      "Epoch 94/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1356 - accuracy: 1.0000 - mse: 0.0226 - root_mean_squared_error: 0.1504End epoch 93 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1360 - accuracy: 1.0000 - mse: 0.0227 - root_mean_squared_error: 0.1508\n",
      "Epoch 95/100\n",
      "160/201 [======================>.......] - ETA: 0s - loss: 0.1360 - accuracy: 1.0000 - mse: 0.0228 - root_mean_squared_error: 0.1510End epoch 94 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1349 - accuracy: 1.0000 - mse: 0.0225 - root_mean_squared_error: 0.1500\n",
      "Epoch 96/100\n",
      "159/201 [======================>.......] - ETA: 0s - loss: 0.1343 - accuracy: 1.0000 - mse: 0.0224 - root_mean_squared_error: 0.1496End epoch 95 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1339 - accuracy: 1.0000 - mse: 0.0223 - root_mean_squared_error: 0.1493\n",
      "Epoch 97/100\n",
      "157/201 [======================>.......] - ETA: 0s - loss: 0.1338 - accuracy: 1.0000 - mse: 0.0223 - root_mean_squared_error: 0.1494End epoch 96 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.1329 - accuracy: 1.0000 - mse: 0.0221 - root_mean_squared_error: 0.1485\n",
      "Epoch 98/100\n",
      "163/201 [=======================>......] - ETA: 0s - loss: 0.1313 - accuracy: 1.0000 - mse: 0.0217 - root_mean_squared_error: 0.1472End epoch 97 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1319 - accuracy: 1.0000 - mse: 0.0219 - root_mean_squared_error: 0.1478\n",
      "Epoch 99/100\n",
      "161/201 [=======================>......] - ETA: 0s - loss: 0.1312 - accuracy: 1.0000 - mse: 0.0217 - root_mean_squared_error: 0.1474End epoch 98 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1309 - accuracy: 1.0000 - mse: 0.0216 - root_mean_squared_error: 0.1471\n",
      "Epoch 100/100\n",
      "158/201 [======================>.......] - ETA: 0s - loss: 0.1294 - accuracy: 1.0000 - mse: 0.0213 - root_mean_squared_error: 0.1459End epoch 99 of training; got log keys: ['loss', 'accuracy', 'mse', 'root_mean_squared_error']\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1299 - accuracy: 1.0000 - mse: 0.0214 - root_mean_squared_error: 0.1464\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=200, epochs=100, callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "\n",
    "layers = [20,10]\n",
    "reg_layers=[0,0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 10e-4\n",
    "\n",
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=None, trainable=True)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=None, trainable=True)\n",
    "\n",
    "user_embedding = Embedding_User(inputs[:,0])\n",
    "item_embedding = Embedding_Item(inputs[:,1])\n",
    "\n",
    "user_latent = Flatten(name = 'user_latent')(user_embedding)\n",
    "item_latent = Flatten(name = 'item_latent')(item_embedding)\n",
    "\n",
    "vector = tf.keras.layers.Multiply()([user_latent, item_latent])\n",
    "\n",
    "user_embedding2 = Embedding_User(inputs[:,0])\n",
    "item_embedding2 = Embedding_Item(inputs[:,1])\n",
    "\n",
    "user_latent2 = Flatten(name = 'user_latent2')(user_embedding2)\n",
    "item_latent2 = Flatten(name = 'item_latent2')(item_embedding2)\n",
    "\n",
    "vector2 = tf.keras.layers.Multiply()([user_latent2, item_latent2])\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "    \n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_2_%d' %idx)\n",
    "    vector2 = layer(vector2)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'click_prediction')(vector)\n",
    "\n",
    "buy_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'buy_prediction')(vector2)\n",
    "\n",
    "outputs = tf.concat([click_prediction, buy_prediction], -1)"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_user = np.zeros((len(data_click), count_item), dtype=int)\n",
    "# for user, item, rating in data_click.values:\n",
    "#     input_user[np.where(list_user == user)[0][0]] [np.where(list_item == item)[0][0]] = 1 # Convert to 0-based index.\n",
    "    \n",
    "# input_item = np.zeros((len(data_click), count_user), dtype=int)\n",
    "# for user, item, rating in data_click:\n",
    "#     input_item[np.where(list_item == item)[0][0]] [np.where(list_user == user)[0][0]] = 1 # Convert to 0-based index."
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_3[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_latent (Flatten)           (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "item_latent (Flatten)           (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_latent2 (Flatten)          (None, 64)           0           user_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "item_latent2 (Flatten)          (None, 64)           0           item_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64)           0           user_latent[0][0]                \n",
      "                                                                 item_latent[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 64)           0           user_latent2[0][0]               \n",
      "                                                                 item_latent2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 20)           1300        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_0 (Dense)               (None, 20)           1300        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 10)           210         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_1 (Dense)               (None, 10)           210         layer_2_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            11          layer_1_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "buy_prediction (Dense)          (None, 1)            11          layer_2_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 2)]          0           click_prediction[0][0]           \n",
      "                                                                 buy_prediction[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 301,209,058\n",
      "Trainable params: 301,209,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model2 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model2.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\",tf.keras.metrics.RootMeanSquaredError()])\n",
    "model2.summary()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = x_train.ite_ID\n",
    "depth = count_item\n",
    "input_user = tf.one_hot(indices, depth, axis=-1)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.9987 - mse: 0.2372 - root_mean_squared_error: 0.4870\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.6391 - accuracy: 1.0000 - mse: 0.2230 - root_mean_squared_error: 0.4722\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.6195 - accuracy: 1.0000 - mse: 0.2133 - root_mean_squared_error: 0.4618\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.6029 - accuracy: 1.0000 - mse: 0.2051 - root_mean_squared_error: 0.4529\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.5880 - accuracy: 1.0000 - mse: 0.1978 - root_mean_squared_error: 0.4448\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 0s 883us/step - loss: 0.5742 - accuracy: 1.0000 - mse: 0.1911 - root_mean_squared_error: 0.4371\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.5611 - accuracy: 1.0000 - mse: 0.1848 - root_mean_squared_error: 0.4299\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.5486 - accuracy: 1.0000 - mse: 0.1788 - root_mean_squared_error: 0.4228\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.5366 - accuracy: 1.0000 - mse: 0.1731 - root_mean_squared_error: 0.4160\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.5250 - accuracy: 1.0000 - mse: 0.1676 - root_mean_squared_error: 0.4094\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 0s 883us/step - loss: 0.5137 - accuracy: 1.0000 - mse: 0.1624 - root_mean_squared_error: 0.4030\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 0s 888us/step - loss: 0.5028 - accuracy: 1.0000 - mse: 0.1574 - root_mean_squared_error: 0.3967\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.4922 - accuracy: 1.0000 - mse: 0.1525 - root_mean_squared_error: 0.3905\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 0s 888us/step - loss: 0.4819 - accuracy: 1.0000 - mse: 0.1479 - root_mean_squared_error: 0.3845\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.4718 - accuracy: 1.0000 - mse: 0.1434 - root_mean_squared_error: 0.3787\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.4621 - accuracy: 1.0000 - mse: 0.1391 - root_mean_squared_error: 0.3730\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 0s 883us/step - loss: 0.4526 - accuracy: 1.0000 - mse: 0.1350 - root_mean_squared_error: 0.3674\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.4434 - accuracy: 1.0000 - mse: 0.1310 - root_mean_squared_error: 0.3620\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 0s 883us/step - loss: 0.4345 - accuracy: 1.0000 - mse: 0.1272 - root_mean_squared_error: 0.3567\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 0s 888us/step - loss: 0.4258 - accuracy: 1.0000 - mse: 0.1236 - root_mean_squared_error: 0.3515\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.4174 - accuracy: 1.0000 - mse: 0.1201 - root_mean_squared_error: 0.3465\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.4092 - accuracy: 1.0000 - mse: 0.1167 - root_mean_squared_error: 0.3416\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.4013 - accuracy: 1.0000 - mse: 0.1135 - root_mean_squared_error: 0.3369\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.3936 - accuracy: 1.0000 - mse: 0.1104 - root_mean_squared_error: 0.3322\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.3861 - accuracy: 1.0000 - mse: 0.1074 - root_mean_squared_error: 0.3277\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.3789 - accuracy: 1.0000 - mse: 0.1045 - root_mean_squared_error: 0.3233\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.3719 - accuracy: 1.0000 - mse: 0.1018 - root_mean_squared_error: 0.3190\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 0s 883us/step - loss: 0.3650 - accuracy: 1.0000 - mse: 0.0991 - root_mean_squared_error: 0.3149\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.3584 - accuracy: 1.0000 - mse: 0.0966 - root_mean_squared_error: 0.3108\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.3520 - accuracy: 1.0000 - mse: 0.0941 - root_mean_squared_error: 0.3068\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 0s 888us/step - loss: 0.3458 - accuracy: 1.0000 - mse: 0.0918 - root_mean_squared_error: 0.3029\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.3398 - accuracy: 1.0000 - mse: 0.0895 - root_mean_squared_error: 0.2991\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.3339 - accuracy: 1.0000 - mse: 0.0873 - root_mean_squared_error: 0.2954\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.3282 - accuracy: 1.0000 - mse: 0.0851 - root_mean_squared_error: 0.2918\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 0s 888us/step - loss: 0.3226 - accuracy: 1.0000 - mse: 0.0831 - root_mean_squared_error: 0.2882\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.3173 - accuracy: 1.0000 - mse: 0.0811 - root_mean_squared_error: 0.2847\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.3120 - accuracy: 1.0000 - mse: 0.0791 - root_mean_squared_error: 0.2813\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.3069 - accuracy: 1.0000 - mse: 0.0773 - root_mean_squared_error: 0.2779\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.3019 - accuracy: 1.0000 - mse: 0.0754 - root_mean_squared_error: 0.2746\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2971 - accuracy: 1.0000 - mse: 0.0737 - root_mean_squared_error: 0.2714\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.2924 - accuracy: 1.0000 - mse: 0.0719 - root_mean_squared_error: 0.2682\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2878 - accuracy: 1.0000 - mse: 0.0703 - root_mean_squared_error: 0.2651\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.2833 - accuracy: 1.0000 - mse: 0.0687 - root_mean_squared_error: 0.2620\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.2789 - accuracy: 1.0000 - mse: 0.0671 - root_mean_squared_error: 0.2590\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.2747 - accuracy: 1.0000 - mse: 0.0655 - root_mean_squared_error: 0.2560\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2705 - accuracy: 1.0000 - mse: 0.0641 - root_mean_squared_error: 0.2531\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 1.0000 - mse: 0.0627 - root_mean_squared_error: 0.25 - 0s 908us/step - loss: 0.2664 - accuracy: 1.0000 - mse: 0.0626 - root_mean_squared_error: 0.2502\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.2625 - accuracy: 1.0000 - mse: 0.0612 - root_mean_squared_error: 0.2474\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.2586 - accuracy: 1.0000 - mse: 0.0598 - root_mean_squared_error: 0.2446\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.2548 - accuracy: 1.0000 - mse: 0.0585 - root_mean_squared_error: 0.2418\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.2511 - accuracy: 1.0000 - mse: 0.0572 - root_mean_squared_error: 0.2391\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2475 - accuracy: 1.0000 - mse: 0.0559 - root_mean_squared_error: 0.2365\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.2440 - accuracy: 1.0000 - mse: 0.0547 - root_mean_squared_error: 0.23390s - loss: 0.2443 - accuracy: 1.0000 - mse: 0.0548 - root_mean_squared_error: 0.\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.2406 - accuracy: 1.0000 - mse: 0.0535 - root_mean_squared_error: 0.2313\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2372 - accuracy: 1.0000 - mse: 0.0523 - root_mean_squared_error: 0.2288\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2339 - accuracy: 1.0000 - mse: 0.0512 - root_mean_squared_error: 0.2263\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.2307 - accuracy: 1.0000 - mse: 0.0501 - root_mean_squared_error: 0.2239\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.2275 - accuracy: 1.0000 - mse: 0.0490 - root_mean_squared_error: 0.2215\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.2245 - accuracy: 1.0000 - mse: 0.0480 - root_mean_squared_error: 0.2191\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2215 - accuracy: 1.0000 - mse: 0.0470 - root_mean_squared_error: 0.2168\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.2185 - accuracy: 1.0000 - mse: 0.0460 - root_mean_squared_error: 0.2145\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.2157 - accuracy: 1.0000 - mse: 0.0451 - root_mean_squared_error: 0.2123\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2128 - accuracy: 1.0000 - mse: 0.0441 - root_mean_squared_error: 0.2101\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2101 - accuracy: 1.0000 - mse: 0.0432 - root_mean_squared_error: 0.2079\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.2074 - accuracy: 1.0000 - mse: 0.0424 - root_mean_squared_error: 0.2058\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.2048 - accuracy: 1.0000 - mse: 0.0415 - root_mean_squared_error: 0.2038\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.2022 - accuracy: 1.0000 - mse: 0.0407 - root_mean_squared_error: 0.2017\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.1997 - accuracy: 1.0000 - mse: 0.0399 - root_mean_squared_error: 0.1998\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.1972 - accuracy: 1.0000 - mse: 0.0391 - root_mean_squared_error: 0.1978\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.1948 - accuracy: 1.0000 - mse: 0.0384 - root_mean_squared_error: 0.1959\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.1925 - accuracy: 1.0000 - mse: 0.0376 - root_mean_squared_error: 0.19400s - loss: 0.1918 - accuracy: 1.0000 - mse: 0.0374 - root_mean_squared_error: 0.\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1902 - accuracy: 1.0000 - mse: 0.0369 - root_mean_squared_error: 0.1922\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 1.0000 - mse: 0.0363 - root_mean_squared_error: 0.19 - 0s 903us/step - loss: 0.1879 - accuracy: 1.0000 - mse: 0.0363 - root_mean_squared_error: 0.1904\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 0s 878us/step - loss: 0.1857 - accuracy: 1.0000 - mse: 0.0356 - root_mean_squared_error: 0.18870s - loss: 0.1865 - accuracy: 1.0000 - mse: 0.0358 - root_mean_squared_error: 0.18\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1836 - accuracy: 1.0000 - mse: 0.0350 - root_mean_squared_error: 0.1870\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.1814 - accuracy: 1.0000 - mse: 0.0343 - root_mean_squared_error: 0.1853\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.1794 - accuracy: 1.0000 - mse: 0.0337 - root_mean_squared_error: 0.1836\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1774 - accuracy: 1.0000 - mse: 0.0331 - root_mean_squared_error: 0.1820\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.1754 - accuracy: 1.0000 - mse: 0.0326 - root_mean_squared_error: 0.1805\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.1735 - accuracy: 1.0000 - mse: 0.0320 - root_mean_squared_error: 0.1789\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.1716 - accuracy: 1.0000 - mse: 0.0315 - root_mean_squared_error: 0.1774\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1697 - accuracy: 1.0000 - mse: 0.0310 - root_mean_squared_error: 0.1760\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.1679 - accuracy: 1.0000 - mse: 0.0305 - root_mean_squared_error: 0.1746\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.1662 - accuracy: 1.0000 - mse: 0.0300 - root_mean_squared_error: 0.1732\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.1644 - accuracy: 1.0000 - mse: 0.0295 - root_mean_squared_error: 0.1718\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.1627 - accuracy: 1.0000 - mse: 0.0291 - root_mean_squared_error: 0.1705\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.1611 - accuracy: 1.0000 - mse: 0.0286 - root_mean_squared_error: 0.1692\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.1595 - accuracy: 1.0000 - mse: 0.0282 - root_mean_squared_error: 0.1679\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.1579 - accuracy: 1.0000 - mse: 0.0278 - root_mean_squared_error: 0.1667\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 0s 898us/step - loss: 0.1563 - accuracy: 1.0000 - mse: 0.0274 - root_mean_squared_error: 0.1655\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1548 - accuracy: 1.0000 - mse: 0.0270 - root_mean_squared_error: 0.1643\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.1533 - accuracy: 1.0000 - mse: 0.0266 - root_mean_squared_error: 0.1632\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1519 - accuracy: 1.0000 - mse: 0.0263 - root_mean_squared_error: 0.1621\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.1505 - accuracy: 1.0000 - mse: 0.0259 - root_mean_squared_error: 0.1610\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.1491 - accuracy: 1.0000 - mse: 0.0256 - root_mean_squared_error: 0.1600\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 0s 893us/step - loss: 0.1477 - accuracy: 1.0000 - mse: 0.0253 - root_mean_squared_error: 0.1589\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.1464 - accuracy: 1.0000 - mse: 0.0249 - root_mean_squared_error: 0.1579\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1451 - accuracy: 1.0000 - mse: 0.0246 - root_mean_squared_error: 0.1569\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1438 - accuracy: 1.0000 - mse: 0.0243 - root_mean_squared_error: 0.1560\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.1425 - accuracy: 1.0000 - mse: 0.0240 - root_mean_squared_error: 0.1551\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train, batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = x_train.use_ID\n",
    "depth = count_user\n",
    "input_item = tf.one_hot(indices, depth, axis=-1)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "\n",
    "layers = [20,10]\n",
    "reg_layers=[0,0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 10e-4\n",
    "\n",
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent, item_latent], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, kernel_initializer='lecun_uniform', name = 'click_prediction')(vector)\n",
    "\n",
    "user_latent2 = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent2 = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector2 = tf.concat([user_latent2, item_latent2], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_2_%d' %idx)\n",
    "    vector2 = layer(vector2)\n",
    "    \n",
    "buy_prediction = Dense(1, activation='sigmoid',use_bias=True, kernel_initializer='lecun_uniform', name = 'buy_prediction')(vector2)\n",
    "\n",
    "outputs = tf.concat([click_prediction, buy_prediction], -1)"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_item.shape, input_user.shape)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None,)]            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_6[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_7[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           user_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           item_embedding[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 128)]        0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 128)]        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 20)           2580        tf_op_layer_concat_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_0 (Dense)               (None, 20)           2580        tf_op_layer_concat_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 10)           210         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_1 (Dense)               (None, 10)           210         layer_2_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            11          layer_1_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "buy_prediction (Dense)          (None, 1)            11          layer_2_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 2)]          0           click_prediction[0][0]           \n",
      "                                                                 buy_prediction[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 301,211,618\n",
      "Trainable params: 301,211,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model3 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model3.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\",tf.keras.metrics.RootMeanSquaredError()])\n",
    "model3.summary()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = input_item.get_shape().as_list()[1]\n",
    "input_length"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.9760 - mse: 0.2415 - root_mean_squared_error: 0.4914\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.6553 - accuracy: 1.0000 - mse: 0.2311 - root_mean_squared_error: 0.4807\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 1.0000 - mse: 0.2228 - root_mean_squared_error: 0.4720\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.6236 - accuracy: 1.0000 - mse: 0.2153 - root_mean_squared_error: 0.4640\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.6096 - accuracy: 1.0000 - mse: 0.2083 - root_mean_squared_error: 0.4564\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.5961 - accuracy: 1.0000 - mse: 0.2017 - root_mean_squared_error: 0.4491\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.5831 - accuracy: 1.0000 - mse: 0.1953 - root_mean_squared_error: 0.4419\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.5704 - accuracy: 1.0000 - mse: 0.1890 - root_mean_squared_error: 0.4347\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 1.0000 - mse: 0.1829 - root_mean_squared_error: 0.4277\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.5456 - accuracy: 1.0000 - mse: 0.1769 - root_mean_squared_error: 0.4206\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.5336 - accuracy: 1.0000 - mse: 0.1711 - root_mean_squared_error: 0.4136\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 0s 908us/step - loss: 0.5217 - accuracy: 1.0000 - mse: 0.1654 - root_mean_squared_error: 0.4067\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.5101 - accuracy: 1.0000 - mse: 0.1598 - root_mean_squared_error: 0.3997\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 1.0000 - mse: 0.1543 - root_mean_squared_error: 0.3928\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.4872 - accuracy: 1.0000 - mse: 0.1490 - root_mean_squared_error: 0.3859\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.4761 - accuracy: 1.0000 - mse: 0.1437 - root_mean_squared_error: 0.3791\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.4651 - accuracy: 1.0000 - mse: 0.1386 - root_mean_squared_error: 0.3723\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4542 - accuracy: 1.0000 - mse: 0.1336 - root_mean_squared_error: 0.3655\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 0s 992us/step - loss: 0.4436 - accuracy: 1.0000 - mse: 0.1287 - root_mean_squared_error: 0.3588\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.4331 - accuracy: 1.0000 - mse: 0.1240 - root_mean_squared_error: 0.3521\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.4228 - accuracy: 1.0000 - mse: 0.1193 - root_mean_squared_error: 0.3454\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.4127 - accuracy: 1.0000 - mse: 0.1148 - root_mean_squared_error: 0.3389\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.4028 - accuracy: 1.0000 - mse: 0.1104 - root_mean_squared_error: 0.3323\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.3930 - accuracy: 1.0000 - mse: 0.1062 - root_mean_squared_error: 0.3259\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.3834 - accuracy: 1.0000 - mse: 0.1021 - root_mean_squared_error: 0.3195\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.3740 - accuracy: 1.0000 - mse: 0.0981 - root_mean_squared_error: 0.3132\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.3648 - accuracy: 1.0000 - mse: 0.0942 - root_mean_squared_error: 0.3069\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.3558 - accuracy: 1.0000 - mse: 0.0905 - root_mean_squared_error: 0.3008\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.3470 - accuracy: 1.0000 - mse: 0.0869 - root_mean_squared_error: 0.2948\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.3384 - accuracy: 1.0000 - mse: 0.0834 - root_mean_squared_error: 0.2888\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 0s 913us/step - loss: 0.3301 - accuracy: 1.0000 - mse: 0.0801 - root_mean_squared_error: 0.2830\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.3219 - accuracy: 1.0000 - mse: 0.0769 - root_mean_squared_error: 0.2772\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.3139 - accuracy: 1.0000 - mse: 0.0738 - root_mean_squared_error: 0.2716\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.3062 - accuracy: 1.0000 - mse: 0.0708 - root_mean_squared_error: 0.2662\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2986 - accuracy: 1.0000 - mse: 0.0680 - root_mean_squared_error: 0.2608\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 0s 918us/step - loss: 0.2913 - accuracy: 1.0000 - mse: 0.0653 - root_mean_squared_error: 0.2556\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.2842 - accuracy: 1.0000 - mse: 0.0627 - root_mean_squared_error: 0.2505\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 1.0000 - mse: 0.0603 - root_mean_squared_error: 0.2455\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2706 - accuracy: 1.0000 - mse: 0.0579 - root_mean_squared_error: 0.2407\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.2641 - accuracy: 1.0000 - mse: 0.0557 - root_mean_squared_error: 0.2360\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.2578 - accuracy: 1.0000 - mse: 0.0536 - root_mean_squared_error: 0.2315\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.2517 - accuracy: 1.0000 - mse: 0.0516 - root_mean_squared_error: 0.2271\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.2458 - accuracy: 1.0000 - mse: 0.0497 - root_mean_squared_error: 0.2228\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 1.0000 - mse: 0.0478 - root_mean_squared_error: 0.2187\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.2346 - accuracy: 1.0000 - mse: 0.0461 - root_mean_squared_error: 0.2147\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.2293 - accuracy: 1.0000 - mse: 0.0445 - root_mean_squared_error: 0.2109\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 0s 973us/step - loss: 0.2242 - accuracy: 1.0000 - mse: 0.0429 - root_mean_squared_error: 0.2072\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 1.0000 - mse: 0.0415 - root_mean_squared_error: 0.2036\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 1.0000 - mse: 0.0401 - root_mean_squared_error: 0.2002\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.2098 - accuracy: 1.0000 - mse: 0.0387 - root_mean_squared_error: 0.1968\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.2053 - accuracy: 1.0000 - mse: 0.0375 - root_mean_squared_error: 0.1936\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 0s 992us/step - loss: 0.2010 - accuracy: 1.0000 - mse: 0.0363 - root_mean_squared_error: 0.1906\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.1968 - accuracy: 1.0000 - mse: 0.0352 - root_mean_squared_error: 0.1876\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.1928 - accuracy: 1.0000 - mse: 0.0341 - root_mean_squared_error: 0.1848\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1889 - accuracy: 1.0000 - mse: 0.0331 - root_mean_squared_error: 0.1821\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.1852 - accuracy: 1.0000 - mse: 0.0322 - root_mean_squared_error: 0.1795\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 0s 997us/step - loss: 0.1816 - accuracy: 1.0000 - mse: 0.0313 - root_mean_squared_error: 0.1769\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1781 - accuracy: 1.0000 - mse: 0.0305 - root_mean_squared_error: 0.1746\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1748 - accuracy: 1.0000 - mse: 0.0297 - root_mean_squared_error: 0.1723\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.1716 - accuracy: 1.0000 - mse: 0.0289 - root_mean_squared_error: 0.1701\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1685 - accuracy: 1.0000 - mse: 0.0282 - root_mean_squared_error: 0.1679\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 0s 958us/step - loss: 0.1655 - accuracy: 1.0000 - mse: 0.0275 - root_mean_squared_error: 0.1659\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.1626 - accuracy: 1.0000 - mse: 0.0269 - root_mean_squared_error: 0.1640\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1598 - accuracy: 1.0000 - mse: 0.0263 - root_mean_squared_error: 0.1621\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1571 - accuracy: 1.0000 - mse: 0.0257 - root_mean_squared_error: 0.1604\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1545 - accuracy: 1.0000 - mse: 0.0252 - root_mean_squared_error: 0.1587\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1520 - accuracy: 1.0000 - mse: 0.0247 - root_mean_squared_error: 0.1571\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1496 - accuracy: 1.0000 - mse: 0.0242 - root_mean_squared_error: 0.1555\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1473 - accuracy: 1.0000 - mse: 0.0237 - root_mean_squared_error: 0.1541\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1450 - accuracy: 1.0000 - mse: 0.0233 - root_mean_squared_error: 0.1527\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1428 - accuracy: 1.0000 - mse: 0.0229 - root_mean_squared_error: 0.1513\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1408 - accuracy: 1.0000 - mse: 0.0225 - root_mean_squared_error: 0.1500\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1387 - accuracy: 1.0000 - mse: 0.0221 - root_mean_squared_error: 0.1488\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1368 - accuracy: 1.0000 - mse: 0.0218 - root_mean_squared_error: 0.1476\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1349 - accuracy: 1.0000 - mse: 0.0215 - root_mean_squared_error: 0.1465\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1331 - accuracy: 1.0000 - mse: 0.0211 - root_mean_squared_error: 0.1454\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 0s 933us/step - loss: 0.1313 - accuracy: 1.0000 - mse: 0.0209 - root_mean_squared_error: 0.1444\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.1296 - accuracy: 1.0000 - mse: 0.0206 - root_mean_squared_error: 0.1434\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1280 - accuracy: 1.0000 - mse: 0.0203 - root_mean_squared_error: 0.1425\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 0s 923us/step - loss: 0.1264 - accuracy: 1.0000 - mse: 0.0201 - root_mean_squared_error: 0.1416\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 0s 968us/step - loss: 0.1249 - accuracy: 1.0000 - mse: 0.0198 - root_mean_squared_error: 0.1408\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1234 - accuracy: 1.0000 - mse: 0.0196 - root_mean_squared_error: 0.1399\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1220 - accuracy: 1.0000 - mse: 0.0194 - root_mean_squared_error: 0.1392\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1206 - accuracy: 1.0000 - mse: 0.0192 - root_mean_squared_error: 0.1384\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 0s 928us/step - loss: 0.1193 - accuracy: 1.0000 - mse: 0.0190 - root_mean_squared_error: 0.1377\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1180 - accuracy: 1.0000 - mse: 0.0188 - root_mean_squared_error: 0.1370\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1167 - accuracy: 1.0000 - mse: 0.0186 - root_mean_squared_error: 0.1364\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 0s 977us/step - loss: 0.1155 - accuracy: 1.0000 - mse: 0.0184 - root_mean_squared_error: 0.1358\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1144 - accuracy: 1.0000 - mse: 0.0183 - root_mean_squared_error: 0.1352\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1132 - accuracy: 1.0000 - mse: 0.0181 - root_mean_squared_error: 0.1346\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1121 - accuracy: 1.0000 - mse: 0.0180 - root_mean_squared_error: 0.1341\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1111 - accuracy: 1.0000 - mse: 0.0178 - root_mean_squared_error: 0.1335\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1101 - accuracy: 1.0000 - mse: 0.0177 - root_mean_squared_error: 0.1330\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 0s 938us/step - loss: 0.1091 - accuracy: 1.0000 - mse: 0.0176 - root_mean_squared_error: 0.1326\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 0s 903us/step - loss: 0.1081 - accuracy: 1.0000 - mse: 0.0175 - root_mean_squared_error: 0.1321\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1072 - accuracy: 1.0000 - mse: 0.0173 - root_mean_squared_error: 0.1317\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 0s 953us/step - loss: 0.1063 - accuracy: 1.0000 - mse: 0.0172 - root_mean_squared_error: 0.1313\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 0s 948us/step - loss: 0.1054 - accuracy: 1.0000 - mse: 0.0171 - root_mean_squared_error: 0.1309\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 0s 963us/step - loss: 0.1045 - accuracy: 1.0000 - mse: 0.0170 - root_mean_squared_error: 0.1305\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 0s 943us/step - loss: 0.1037 - accuracy: 1.0000 - mse: 0.0169 - root_mean_squared_error: 0.1301\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train, y_train, batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuMF"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_item"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "\n",
    "layers = [20,10]\n",
    "reg_layers=[0,0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 10e-4\n",
    "j = (int)(64/3)\n",
    "\n",
    "## Tạo lớp input kích thước (None, 32, 32, 1)\n",
    "inputs = tf.keras.layers.Input(shape=(2))\n",
    "\n",
    "Embedding_User = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "Embedding_User2 = Embedding(\n",
    "    input_dim = num_users, \n",
    "    output_dim = 64, name = 'user_embedding2',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "Embedding_Item = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "Embedding_Item2 = Embedding(\n",
    "    input_dim = num_items, \n",
    "    output_dim = 64, \n",
    "    name = 'item_embedding2',\n",
    "    embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_layers[0]), input_length=1)\n",
    "\n",
    "user_latent = Flatten()(Embedding_User(inputs[:,0]))\n",
    "item_latent = Flatten()(Embedding_Item(inputs[:,1]))\n",
    "\n",
    "vector = tf.concat([user_latent[:,j:64], item_latent[:,j:64]], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_1_%d' %idx)\n",
    "    vector = layer(vector)\n",
    "\n",
    "vector_gmf = tf.keras.layers.Multiply()([user_latent[:,0:j], user_latent[:,0:j]])\n",
    "\n",
    "concat_layer = tf.concat([vector, vector_gmf], -1)\n",
    "\n",
    "click_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'click_prediction')(concat_layer)\n",
    "\n",
    "user_latent2 = Flatten()(Embedding_User2(inputs[:,0]))\n",
    "item_latent2 = Flatten()(Embedding_Item2(inputs[:,1]))\n",
    "\n",
    "vector2 = tf.concat([user_latent2[:,j:64], item_latent2[:,j:64]], -1)\n",
    "\n",
    "for idx in range(0, num_layer):\n",
    "    layer = Dense(layers[idx], kernel_regularizer= l2(reg_layers[idx]), activation='relu', name = 'layer_2_%d' %idx)\n",
    "    vector2 = layer(vector2)\n",
    "\n",
    "vector_gmf2 = tf.keras.layers.Multiply()([user_latent2[:,0:j], item_latent2[:,0:j]])\n",
    "\n",
    "concat_layer2 = tf.concat([vector2, vector_gmf2], -1)\n",
    "    \n",
    "buy_prediction = Dense(1, activation='sigmoid',use_bias=True, \n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         name = 'buy_prediction')(concat_layer2)\n",
    "\n",
    "outputs = tf.concat([click_prediction, buy_prediction], -1)"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(49393,))\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=5)\n",
    "# model.evaluate(x_test, y_test)\n",
    "model.predict(input_item[0])"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None,)]            0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [(None,)]            0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_28 (T [(None,)]            0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_29 (T [(None,)]            0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 64)           150603008   tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "user_embedding2 (Embedding)     (None, 64)           150603008   tf_op_layer_strided_slice_28[0][0\n",
      "__________________________________________________________________________________________________\n",
      "item_embedding2 (Embedding)     (None, 64)           150603008   tf_op_layer_strided_slice_29[0][0\n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 64)           0           user_embedding2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64)           0           item_embedding2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None, 43)]         0           flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None, 43)]         0           flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_30 (T [(None, 43)]         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_31 (T [(None, 43)]         0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 86)]         0           tf_op_layer_strided_slice_24[0][0\n",
      "                                                                 tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_14 (TensorFl [(None, 86)]         0           tf_op_layer_strided_slice_30[0][0\n",
      "                                                                 tf_op_layer_strided_slice_31[0][0\n",
      "__________________________________________________________________________________________________\n",
      "layer_1_0 (Dense)               (None, 20)           1740        tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None, 21)]         0           flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 21)]         0           flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_2_0 (Dense)               (None, 20)           1740        tf_op_layer_concat_14[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_32 (T [(None, 21)]         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_33 (T [(None, 21)]         0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_1_1 (Dense)               (None, 10)           210         layer_1_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 21)           0           tf_op_layer_strided_slice_26[0][0\n",
      "                                                                 tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "layer_2_1 (Dense)               (None, 10)           210         layer_2_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 21)           0           tf_op_layer_strided_slice_32[0][0\n",
      "                                                                 tf_op_layer_strided_slice_33[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 31)]         0           layer_1_1[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_15 (TensorFl [(None, 31)]         0           layer_2_1[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "click_prediction (Dense)        (None, 1)            32          tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "buy_prediction (Dense)          (None, 1)            32          tf_op_layer_concat_15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_16 (TensorFl [(None, 2)]          0           click_prediction[0][0]           \n",
      "                                                                 buy_prediction[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 602,415,996\n",
      "Trainable params: 602,415,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "# with strategy.scope():\n",
    "model4 = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model4.compile(optimizer=Adagrad(lr=learning_rate), loss='binary_crossentropy', \n",
    "              metrics=[\"accuracy\",\"mse\",tf.keras.metrics.RootMeanSquaredError()])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.9865 - mse: 0.2437 - root_mean_squared_error: 0.4937\n",
      "Epoch 2/100\n",
      "201/201 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 1.0000 - mse: 0.2364 - root_mean_squared_error: 0.4862\n",
      "Epoch 3/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 1.0000 - mse: 0.2304 - root_mean_squared_error: 0.4800\n",
      "Epoch 4/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 1.0000 - mse: 0.2248 - root_mean_squared_error: 0.4741\n",
      "Epoch 5/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 1.0000 - mse: 0.2194 - root_mean_squared_error: 0.4684\n",
      "Epoch 6/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 1.0000 - mse: 0.2143 - root_mean_squared_error: 0.4629\n",
      "Epoch 7/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 1.0000 - mse: 0.2092 - root_mean_squared_error: 0.4574\n",
      "Epoch 8/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 1.0000 - mse: 0.2043 - root_mean_squared_error: 0.4520\n",
      "Epoch 9/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 1.0000 - mse: 0.1994 - root_mean_squared_error: 0.4466\n",
      "Epoch 10/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 1.0000 - mse: 0.1946 - root_mean_squared_error: 0.4411\n",
      "Epoch 11/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 1.0000 - mse: 0.1898 - root_mean_squared_error: 0.4357\n",
      "Epoch 12/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 1.0000 - mse: 0.1850 - root_mean_squared_error: 0.4302\n",
      "Epoch 13/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 1.0000 - mse: 0.1803 - root_mean_squared_error: 0.4246\n",
      "Epoch 14/100\n",
      "201/201 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 1.0000 - mse: 0.1759 - root_mean_squared_error: 0.41 - 0s 1ms/step - loss: 0.5429 - accuracy: 1.0000 - mse: 0.1756 - root_mean_squared_error: 0.4190\n",
      "Epoch 15/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 1.0000 - mse: 0.1709 - root_mean_squared_error: 0.4134\n",
      "Epoch 16/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 1.0000 - mse: 0.1662 - root_mean_squared_error: 0.4077\n",
      "Epoch 17/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 1.0000 - mse: 0.1615 - root_mean_squared_error: 0.4019\n",
      "Epoch 18/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 1.0000 - mse: 0.1569 - root_mean_squared_error: 0.3961\n",
      "Epoch 19/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 1.0000 - mse: 0.1523 - root_mean_squared_error: 0.3902\n",
      "Epoch 20/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 1.0000 - mse: 0.1477 - root_mean_squared_error: 0.3843\n",
      "Epoch 21/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 1.0000 - mse: 0.1431 - root_mean_squared_error: 0.3783\n",
      "Epoch 22/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 1.0000 - mse: 0.1386 - root_mean_squared_error: 0.3723\n",
      "Epoch 23/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 1.0000 - mse: 0.1342 - root_mean_squared_error: 0.3663\n",
      "Epoch 24/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 1.0000 - mse: 0.1298 - root_mean_squared_error: 0.3602\n",
      "Epoch 25/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 1.0000 - mse: 0.1254 - root_mean_squared_error: 0.3541\n",
      "Epoch 26/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 1.0000 - mse: 0.1211 - root_mean_squared_error: 0.3481\n",
      "Epoch 27/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 1.0000 - mse: 0.1169 - root_mean_squared_error: 0.3420\n",
      "Epoch 28/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 1.0000 - mse: 0.1128 - root_mean_squared_error: 0.3359\n",
      "Epoch 29/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 1.0000 - mse: 0.1088 - root_mean_squared_error: 0.3298\n",
      "Epoch 30/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 1.0000 - mse: 0.1048 - root_mean_squared_error: 0.3238\n",
      "Epoch 31/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 1.0000 - mse: 0.1010 - root_mean_squared_error: 0.3178\n",
      "Epoch 32/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 1.0000 - mse: 0.0972 - root_mean_squared_error: 0.3118\n",
      "Epoch 33/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 1.0000 - mse: 0.0936 - root_mean_squared_error: 0.3059\n",
      "Epoch 34/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 1.0000 - mse: 0.0901 - root_mean_squared_error: 0.3001\n",
      "Epoch 35/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 1.0000 - mse: 0.0866 - root_mean_squared_error: 0.2943\n",
      "Epoch 36/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 1.0000 - mse: 0.0833 - root_mean_squared_error: 0.2887\n",
      "Epoch 37/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 1.0000 - mse: 0.0801 - root_mean_squared_error: 0.2830\n",
      "Epoch 38/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 1.0000 - mse: 0.0770 - root_mean_squared_error: 0.2775\n",
      "Epoch 39/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 1.0000 - mse: 0.0740 - root_mean_squared_error: 0.2721\n",
      "Epoch 40/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 1.0000 - mse: 0.0712 - root_mean_squared_error: 0.2668\n",
      "Epoch 41/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 1.0000 - mse: 0.0684 - root_mean_squared_error: 0.2616\n",
      "Epoch 42/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 1.0000 - mse: 0.0658 - root_mean_squared_error: 0.2565\n",
      "Epoch 43/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 1.0000 - mse: 0.0632 - root_mean_squared_error: 0.2515\n",
      "Epoch 44/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 1.0000 - mse: 0.0608 - root_mean_squared_error: 0.2466\n",
      "Epoch 45/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 1.0000 - mse: 0.0585 - root_mean_squared_error: 0.2418\n",
      "Epoch 46/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 1.0000 - mse: 0.0563 - root_mean_squared_error: 0.2372\n",
      "Epoch 47/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 1.0000 - mse: 0.0542 - root_mean_squared_error: 0.2327\n",
      "Epoch 48/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 1.0000 - mse: 0.0521 - root_mean_squared_error: 0.2283\n",
      "Epoch 49/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 1.0000 - mse: 0.0502 - root_mean_squared_error: 0.2241\n",
      "Epoch 50/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 1.0000 - mse: 0.0484 - root_mean_squared_error: 0.2200\n",
      "Epoch 51/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 1.0000 - mse: 0.0466 - root_mean_squared_error: 0.2160\n",
      "Epoch 52/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 1.0000 - mse: 0.0450 - root_mean_squared_error: 0.2121\n",
      "Epoch 53/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 1.0000 - mse: 0.0434 - root_mean_squared_error: 0.2084\n",
      "Epoch 54/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 1.0000 - mse: 0.0419 - root_mean_squared_error: 0.2047\n",
      "Epoch 55/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 1.0000 - mse: 0.0405 - root_mean_squared_error: 0.2013\n",
      "Epoch 56/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 1.0000 - mse: 0.0392 - root_mean_squared_error: 0.1979\n",
      "Epoch 57/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 1.0000 - mse: 0.0379 - root_mean_squared_error: 0.1946\n",
      "Epoch 58/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 1.0000 - mse: 0.0367 - root_mean_squared_error: 0.1915\n",
      "Epoch 59/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 1.0000 - mse: 0.0355 - root_mean_squared_error: 0.1885\n",
      "Epoch 60/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 1.0000 - mse: 0.0344 - root_mean_squared_error: 0.1856\n",
      "Epoch 61/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 1.0000 - mse: 0.0334 - root_mean_squared_error: 0.1828\n",
      "Epoch 62/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 1.0000 - mse: 0.0325 - root_mean_squared_error: 0.1801\n",
      "Epoch 63/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 1.0000 - mse: 0.0315 - root_mean_squared_error: 0.1776\n",
      "Epoch 64/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 1.0000 - mse: 0.0307 - root_mean_squared_error: 0.1751\n",
      "Epoch 65/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 1.0000 - mse: 0.0298 - root_mean_squared_error: 0.1727\n",
      "Epoch 66/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 1.0000 - mse: 0.0291 - root_mean_squared_error: 0.1705\n",
      "Epoch 67/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 1.0000 - mse: 0.0283 - root_mean_squared_error: 0.1683\n",
      "Epoch 68/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 1.0000 - mse: 0.0276 - root_mean_squared_error: 0.1662\n",
      "Epoch 69/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 1.0000 - mse: 0.0270 - root_mean_squared_error: 0.1642\n",
      "Epoch 70/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 1.0000 - mse: 0.0264 - root_mean_squared_error: 0.1623\n",
      "Epoch 71/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 1.0000 - mse: 0.0258 - root_mean_squared_error: 0.1605\n",
      "Epoch 72/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 1.0000 - mse: 0.0252 - root_mean_squared_error: 0.1588\n",
      "Epoch 73/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 1.0000 - mse: 0.0247 - root_mean_squared_error: 0.1571\n",
      "Epoch 74/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 1.0000 - mse: 0.0242 - root_mean_squared_error: 0.1555\n",
      "Epoch 75/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 1.0000 - mse: 0.0237 - root_mean_squared_error: 0.1540\n",
      "Epoch 76/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 1.0000 - mse: 0.0233 - root_mean_squared_error: 0.1526\n",
      "Epoch 77/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 1.0000 - mse: 0.0229 - root_mean_squared_error: 0.1512\n",
      "Epoch 78/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 1.0000 - mse: 0.0225 - root_mean_squared_error: 0.1498\n",
      "Epoch 79/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 1.0000 - mse: 0.0221 - root_mean_squared_error: 0.1486\n",
      "Epoch 80/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 1.0000 - mse: 0.0217 - root_mean_squared_error: 0.1474\n",
      "Epoch 81/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 1.0000 - mse: 0.0214 - root_mean_squared_error: 0.1462\n",
      "Epoch 82/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 1.0000 - mse: 0.0211 - root_mean_squared_error: 0.1451\n",
      "Epoch 83/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 1.0000 - mse: 0.0208 - root_mean_squared_error: 0.1441\n",
      "Epoch 84/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 1.0000 - mse: 0.0205 - root_mean_squared_error: 0.1431\n",
      "Epoch 85/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 1.0000 - mse: 0.0202 - root_mean_squared_error: 0.1421\n",
      "Epoch 86/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 1.0000 - mse: 0.0199 - root_mean_squared_error: 0.1412\n",
      "Epoch 87/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 1.0000 - mse: 0.0197 - root_mean_squared_error: 0.1403\n",
      "Epoch 88/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 1.0000 - mse: 0.0195 - root_mean_squared_error: 0.1395\n",
      "Epoch 89/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 1.0000 - mse: 0.0192 - root_mean_squared_error: 0.1387\n",
      "Epoch 90/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 1.0000 - mse: 0.0190 - root_mean_squared_error: 0.1380\n",
      "Epoch 91/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 1.0000 - mse: 0.0188 - root_mean_squared_error: 0.1372\n",
      "Epoch 92/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 1.0000 - mse: 0.0186 - root_mean_squared_error: 0.1365\n",
      "Epoch 93/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 1.0000 - mse: 0.0185 - root_mean_squared_error: 0.1359\n",
      "Epoch 94/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 1.0000 - mse: 0.0183 - root_mean_squared_error: 0.1353\n",
      "Epoch 95/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 1.0000 - mse: 0.0181 - root_mean_squared_error: 0.1347\n",
      "Epoch 96/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 1.0000 - mse: 0.0180 - root_mean_squared_error: 0.1341\n",
      "Epoch 97/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 1.0000 - mse: 0.0178 - root_mean_squared_error: 0.1335\n",
      "Epoch 98/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 1.0000 - mse: 0.0177 - root_mean_squared_error: 0.1330\n",
      "Epoch 99/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 1.0000 - mse: 0.0176 - root_mean_squared_error: 0.1325\n",
      "Epoch 100/100\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 1.0000 - mse: 0.0174 - root_mean_squared_error: 0.1321\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train, y_train, batch_size=200, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEaCAYAAADg2nttAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABvJUlEQVR4nO3dd3xT5f7A8c/JaNJ0J+keFEqZZZdVBMSi4mB7xaveq+J14b7Dvcd1/XDrdSEXx/XClQ0iUjZUoBQKZVOg0EVXutukSc75/RGJVgoddFD6vF+vvEpyRp5vD80355mSoigKgiAIgnAeqvYugCAIgnDxE8lCEARBaJBIFoIgCEKDRLIQBEEQGiSShSAIgtAgkSwEQRCEBolkIXRa//73v9FoNE065oUXXqB79+6tVCJBuHiJZCFcdG6//XYkSWLatGlnbVu6dCmSJDX5Q749bN++HbVazdChQ9u7KIJwwUSyEC5KUVFRrFixgvz8/Dqvf/rpp3Tp0qWdStU0n376Kffddx/Hjh0jLS2tvYuDoijY7fb2LobQQYlkIVyUYmNjGTFiBP/+97/dr506dYo1a9Zwxx13nLX/Dz/8wJAhQ9DpdAQFBTFr1iyqqqrc22VZ5tlnnyUoKAhvb29mzJhBSUnJWedZs2YNo0aNwtPTk/DwcO644w6Ki4ubXP6ysjLmz5/PPffcw4wZM/j000/P2ufYsWPccMMNGI1GDAYD/fv3Z8WKFe7tqampTJgwAV9fX7y9vRk2bBjbt28H6q8O27JlC5IkkZmZCfxazbZ+/XoGDRqETqcjKSmJEydOMG3aNMLCwjAYDPTr14+vv/76rPJ99NFH9OnTx/07nT59uvu9e/bsedb+M2fOJDExscm/K6FjEMlCuGjdfffdfPHFF5yZkeaLL74gMTHxrDuLvXv3MmnSJMaMGcOePXuYN28eK1as4N5773Xv88EHH/D222/z1ltvsWvXLoYMGcKLL75Y5zzr1q1j8uTJ3HTTTezdu5clS5aQmZnJtGnTaOqsON988w29evWiX79+3H777Xz77bd1ktfp06dJSEigtLSUZcuWkZ6ezssvv4xK5fqT3L9/P2PGjCEgIIB169axe/duHn30UWRZblI5ZFnm8ccf5+233+bQoUPEx8dTWVnJFVdcwapVq0hPT+fuu+/mjjvuYP369e7jnn/+eR5//HFmzZpFeno6P/74I4MHDwbgL3/5C8eOHWPjxo3u/SsqKliwYAF33313k8ondCCKIFxkbrvtNiUxMVGpqalRjEajsm7dOsXhcCjh4eHKwoULlblz5ypqtdq9/6233qoMHTq0zjmWLFmiSJKkZGZmKoqiKOHh4cpTTz1VZ5/p06fXOc/YsWOVxx9/vM4+J0+eVABl9+7diqIoyvPPP6/ExMQ0GMOAAQOU999/3/28Z8+eyueff+5+/swzzyjBwcFKZWVlvcffeuutSv/+/RWn01nv9vrKsXnzZgVQTpw4oSiKosydO1cBlE2bNjVY3kmTJil/+ctfFEVRlMrKSkWv1ytvvfXWOfefOHGicsstt7iff/LJJ4rZbFZsNluD7yV0TOLOQrho6fV6/vSnP/H555+zcuVKHA4HEydOPGu/M9/Cf2vs2LEoisKBAwcoLy8nJyeHhISEOvtcdtlldZ6npKTw7rvv4u3t7X706dMHgKNHjza63Nu3b+fgwYPcfPPN7tduu+22OlVRqampJCQk4OXlVe85UlNTSUxMdN9pXIjfN7BXV1fzxBNP0LdvX4xGI97e3vzwww+cPHkScP0+rVYrV1111TnPec8997Bw4UJ3Vd7nn3/ObbfdhoeHxwWXV7g4XfxdSoRO7e6772bw4MFkZWVxxx13oNVqW+29zlTZ/OlPfzprW0hISKPP8+mnn1JbW0twcLD7NUVRkGWZtLQ0Bg4ceMFlValUZ1WN1dd4rVar0ev1dV77xz/+wdKlS3n77bfp2bMnXl5e/O1vf6OsrKzR73/NNdcQFBTE119/zZgxY0hNTeXbb79tXjBChyCShXBR69OnD0OHDmXr1q11Grt/q2/fvmzatKnOaxs3bkSSJPr27Yuvry/h4eEkJydz3XXXuffZunVrnWPi4+PZv3//BY2jONOw/dFHH511t3P//ffz6aef8q9//YshQ4bw+eefU1VVVe/dxZAhQ1i7di2yLNd7dxEUFERBQQFOpxO1Wg3Arl27GlXGTZs2ccstt3DjjTcCriR55MgRd3Lr06cPer2en376if79+9d7DpVKxV133cXnn3/O4cOHGTNmTL2N3sIlpJ2rwQThLGfaLM6oqqpSiouL3c9/32axZ88eRa1WK4888ohy8OBBZdWqVUpkZKRy6623uvd5++23FS8vL+Wrr75Sjhw5ovzf//2f4u/vX+c869atUzQajfLoo48qu3fvVjIyMpRVq1YpM2fOVKqrqxVFabjN4sMPP1S8vb3d+//Wp59+qvj4+CiVlZVKbm6uEhgYqCQmJipbtmxRjh8/rixfvlz54YcfFEVRlL179yqenp7KTTfdpKSkpCgZGRnKggULlOTkZEVRFOXQoUOKSqVSnnrqKfe2rl27ntVm8dv4zpg+fbrSs2dPZfv27cr+/fuVO++8U/H19VXGjh3r3ufpp59WvLy8lA8//FA5fPiwkpaWpvzzn/+sc57c3FxFo9EoHh4eyjfffHPO34lwaRDJQrjo/D5Z/F59H4IrV65UBg8erHh4eChms1m599576zQeO51O5cknn1RMJpNiMBiU6dOnK2+//fZZ59m0aZOSmJioeHt7KwaDQenVq5fy8MMPK3a7XVGUhpPFgAEDlJtuuqnebYWFhYpGo3E3dB8+fFiZMmWK4uvrq3h6eir9+/dXVq5c6d5/+/btSmJiomIwGBRvb29l+PDhyvbt293b58yZo3Tt2lXR6/XKhAkTlO+++65RyeLUqVPKVVddpRgMBiUkJER57rnnlJkzZ9ZJFrIsK++++67So0cPRavVKkFBQcoNN9xw1rmmTJmiGI1GxWq1nvN3IlwaJEURK+UJgtA8w4YNY9SoUbzzzjvtXRShlYk2C0EQmqyoqIgVK1awa9cu/vvf/7Z3cYQ2IJKFIAhNFhgYSEBAAO+//z7dunVr7+IIbUAkC0EQmkzUXnc+YlCeIAiC0CCRLARBEIQGXbLVULm5uc0+1mw2U1RU1IKlufh1xpihc8bdGWOGzhl3U2MOCws75zZxZyEIgiA0SCQLQRAEoUFtVg2VlpbG3LlzkWWZxMREpkyZUmf7hg0b+PrrrzEajQBMmDDBvZDKhg0bWLRoEQDTpk3j8ssvb6tiC4IgCLRRspBlmTlz5vDMM89gMpl48skniY+PJyIios5+CQkJ3HnnnXVeq6ys5Pvvv+f1118H4IknniA+Ph5vb++2KLogCIJAG1VDZWRkEBISQnBwMBqNhoSEBFJSUhp1bFpaGv3793evL9C/f/+LYj1jQRCEzqRN7iwsFgsmk8n93GQy1buYzJlFY0JDQ7ntttswm81nHWs0GrFYLGcdm5SURFJSEgCvv/46ZrO52eXVaDQXdHxH1Bljhs4Zd2eMGTpn3C0Z80XTdXbIkCGMGjUKrVbLmjVr+Oijj3j++ecbffz48eMZP368+/mFdJETXew6j84Yd2eMGTpn3B2u66zRaKS4uNj9vLi42N2QfYaPj497FbTExESOHz9e77EWi+WsY1uKw+Fg69atlJaWtsr5BUEQOqo2SRYxMTHk5eVRUFCAw+EgOTmZ+Pj4OvucWcsXYOfOne7G74EDB7Jnzx4qKyuprKxkz549LbIsZX1c59/Lf/87H6fT2SrvIQiC0BG1STWUWq1m5syZvPrqq8iyzLhx44iMjGT+/PnExMQQHx/PqlWr2LlzJ2q1Gm9vb2bNmgWAt7c306dP58knnwTghhtuaLWeUBq1D0avBHJzN7JlyxbGjh3bKu8jCILQ0Vyyix81d7qP1J+r2HcgmbKqg1xzzTXExsa2cMkuTp2xPhc6Z9ydMWbonHF3uDaLjiK/spa5efkEeA/GxzuQpKSkOtVjgiAInZVIFr9hNmixSjIWL4UAz9GoVGqWLVtGdXV1exdNEAShXYlk8RtqlcQVMX6sLrOg1XrTs9uVVFVVsXTpUmw2W3sXTxAEod2IZPE7id38qEbGFiBTYQlg7OirKSoqYuXKlTgcjvYuniAIQrsQyeJ3gr09GBLhx9qKUrQeEiX5QSQmJpKdnc3q1auRZbm9iygIgtDmRLKox3V9g8muqsUvRkVJsRO9JobRo0dz7Ngx1qxZIxKGIAidjkgW9RgbY8KgVbGtooKgUA2H9tbQM7Y/I0eO5PDhw6xfv14sWC8IQqcikkU99Fo1o7v4kpxVQewAHUiwZ2cN8fHxDB06lP3797Np0yaRMARB6DREsjiH8TF+1DoVtuVX0meAJ0X5DrJO1DJixAgGDRrEnj17RMIQBKHTEMniHGJNenqa9fxvXzEhXTSYAtXs211DdZXMZZdd5p6zSiQMQRA6A5EszkGSJG4bFISlxsGKw6UMHO6FJMHubdUoCowePVokDEEQOg2RLM6jb5CBYRHeLDxQjEMt0z/eQEmxk6MHbEiSVCdhbNiwQSQMQRAuWSJZNOBPAwOxOmQW7CsmPMqDiC5ajh6wYilyuBPGkCFDSE9PZ926dSJhCIJwSRLJogFRfjoSu/mx6mgJpytqiRtiQG9QsevnKmprZSRJIiEhwd1LKikpSYzDEAThkiOSRSP8sb8ZtSTx5a4CtFqJISMNWGsU9uyoQVEUJEli5MiRDB8+nIMHD/LTTz+JxZMEQbikiGTRCCaDlpv6mdmeXcnPWRUEmDT0HqDndI6dzKO17v2GDx/OqFGjOHLkCD/++KNIGIIgXDJEsmikSb2NdA3Q8VlKPtV2J9166AgO03BgTw2lll8nGBwyZAhjxozh2LFjYvJBQRAuGSJZNJJGJXH/8BBKahx8nVaIJEkMHGbAQy+RmlxNbe2v7RQDBw7kiiuuIDMzk+XLl2O329ux5IIgCBeuzZJFWloaDz/8MA8++CBLliw5537btm3jxhtv5NixYwAUFBRwyy238I9//IN//OMffPbZZ21U4rPFmjy5vmcAq46UcqiwBg+diiEjvaiplknbXl2nJ1RcXBxXXnkl2dnZYj0MQRA6PE1bvIksy8yZM4dnnnkGk8nEk08+SXx8PBEREXX2q6mpYdWqVWetex0SEsJbb73VFkVt0M0DzPycVcH72/J455pojGYNfQZ6sn93DRmHbMT21rv37d27NxqNhtWrV7NkyRImT56MXq8/z9kFQRAuTm1yZ5GRkUFISAjBwcFoNBoSEhJISUk5a7/58+czefJktFptWxSrWQxaNQ+NDCWnvJZ5uwsA6BrrQViklkPpVooK6lY5xcbGcu2111JYWMiiRYvEEq2CIHRIbXJnYbFYMJlM7ucmk4mjR4/W2ef48eMUFRUxePBgli1bVmdbQUEBjz32GJ6entx000307t37rPdISkoiKSkJgNdffx2z2dzs8mo0mvMen2g2s6/YyYK0XBL7hDO8SwBXTJBZ/n0Wu7dZmXRjIF7ev/5qzWYzRqOR7777jqVLl3Lbbbfh6+vb7PK1hoZivlR1xrg7Y8zQOeNuyZjbJFk0RJZlvvrqK2bNmnXWtoCAAD7++GN8fHw4fvw4b731FrNnz8ZgMNTZb/z48YwfP979vKioqFllUZxOzEYjxWVl593vhp7e/HzCg1dWH+b967rio1MzaISezWsqWLMii4Rx3qjUknt/f39/Jk6cyPLly/n888+ZOnXqRZUwzGZzs39nHVlnjLszxgydM+6mxhwWFnbObW1SDWU0GikuLnY/Ly4uxmg0up9brVaysrJ48cUXuf/++zl69Chvvvkmx44dQ6vV4uPjA0C3bt0IDg4mLy+vVcqpFOUj/+3PWLeubXBfnUbFXxPCKLM6+HjHaRRFwcdXzcBhrvmj9qfVnHVMREQEU6ZMwWq1snDhQkpLS1shCkEQhJbXJskiJiaGvLw8CgoKcDgcJCcnEx8f795uMBiYM2cOH330ER999BGxsbE89thjxMTEUF5e7p4+Iz8/n7y8PIKDg1unoMZA0Gix7djcqN27GfXcMiCQ5FMVrM4oBSAs0oOYnjoyM2rJyqw965jQ0FCmTp2K3W5n4cKFWCyWloxAEAShVbRJNZRarWbmzJm8+uqryLLMuHHjiIyMZP78+cTExNRJHL934MABFixYgFqtRqVScdddd+Ht7d0q5ZRUKqQBQ6ndsRnJbkdqREP71D5G0vOrmZNaQC+zJ9EBenr111Na4mTvzmp8/VT4BdT9NQcFBTF9+nQWL17MwoULmTJlCoGBga0SkyAIQkuQlEt0mtTc3NxmHaek70R+/yVUDz2P1G9Io44ptTp4ZOUJvDzUzL4mGr1Ghc0qs+mnCiSVxJgrvfHQnX0TV1JSwuLFi7Hb7UyZMqX17pgaoTPW50LnjLszxgydM+4O12bRofTqj6T3RNmzvdGH+Os1/HVUGDnltXzyS/uFTq8ifpQXthqZ1J+rUeSzc3JAQADTp09Hp9OxePHiVmuLEQRBuFAiWfyOpPXAY9BwlD07UJow1Xj/EC9m9DOx/kQ5P2W4elIFmDT0G+Jav/tgurXe4/z8/Jg+fToGg4ElS5aQnZ3dInEIgiC0JJEs6qEbNhpKLXDyWJOOuzHOzKBQLz7bmc/RYldvqKhuOrrEeHDskI3cU2c3eAP4+Pgwffp0fHx8WLZsGadOnbrgGARBEFqSSBb10A1OAJUKJa3xVVEAapXEX0eFEaBX88amHMptrinK+w7yJMCkJm1HNeWl9U9b7uXlxbRp0/Dz82P58uVkZmZeaBiCIAgtRiSLeqh8/aB7nya1W5zhq1Pz+JhwSqxOZm/NxSkrqNUS8aO80GglUrZUUWurv3rLYDAwbdo0jEYjK1ascE+mKAiC0N5EsjgHaeBwyDmJUni6ycfGmjy5Z2gwaXlVfLOnEAC9p6vBu6ZGZte2+hu8ATw9PZk2bRqBgYGsWrWKjIyMC4pDEAShJYhkcQ7SwOEAKLuSm3X8Vd39uSbWn0UHLGzKLAfAaNbQb7AnhacdHNpXf4M3gE6nc3elXbVqFUeOHGlWGQRBEFqKSBbnIAWGuKqi1v+A0szlUe8cEkyfQE8+2JbHcYsrOXSJcTV4Zxw8d4M3uBLG5MmTCQ0NZfXq1Rw6dKhZZRAEQWgJIlmch+rqKVBcgJK6tVnHa9USj48Ox0en5rVN2ZRaXUusxg3yJMDsavAuKzl3IvLw8GDy5MmEh4ezZs0aDh482KxyCIIgXCiRLM6n/zAICUdZvZjmDnT399Tw1JgISq1OXt+Ug90po1JLxCd4ofWQSNlahe0cDd4AWq2WiRMnEhERwZo1azhw4EBzoxEEQWg2kSzOQ1KpkK6cAqeOweH0Zp+nu0nPwyNDOVhYw7925KMoirvB21Yjsyu5GvkcDd7wa8KIjIwkKSmJ/fv3N7ssgiAIzSGSRQOkkePAxw959eILOs9lXXy5qZ+JtcfLWHrINdNsgElD/3gDRQUODuw5d4M3uBYxmThxIlFRUaxdu1YkDEEQ2pRIFg2QtB5IV1wP+1JRck5e0Llm9DMzKsqHf+8qZHt2BQCRXT3oGuvBiSM2sk6cu8EbXAnj+uuvFwlDEIQ2J5JFI0jjrgUPHcrKBRd0HpUk8fDIULqb9MzekktGsetuos9AT0xBGvburKak2HHec4iEIQhCexDJohEkLx+kq6aipGxGOXZhXVh1GhVPj43AV6fmlY3ZFFbZUakkhiQY0Hmq2Lm1CmvN+Scw/H3CEI3egiC0NpEsGkmaMA38jMjzv2jSbLT1CfDU8Oy4SKx2mVc2ZFNtd6LTqRh2mRf2WoWdW6twOs/f++q3CSMpKUl0qxUEoVWJZNFIkk6PNPVPcOIISkrjll09ny7+Oh4bHcapMhtvbM7FISv4+qsZONy1hve+1JoGu+ueSRiRkZGsWbNGDNwTBKHViGTRBNLIcRAVg7JoHorNdsHnGxzmzaxhIaTlVfGvXxZNCov0ILaPjlMnasnMOH+DN/yaMM6MwxBTgwiC0BraLFmkpaXx8MMP8+CDD7JkyZJz7rdt2zZuvPHGOjOuLl68mAcffJCHH36YtLS01i/sOUgqFaob7wRLEcpPF9aV9owru/tzY5yJpGNlLNhXDEDPOD3BYRr2766hKN/e4DnOjMM4MzXI0aNHW6RsgiAIZ7RJspBlmTlz5vDUU0/xzjvvsHXr1npXhKupqWHVqlXExsa6X8vOziY5OZm3336bp59+mjlz5iBfYJvBhZB6xiHFX4bywwKUvKwWOefN/c2M6+rLf/YWkXSsFEmSGDTCCy8fFTuTq6mubHhuKq1Wy6RJkwgJCWH16tVienNBEFpUmySLjIwMQkJCCA4ORqPRkJCQQEpKyln7zZ8/n8mTJ6PVat2vpaSkkJCQgFarJSgoiJCQkHaftlv6412g80Se9wGK3LxJBuucT5K4f3goA0O9+Gj7aXbmVKLVSgwb7QXAji1VOOwNTzfi4eHBpEmT3NObnzhx4oLLJgiCAKBpizexWCyYTCb3c5PJdFZVyfHjxykqKmLw4MEsW7aszrG/vdMwGo1YLJaz3iMpKYmkpCQAXn/9dcxmc7PLq9Fozn+82UzNXx6l/L2XMGzfgNfEGc1+r996c0oADy5M580tuXwwvR99o33QTPBhzfJc9qc5uGJCCJIkNXiemTNnMm/ePFatWsXNN99M9+7dGzymwZgvUZ0x7s4YM3TOuFsy5jZJFg2RZZmvvvqKWbNmNfsc48ePZ/z48e7nRUVFzT6X2Wxu8Hil7xDoF0/lN/+iOqYPUlBos9/vt566LJTHfzrJ35bs4/Uro4jw09FngJ79aVUkb8ymZ5xno85z/fXXs2jRIr799lsmT55MRETEefdvTMyXos4Yd2eMGTpn3E2NOSws7Jzb2qQaymg0Ulxc7H5eXFyM0Wh0P7darWRlZfHiiy9y//33c/ToUd58802OHTt21rEWi6XOse1FkiRUt84CtQb53++1SHUUuGapfeGKSFQSPL8ui8IqO1176IiM9uDIfhu5WQ33kALQ6/VMmTLFvaZ3Xl5ei5RPEITOqU2SRUxMDHl5eRQUFOBwOEhOTiY+Pt693WAwMGfOHD766CM++ugjYmNjeeyxx4iJiSE+Pp7k5GTsdjsFBQXk5eU1qlqlLUhGM9If74GjB1BW/q/Fzhvq48EL4yKptsu8sC6LCpuTfvGeBJjUpG0//xoYv2UwGJg6dSpeXl4sXbqUgoKCFiujIAidS5skC7VazcyZM3n11Vd59NFHGTlyJJGRkcyfP5+dO3ee99jIyEhGjhzJX//6V1599VXuvPNOVKqLZ3iIauQ4pBGXoyz/L8qRlpunqZtRzzNjIyiosvPShmxsskz8qF/WwNhSic3auB5hXl5eTJ06FZ1Ox5IlSzrdbbggCC1DUpq7qs9FLjc3t9nHNrWeT7FWI7/8KDjsqJ57D8nLp9nv/Xs7sit4bVMOcUEGnh0XQXWZzNZ1lfgHqBl5uTcqdcMN3gBlZWV8//33yLLMDTfcQEBAQJ3tnbE+Fzpn3J0xZuiccXe4NotLnaQ3oLrr71BWijz3vQueO+q3hkX48PDIUPbmV/Pm5ly8/dUMHGbAUuQkfVfDU4Kc4efnx7Rp0wBYtGgRZWVlLVZGQRAufSJZtBApOhbphttgzw6UVd+36Lkv7+rHvUODScmp5L3kPEIitHTvrePU8VpOHG1cgzdAQEAAU6dOxeFwsHjxYiorK1u0nIIgXLpEsmhBUuIkpGFjUZZ+i5Ke2qLnvqZHAH8eGMimk+X8a8dpesTpCA7XsD+thsLTDU8JcobZbGbKlCnU1NSwePFiqqurW7ScgiBcmkSyaEGSJCH9+QEIj0b+4v9QCprfblKf6X1N/KGviTXHypiTWsCgYQZ8fFWkJldTWdH4rrvBwcFMmjSJiooKlixZgq0FJkUUBOHSJpJFC5N0OlSzngRJhfzRP1FqWvab+y0DzEzuFcDKI6V8u6+IoaO8kFSwY3MV9trGt5WEh4dz7bXXYrFYWLp0qUgYgiCcl0gWrUAKDEF1z2OQn4P82ZsozpYZsAeuu5c7BgdxTaw/iw9aWHLcQnyCF9WVMqk/VyPLje/cFh0dzYQJE8jPz+e7777D4Tj/kq6CIHReIlm0Eqn3AKSb74V9u1D++1mjey016tySxN1Dgxkf48eCfcWsOV1KvyGeFJ52cGCPtUnn6t69O+PHj+f48eP8+OOPOFswsQmCcOm4KOaGulSpxlyNXJCLsnoxBIchjZ/ccueWJO4fHoKiwHfpRaj6Q59YAyeO2PDxVdElRtfoc/Xu3RsPDw9WrlxJUlISV111VaMmLBQEofMQyaKVSdNuQynIQ1nwJUqAGWnIqBY7tzthoPDt3iJu6W8mKkRP+q4avH3UmIIaf3mHDx+OxWLh559/xsPDg8svv1wkDEEQ3EQ1VCuTVCpUd/4NYnohfzEb5dDeFj2/WiXxwPBQxnX15du9RWT6WjF4qUjZWkVVIxZN+q34+HiGDBlCeno6P//8c4uWUxCEjk0kizYg6XSoHngGgsKQP/4nyqnjLXp+tUriwRGhXNHNj+8OFJEf6OrZtGNzFfZGLJrkLqckkZCQQFxcHDt37iQ1tWXHigiC0HGJZNFGJC8fVA+/AJ4G5PdeQMlv2TEYroQRwpUxfvz3SDHFQbVUVcjs+rkKpQk9pCRJ4vLLL6dHjx5s3bqVffv2tWg5BUHomESyaEOS0YzqkRdBlpHffgaluGWnDFdJErOGhzAh1p8FmcWUmuwU5DnY38QeUiqViiuvvJLo6GjWrVvHkSNHWrScgiB0PCJZtDEpNBLVoy9CTQ3y28+ilJ69ROyFUEkS9w4NZlKvAP53uphyHwcnjtg4eaxpg+7UajXXXnstYWFh/PTTT2RmZrZoOQVB6FhEsmgHUlQMqoefh7ISV8KoaNkZYCVJYubgIP7Q18T/Soqo0jlJT62hKL/xc0iBa/3eiRMnYjKZ+OGHH8jJyWnRcgqC0HGIZNFOpJherkbvonzk2c+0SsK4dWAgtw4I5PuqImpUTlK2VjVpDikAnU7H5MmT8fHxYfny5WK1PUHopESyaEdSr/6oHnwWCvJaJWEA3BBn4s6hQSyzWahxyGzbVEmtrWnrbRgMBqZMmYKHhwdLly6lpKSkxcspCMLFTSSLdib1HlA3YZSXtvh7XNMjgL8kBPGTo4SqSpltW6qQnU2bfsTHx4epU6cCsGTJEioqKlq8nIIgXLzabFnVtLQ05s6diyzLJCYmMmXKlDrbf/rpJ1avXo1KpUKv13PPPfcQERFBQUEBjz76qHu5v9jYWO6+++4G368tl1VtCcrBPcgfvgymYFR/fQnJ39Ti75GSXcn3W4q5TPIjMFLN8JHe7lHajY25oKCARYsW4eXlxfTp0zEYDC1ezrYkltrsPDpj3B1uWVVZlpkzZw5PPfUU77zzDlu3biU7O7vOPpdddhmzZ8/mrbfeYvLkycybN8+9LSQkhLfeeou33nqrUYmiI5J6D3CNw7AUIb/5ZIt3qwUYGuHN7VcEso8qCrOc7EyravI5goKCmDhxIuXl5SxbtkxMbS4InUSbJIuMjAxCQkIIDg5Go9GQkJBASkpKnX1++w3VarV2ynmJpB5xqP76ElRVuBJGCw/cA+gdZOCPV5nIlmzkHbGzfV/Tl1Y9sxZGYWEhK1asEFObC0In0CYTCVosFkymX6tVTCYTR48ePWu/H3/8kZUrV+JwOHjuuefcrxcUFPDYY4/h6enJTTfdRO/evc86NikpiaSkJABef/11zGZzs8ur0Wgu6PgLYjZjf/lDSl58FN56Er/n30HbtUdLvwWhJhP/m38Sxz5I8XYwMaRpMZvNZjw8PFi4cCHr1q1jxowZqNXqFi1nW2jXa91OOmPM0DnjbsmY26TNYtu2baSlpXHvvfcCsGnTJo4ePcqdd95Z7/5btmwhLS2NBx54ALvdjtVqxcfHh+PHj/PWW28xe/bsBuvKO1qbxe8pednI7z4HNdWoHngWqUffFn+P4jI7636qwOlUMA4xcFWsZ5PPsWfPHjZu3EivXr248sorO9wd4cVwrdtaZ4wZOmfcHa7Nwmg0Ulxc7H5eXFyM0Wg85/6/rabSarX4+PgA0K1bN4KDg8nLy2vdAl8EpNAIVI+9AX4ByO8+j5K2vcXfw+SnZdwVPuhVKnJTK/l8Rz7OJswjBTBgwABGjBjBoUOH2Lx5c4su8iQIwsWjTZJFTEwMeXl5FBQU4HA4SE5OJj4+vs4+v00Au3btIjQ0FIDy8nJk2TUuID8/n7y8PIKDg9ui2O1OMgWieux1CO+C/PFryJtWt/h7mE1aRlzmhVHSUntM4bWNOdTYmzYOY+jQoQwcOJC0tLSz2qIEQbg0tEmbhVqtZubMmbz66qvIssy4ceOIjIxk/vz5xMTEEB8fz48//kh6ejpqtRpvb2/uv/9+AA4cOMCCBQtQq9WoVCruuusuvL2926LYFwXJxw/V315B/vRNlK8/Qi4tRpr4xxat7gkJ82DU5V4kbyik8nQVT685ydOXR2AyaBtXRkli9OjR2Gw2tm3bhk6nY8CAAS1WPkEQ2l+bjbNoax29zeL3FIcD5ZuPULauRRqViHTr/Uialsv1ZrOZTWuzOHbIxk4qOKW18fTYCLqb9I0+hyzL/PDDDxw/fpyrrrqKXr16tVj5WsvFeK1bW2eMGTpn3B2uzUK4cJJGg3TbQ0jX34SydS3y+y+iVDd9nMT59O6vJzRCSzw+hCsePLnmJMmnyht9vEqlYsKECURERLBmzRqOH2/ZRZ4EQWg/Ill0IJIkoZp8M9IdD8ORfchvPN6ig/ckSWLgcAP+RjUjFV/6+Rh4Y3Mu/00vQm7kDahGo+H6668nKCiIVatWnTX4UhCEjkkkiw5IlZDoGu1dUoz86t9Qjh1qsXNrNBLDRnuh16sYbvdlfKQf3+0t4s3NuVgdjWv49vDwYNKkSfj6+rJ8+XLy8/NbrHyCILQPkSw6KKn3AFRPvgl6T+T/exp5+8YWO7dOr2LYGC8UGeIqvbijfyDbsyt44qeT5FfWNuocnp6eTJ06FU9PT5YuXYrF0rKLPAmC0LZEsujApNBIVE/9H3TrgfLFbOTF36DITev2ei4+vmriL/OiukomqNCDp0eHU1Bp52+rMknLa1xbibe3N1OmTEGlUrF48WLKyxvf/iEIwsVFJIsOTvL2RfXoS0iXXYnywwLkf72GYq1ukXObgzQMGGaguNCJKlvFW1d3IcBTw4vrs1h0oLhRA/D8/f2ZMmUKDoeDxYsXU13dMmUTBKFtiWRxCZA0WqQ/P4B0092wNwX5tcdQClpmlHtEFw969deTc8pO+UmZN6+OZkSkD/N2F/Lmllyq7Q2vvGc2m5k0aRJVVVUsWbIEq9XaImUTBKHtiGRxiZAkCVXi9ageeRFKLciv/hVlX2qLnLt7Lx1dYjzIOGgj/6Sdxy4L47ZBgWzLquDvP57kVFnD05SHhoZy/fXXY7FYWLZsGbW1jWv7EATh4tDoZLFv3z73+sslJSV8+OGHfPzxx5SWlrZW2YRmkHoPQPXM22AMRH7/JeSVCy54viZJkogb7ElwmIb0XTXk5zqY1sfES4mRVNY6+cePmWw80fCSsFFRUUyYMIH8/Hz37MKCIHQMjU4Wc+bMQaVy7f7VV1/hdDqRJIlPP/201QonNI8UGILqiTeRho5GWfKNqx3jAgfwqVQSg0d64R+gJvXnKkqKHfQL9uKda6LpGqDn7eQ8/rXjNLXO8zewd+/enfHjx5OVlcWPP/6I09lwNZYgCO2v0cnCYrFgNptxOp3s2bOHe+65h7vuuosjR460ZvmEZpJ0eqS//A3pxjthzw7XeIzszAs6p3sMhqeKHZurqKxwYjJoeWV8FNP6GPnxaCmPrz5JXsX5q5h69+7N2LFjOX78OElJSWKmWkHoABqdLDw9PSktLeXAgQNERESg17vmDBJVCRcvSZJQXTkZ1d9eBVsN8mt/R962/oLOqdOrGD7GC4DtG6uwWWU0KonbBgXxzNgICqrsPPpDJpsyz99NdsCAAYwcOZLDhw+zYcMGkTAE4SLX6GQxYcIEnnzySd5//32uvvpqAA4dOkR4eHirFU5oGVKPvqiefReiY1HmvIP81Ycotc1fO9vbR82w0V7YrDLbN1XhsLs+6IdGePPutV3p4q9j9tZcPtyWh+08o77j4+MZMmQI6enpbN26VSQMQbiINWnW2dzcXFQqFSEhIe7nDoeDqKioVitgc11qs862BMXpRFn6DcqqhRDRFdW9jyMFu2aZbE7M+bl2UrZUYQrSMHy0Fyq1a9p0h6zw3d4iFu4vJtzXg79fFkbXgPpnr1UUhQ0bNpCens6IESMYNmzYhQXZRJfqtT6fzhgzdM64223W2bCwMHei2LdvH6WlpRdlohDqJ6nVqKbdhuqh56CkCPmVRy9ompDgMC394z0pyneQtqPafWegUUn8aWAgLyZGUmWX+fuPJ1l2yFLvZISSJHH55ZfTq1cvtm3bxu7du5tdHkEQWk+jk8Xzzz/PoUOuCeuWLFnCe++9x3vvvceiRYtarXBC65D6xbuqpcK7uKYJ+epDFFvzBspFddPRq59r0N7+NGudqqQBIV68f200g0K9mJNawEvrs7HUnN3GJUkS48ePJyYmhs2bN5Oent7c0ARBaCWNThZZWVn06NEDgLVr1/L888/z6quvsmbNmlYrnNB6JFMgqr//E+naP6BsWUPxP+5sdm+p7r11dI314MQRG8cO1W0L8dVreHpsOPcODWZ/QTUPrTzBz1kVZ53jzFoY0dHRrF+/noMHDzarLIIgtI5GJ4sz3xhPnz4NQEREBGazmaqqll2AR2g7kkaDauqfUD3yAkpFGfKrf0Nev7LJDc2SJNF3kCfhUVoO7rVy6rjtrO3X9AjgnWuiCfLS8PqmHN7/Oe+sqULUajXXXnstERERJCUlcfTo0QuOURCEltHodTl79uzJl19+SUlJCUOHDgVcicPHx6dRx6elpTF37lxkWSYxMZEpU6bU2f7TTz+xevVqVCoVer2ee+65h4iICAAWL17MunXrUKlU3HHHHQwcOLCxxRYaQeozCOM7X1E4+3mU/3yKsn83qtseRPLxa/w5JImBwwzU1laxZ2cNWg+J0AiPOvtE+Ol446po/ptexKIDxaTnV/HQyFD6BXu599FoNEycOJElS5awevVq1Go13bp1a7FYBUFonkbfWdx///0YDAa6dOnCjTfeCLh6HF177bUNHivLMnPmzOGpp57inXfeYevWrWetoHbZZZcxe/Zs3nrrLSZPnsy8efMAyM7OJjk5mbfffpunn36aOXPmILfQNNzCr1T+RlQPPos0407Yvwv5xYeaPLeUSi0Rn+Aa5b3r52qKCuxn7aNVuxq/X7uyC2qVxDNJWXyRml+ni61Wq2XSpEkEBgbyww8/cPLkyQuOTxCEC9PoZOHj48PNN9/MjTfe6B6QN3jwYK677roGj83IyCAkJITg4GA0Gg0JCQmkpKTU2cdgMLj/bbVakSRXN8yUlBQSEhLQarUEBQUREhJCRkZGY4stNIGkUqEaPxnV07PB2xf5vReR//t5k8ZkaLQSw8d4YfBWkbK5ilJL/YM2ewV68u61Xbkm1p/lh0p45IdMDhXWuLfrdDomT56M0WhkxYoVZGVlXXB8giA0X6OThcPhYMGCBTzwwAPccsstPPDAAyxYsKBRI7gtFgsmk8n93GQy1bty2o8//siDDz7It99+yx133FHvsUajUay61sqkiK6onp6NlDgRZe1y5Ff+inLyWKOP99CpGDHWG62HxPZNVVSU1z//k16j4t5hIbycGIlDlnlyzUnm7ipw32Xo9XqmTp2Kn58fy5cvJycnp0XiEwSh6RrdZvHNN99w7Ngx7rrrLgIDAyksLGThwoVUV1dz++23t0hhJkyYwIQJE9iyZQsLFy7kgQceaPSxSUlJJCUlAfD6669jNpubXQ6NRnNBx3dE9cb8wJPYLkuk/INXkF/7O14z7sRr2q1I6sb9t7lmqj+rFuWwY3MN100Nx9tXW+9+V5jNDO8RzkebM1my7zSpedU8OT6WAeGuNpO//OUvfPnllyxfvpw///nPLTq2R1zrzqMzxt2SMTc6WWzbto233nrL3aAdFhZG165d+cc//tFgsjAajRQXF7ufFxcXYzQaz7l/QkICn3/+eb3HWiyWeo8dP34848ePdz+/kJGaYqTnb0R0g+feQ/r2E6r+8xlVP29ANfMRpJCIRp136GgDP6+v5IfFWYxK9EanP/fN7MwB/gwJ1vLR9tPc/3061/bw59aBgRi0aiZNmsSiRYuYN28eU6dOdQ8OvVDiWncenTHudhnBfSHz9sTExJCXl0dBQQEOh4Pk5GTi4+Pr7JOX9+vKbrt27SI0NBRwzR+UnJyM3W6noKCAvLw8unfv3uyyCE0nefmguvsfSHf/AwrykF96BDlpWaPW+/YLUDNsjBfWGpltGyqptZ3/mAEhXrx3bVeu7RnAD0dKeXDFCXbmVOLt7c3UqVPx9PRkyZIl5Ofnt1R4giA0QqPnhvr3v/9NRkYGN9xwgztbLVy4kG7durnbF85n165dzJs3D1mWGTduHNOmTWP+/PnExMQQHx/P3LlzSU9PR61W4+3tzcyZM4mMjARg0aJFrF+/HpVKxe23386gQYMafD8xN1TTNDZmpdSC/NWHkL4TevRFddtDSEGhDR5XeNrOjs1V+PqrGXm5Nxqt1OAxhwpr+GBbHtnltYyJ9uXOIUGo7TUsXLgQm83G1KlTCQoKalR85yKudefRGeNuyTuLRicLh8PBwoUL2bJlCyUlJRiNRhISErjhhhvQaBpdm9VmRLJomqbErCgKSvI6lPlfgNOBNO02pHHXIqnOf6N6OsfOzq1VBJjVDB/jjUbTcMKwO2W+31/M9/uL0WtU3DE4iKFmicWLF7dIwhDXuvPojHG3WbLYt29fva8riuLu2goQFxfX6MK0FZEsmqY5MSuWIuSvP4J9qRDbx3WXEXzu/2wAOSdr2bWtmsAQDUMv80KtbjhhAGSV2fh4+2kOFNYQF+TJn/p48fNPy6mtrb2ghCGudefRGeNus2Rx//3313/QL4niTNL48MMPG12YtiKSRdM0N2b3XcaCL8BuR5pyC9L4SUgq9TmPOXXcxp6UGoLDNMQn/Dq1eUNkRSHpWBnzdhdgdchM6qrDeXAD9gtIGOJadx6dMe52qYbqaESyaJoLjVkpLUb+5l+wZwdEx6K67QGkiK7n3D8zw0Z6ag2hEVoGjzSgUjUuYQCUWh3M3VXAhhPlROjt9C9JAaedKVOmEBwc3KRyi2vdeXTGuNttPQtBOBfJ34Tq/qeR7vo7FBcgv/JX5CXfoNjrX487uruOPgP15GXbSdtejSI3/juLv17DowlhvJwYCR5erPMYRI2iZtHixe6JLgVBaFkiWQgtRpIkVMPGoHrpI6RhY1BWLkB+6WGUw/W3fcX01NO7v2stjN07mpYwAPqHePHutV25cUgUqT7xlDvV/G/hIk5mZTd8sCAITSKShdDiJG9fVDMfRfXIi+BwIP/fU8jzPkCpOnsdi+699fTspyfnpJ20lKYnDK1aYnpfE29P6Qu9xlGpeLBoyVLWponpzQWhJYlkIbQaqe8gVC98iHT1VJTktcjPzkLetuGsAZ49+ujpGacnO9POnp01zRoAGuil5fHE7iReNxmHxpO9m1bzz2U7ySmvvxpMEISmEclCaFWSTofqhjtQPf02mINR5ryN/M5zKPl1OyD06KunR18dWSdq2bOjpsl3GGcM6xrIPX+6Cb23H4bMn3lx0Tb+vavgrIWWBEFoGpEshDYhRXVD9cQbSDffC5lHkV94AHnpf+o0gPeM86RHXz1ZmbWkNaMN4wxfbwN33PwHAgMDiavYw9a0A9y77Dg/ZZTibOY5BaGzE8lCaDOSSo1q3LWoXvoYafAolBX/RX7+gTqLLPWM+6VK6qSr0Vtu5oe7Xq/nhmlTCQsNpV9VOjHOPD7afpq//ZhJer5YClgQmkokC6HNSf5GVHf9DdVfXwa1Gvm9F3F+/E+U4gLAVSXV65dG713bmp8wziygFBUZScDpNP4cWkqlzckzSVn8c2M2uaI9QxAaTSQLod1IvQegeu59pGl/hv27kZ+bhbxyAYq9ltg+etc4jCw7O5OrcDqblzC0Wi3XX389MTEx5OzbwcyQIm7tb2bP6WoeXHmcdzcep9wm2jMEoSEiWQjtStJqUV1zA6qXPoa4eJQl37iqpvakENNTT9xgT/JzHKRsqcLhaF7C0Gg0XHPNNfTu3ZudKTsILjnAvyZ25Ypufizck8u9S4+x6EAxtU6xtrsgnItIFsJFQTIFor7vCVSPvgRqDfKHL+N8/yWifYoYMNSTwtMOtm+qxG5vXsJQqVSMHz+egQMHkpaWxs4t67k3Poh5twyiV6An83YXMmvZcdYfL0O+NGfAEYQLIpKFcFGR+gxE9fz7SH+4A47uR37hQSJSv2XwYDUlRc5GLaB0znNLEqNHj2bEiBEcOnSIlStXEunrwXPjInk5MRJfvYZ3f87jr6sy2ZVbeUELfgnCpUZMJFgPMeHYxUEpL0FZ9DVK8lrw9qVgwgPsKuuJl4+KEWO90Xs2/7vO3r172bBhA1FRUUyYMAG9Xo+sKGw5WcE3ewrJr7QTF2zgtoGB9DB7tmBU7e9ivNZtoTPGLWadbQSRLJrmYo5ZyTyKPP8LyDhIUY8rSI3+MzpPDSPGeuHlc+6p0Bty5MgR1qxZg5+fH5MnT3avL293KqzOKGFBejFlNicjI725ZUAgkX66lgqpXV3M17o1dca4RbJoBJEsmuZij1lRFJSdW1G+n0upw5uU+CdQ6XQMH+eHX0DzE0Z5eTnffvutu5utyWRyb6u2O1l2sIQlBy3YnDKXd/Xjj/3MBHlrWyKkdnOxX+vW0hnjFlOUC52OJEmohl6G6uWPCUi8jJG7XkeqKCV5dTFFmWXNPm+3bt244YYbkGWZ77//npycHPc2g1bNTf3NfDa5GxN7BrA5s5z7lh/j05TTWGocLRGWIHQYbXZnkZaWxty5c5FlmcTERKZMmVJn+4oVK1i7di1qtRpfX1/uu+8+AgMDAZgxYwZRUVGAK1M+/vjjDb6fuLNomo4Ws1JeQvXSJWy3D6fGM5CBXgcJmzAcyaNpVUVn4i4vL2fp0qWUlZVx1VVX0aNHj7P2Laq2syC9mKRjpahVEtf2CGBaHyN++otvDfrz6WjXuqV0xrg7XDWULMs8/PDDPPPMM5hMJp588kkefvhhIiIi3Pvs27eP2NhYdDodP/30E/v37+fRRx8F4E9/+hNff/11k95TJIum6agx2zKz2LG5klJtMH2zFhE9qhvSiLHnXdb1t34bt9VqZcWKFeTm5jJq1CgGDx5cZ635M/IqapmfXsTGzHI81BLX9QhgSh8TvrrmV4e1pY56rS9UZ4y7w1VDZWRkEBISQnBwMBqNhoSEBFJSUursExcXh07n+lYYGxuLxWJpi6IJHZwuOpKRf+xFsJ+V/VE3cHBTDs6X/4qSntrkrq96vZ4pU6bQvXt3tm7dyoYNG5Dls7vphvp48EhCGB9c15Wh4d4sOmDh7iXH+CatkAoxGly4RLXJ/bPFYqnTcGgymTh69NyL06xbt46BAwe6n9vtdp544gnUajWTJ09m2LBhZx2TlJREUlISAK+//jpms7nZ5dVoNBd0fEfU0WOecIuZnzcWcISJ2EojiPvgVfR9+uF967149Op3zuPqi/vWW28lKSmJLVu2YLVaufHGG91fZH7LbIaBMeEcL6pi7o4s/re/iJVHS/nDgDBmDArDz/PibAjv6Ne6uTpj3C0Zc5tUQ23bto20tDTuvfdeADZt2sTRo0e58847z9p306ZNrF69mhdeeAGt1vXHZrFYMBqN5Ofn89JLL/Hss88SEhJy3vcU1VBNcynErCgKGYdsHNprxagtY/C21/AoyYWBw1FNuRUpvMtZx5wv7n379rF+/XqMRiMTJ07E19f3vO+fWWJl/r5ikk9VoNeouL5nAJN7BeB7kbVpXArXujk6Y9wdrhrKaDRSXFzsfl5cXIzRaDxrv71797J48WIee+wxd6I4czxAcHAwffr0ITMzs9XLLHQ8kiQR21vPoBEGSp1+/DzmDaon3QWH05FffAj5i9koBXmNPl9cXByTJ0+moqKC+fPnk5d3/mOjA/Q8Pjqc96/rSny4Fwv3F/OXJceYu6tA9J4SOrw2SRYxMTHk5eVRUFCAw+EgOTmZ+Pj4OvucOHGCzz//nMceeww/Pz/365WVldjtdsDVJ/7w4cN1GsYF4fciungw4nJvau2w1TGGkr9/hnT1NJTdP7tmtv3qQ5TiwkadKyoqihtvvBEPDw8WLVrE4cOHGzymi7+Of1wWzgfXd2VkpA/LDrnaND5NOU1Bpf1CwxOEdtFmXWd37drFvHnzkGWZcePGMW3aNObPn09MTAzx8fG8/PLLnDp1Cn9/f+DXLrKHDx/ms88+Q6VSIcsy1113HVdccUWD7yeqoZrmUoy5qsLJ9s1V1FTJ9I83EBFQifLD/1A2rwZAGn0VplvvoUQ+u8fT79XU1PDDDz+Qk5PDkCFDGDlyJCpV475r5VXU8v3+YjacKENRYGxXP6b3MRLRTiPCL8Vr3RidMe4O13W2PYhk0TSXasy1NpnU5GqKChzE9NTRu78eSopQVs53zTmlUiONuRppwnQk/7OrRn/L6XSyadMm0tPTiY6O5uqrr6634ftcCqvsLD1oYXVGKXanwohIH6b3NRJratu5py7Va92Qzhi3SBaNIJJF01zKMcuywv7dNWRm1BIUqmHwCC+0HhJK4Wk81i7Duv4HUGt+SRrTkPxN5z3f3r172bRpE35+flx33XX1tr+dT5nVwfJDJfxwpIQqu0z/EAPT+5gYEGKod1xHS7uUr/X5dMa4RbJohN8nC0VRsFqtyLLc4B+kTqfDZrO1ZvEuCoqioFKp0Ov1BAYGXvJ/SJkZNvbtqsHgrWLoZV74+Koxm80UHtznutP4eb3rTmP0la47DWPgOc+VnZ3NqlWrcDgcXHXVVcTExDS5PNV2J6uPlrL0UAklNQ66BuiY1sfEqCgf1KrWSxqd8UMTOmfcIlk0wu+TRU1NDVqtFo2m4W6MGo0Gh6Nz9F5xOBzY7XYiIyM7xR9SUYGD1OQqZKfCoBFexA0IdcetFJ5GWfW9q3oKCSnhClfSCAqt91wVFRWsXLmSgoIChg4dyvDhwxvdjvFbdqfMxsxyFh+wkF1eS5CXhkm9jCTG+GHQtvyo8M74oQmdM26RLBrh98miqqoKLy+vRh3bmZIFuH43Xbp06TR/SNVVMju3VlFW4mRgfAARXWWk33yTV4oLUVYvRNm8BpxOpGGjka65od5xGg6Hgw0bNnDgwAGioqK4+uqr8fRsXhuErCik5FSy5ICFA4U1eHmouLq7P9f1DMBsaLkBfp3xQxM6Z9wiWTTC75NFdXU1BoOhUcd2tmRRXV1NVFRUp/pDcjoU9qZWk51pJzBEw+ARBjx0de8KlFILypolKBt/BJsVBgxDdc0NSDG96u6nKOzfv5+NGzfi6enJtdde2+Cg0YYcLqphyUEL27IqkIDRXXyZ1NtIjFF/QeeFzvmhCZ0zbpEsGkEki8brjMkCXB/yxfkebN9ciE4vET/KC3/j2dWUSmU5yrqVKOtWQFUF9OiLasJ0iBtSp/2roKCAH374gcrKSkaPHk3//v0vuME6v7KW5YdLWJNRhtUh0zfIk4m9jAwL9252u0Zn/NCEzhm3SBaNcDEmi/DwcKZNm8YHH3wAuKowBg0axKBBg7juuuv44osvADh69CgxMTGoVCrGjRtHTEwMr7zyCiEhIdhsNm699VbuvvtuwDVJ4xNPPEFZWRm1tbUMHz6cN998s0nl6qzJAlx/TEcPn2ZnchW1VoU+Az2J7u5R74e8Yq1B2fITypqlYCmC8C5IV01BGjYGSeOqJrJaraxZs4YTJ04QExPD+PHjm9S99lyqap0kHStjxeESCqrsBHlpua6nP+Nj/PH2aFq7Rmf80ITOGbdIFo1wMSaL2NhYoqOjWbZsGZ6enqxbt47XXnuN0NBQvvrqK/d+w4cPZ9WqVe4umfPnz2fv3r28+uqrWCwWxowZw+rVqwkPD+fmm2/mtttu4+qrrwbg4MGD9O7du0nl6uzJoqioiFqbzO7t1RTkOQiN1DIg3oDWo/5v7orDgbJjE8pPiyHnJPgbkRInurreGrxRFIXdu3eTnJyMt7c3EyZMuOBqqTOcssKO7EqWH7awv6AGnVpiXDc/rusRQJR/45JSZ/zQhM4Zd0smi4trhrM2Iv/3c5SsE+feLklNnt5aiuyK6qa7GtzviiuuYO3atVx//fUsWbKEKVOmsH379ka/j9FoJDo6moKCAsLDwykoKCA09NfeOk1NFIKLh07FsNFeHDtk41C6lTJLBYNHGggwnf0nImk0SAlXoIwcB/t3Ia9ejLJwHsqK+UiXXYmUOJHBgwcTGhrKjz/+yPfff8/IkSPPuT5GU6hVEiOjfBgZ5cNxi5Xlh0tYe6yMH4+W0j/YwLU9AhgW0fwqKkE4F7GsahubPHkyS5cuxWq1cvDgQQYNGtSk43NycrDZbO6kcNddd3HjjTdy66238tlnn1FW1vwlRjs7SZLo3ltPwjjX3cHWtZVkHLSe84uDJElIcUNQ/+0VVM++izR4JMqGVchP34Pzo38SUlHMH//4R7p168bWrVtZsmQJlZWVLVbebkY9D48M5cupMfxpYCC5FbW8vjmHu5YcY356ESVi8kKhBXXKO4uG7gBas4G7T58+ZGdns3Tp0kbNcXXGsmXL2L59OxkZGbzyyivo9a5eMTNmzGDs2LFs2LCB1atX880337BmzZoWqSfvrIyBGsZc7cPelBoO7rVSmO9g4DADnoZzf7eSorohzXwUZdqfUdavQtm0CjltG9rIrlx9xfVEjh3D5q3J/Oc//yExMbFZg/jOxVev4Ya+Jqb2NrIzp5Ifjpbyn71FzE8vYkSkDxNi/ekX3Dajw4VLl7izaAdXXXUVL7300lnrkJ/PpEmTSEpKYunSpbz22msUFBS4t4WEhHDTTTcxd+5cNBpNo2ZGFc7Pw0PFkAQD/eM9KSlysHF1BblZtQ0eJ/mbUE29FdUbXyL96X6QZZj3AX3+/RYzTJ74GgysXLmSpKQkamsbPl9TqFUSwyN9ePGKSD6e2I3regaw53QVz67N4v4VJ1h60EK5WMlPaCaRLNrBjBkz+Otf/9qs9oUBAwYwffp05syZA8D69evdU7gXFBRQUlLSYo2pnZ0kSXSJ0THmah+8vFWkJleze3sV9tqzl1o961gPHaoxV6N6/n1Uf3sFuvfFf+1Spm1eyGDJxoEDB/jPf/5DTk5Oq5Q93NeDO4cE8+XU7jw8MhRvDxVf7ipg5qIMXvzxMPvyq5vcLid0bp2yGqq9hYWF1btKYGPNmjWLCRMm8OCDD7Jx40aee+45d7XTM888Q1BQUEsVVQC8fdSMSvTmyH4rGQdtFP1SLRUY0vCoakmSoFd/1L36oxQXIG1cxcjNa4iWJZK6DGDhwoUMjOtLwpixjZqKpql0GhVXdPPjim5+ZJZY+fFoKZtOWPjpsJMwHw+u7O7HFV398PcUHwXC+Ymus/UQg/I6j6Z2LSwpdpC2vZrKCpkuMR70GeCJRtu0tgDFXouSuhXbhh/5uUZmnykSf0lh/IhhhMaPaPW2BW+/AJbtzuSnjFIOFtagliA+3JsrY/wZHOZ1yfakEl1nGybGWSCSxfmIZNG0uJ0OhUPpVo4fseFpkOgfbyAotHlzNylZJziVtJJ1lmoqNDoG2EoZMXAAHqMSkbx8mnXOhvw25qwyG0nHylh/vIwym5MATw3juvqS2M2v3RZnai0iWTRMJAtEsjgfkSyaF7elyMGeHa67jMhoD/oM1J81v1Rj2crLSF6xlPSiUnxrq7n8dAZRPXsjXTYeevZDasZstudSX8x2p8LO3ErWHisjNbcSWYGeZj3juvoxuosv3rqWn/22rYlk0TCRLBDJ4nxEsmh+3E6nwpH9Vo4dsqH1kOg7yJPwKG2zq5JycnJYu/pHSiur6FlRwKisg3gGGJFGJSKNTEQynXuNjcZqKOaSGgcbTpSx/ng5J8tsaFUSQyO8GdfVl8Fh3mg6aDWVSBYNuyiSRVpaGnPnzkWWZRITE8/qNrpixQrWrl2LWq3G19eX++67j8BA1x/Ghg0bWLRoEQDTpk3j8ssvb/D9RLJoPJEsLjzu8lIne1KqKbU4CQzR0G+wJ14+zfs27nA4SElJITU1FQ+VRIKthF4Hdrgby6WERKRBI5GaOZamsTErisLxEhvrjpexObOcMpsTX52a0V18GNvVjx4mfYcauyGSRcPaPVnIsszDDz/MM888g8lk4sknn+Thhx8mIiLCvc++ffuIjY1Fp9Px008/sX//fh599FEqKyt54okneP311wHc//b29j7ve4pk0XgiWbRM3IqskJlRy6H0GmQZuvfW0b23HrW6eR+oxcXFrF+/ntzcXMICzYzVOjGmboKifNB5IsUnII28AmL7NqmaqjkxO2SF3blVrD9RRkpOJbVOhVAfLWOifRnTxbdDtG+IZNGwdp8bKiMjg5CQEIKDgwFISEggJSWlTrKIi4tz/zs2NpbNmzcDrjuS/v37u5ND//79SUtL47LLLmuLogtCo0kqia49dIRGatmfVsOR/TayM+30HeRJcJimyd/CTSYT06dP58CBA2zdupX/2mwMmHArw0x+eOzchJK6FWXrWjCakYaPRRo+Dik8qlVi0/xSFTU0wpuqWic/Z1Ww8UQ5C9KLmZ9eTIxRx2VdfBndxZdAr5ZbqEm4eLRJsrBYLJhMJvdzk8nE0aNHz7n/unXrGDhwYL3HGo1GLBbLWcckJSWRlJQEwOuvv47ZbK6zPT8/v0n92Fujzzu4Bs4999xzpKam4u/vj1ar5YEHHsDPz49p06Yxe/Zsbr31VsB1t5WYmMjzzz/PrFmzeOihh0hOTsbX1xeAP/7xj9x1V8OTFzZEp9Oh0WjO+p11Bq0Vd0Qk5GZVs21zISlbqgiPMjB8tBk/f48mn2vs2LEMHTqUpKQkUlNTyfDy4sorp9L/gSep3bEZ66bV1K5egrJqIZroWPRjrkR/2XjUgfUPzrzQmM1Al7BgbhoOhZU21h0tYs3hQubtdj36h/pyRQ8z42LNmL2aHm9r6Yz/x1sy5otuJM6mTZs4fvw4L7zwQpOOGz9+POPHj3c///2tl81mQ61uXB1ya1VDKYrCbbfdxh/+8Ac+/PBDALKzs/npp5/w9vamV69eLF26lJtuugmAhQsX0qdPH2RZxuFwIMsyzzzzDNdff737nC1RTpvNhsPh6HS36NC6VRMennDZeAMnjto4sq+axd+domt3HbF9dXh4NL13U0JCAt27d2fDhg0sXryYrVuDGDNmDGH3PomqvBQlZTOO7Rup/OpjKr/6GLr3cS0JOyQByTfAfZ6WjFkCEiN1JEZGkFdRy5aT5Ww+WcG7G4/z3sbj9A3yJCHKl5FRPhjbeeCfqIZqWLtXQxmNRoqLi93Pi4uL3Ws1/NbevXtZvHgxL7zwAlqt1n3sgQMH3PtYLBb69OlzQeX5Ymc+J0qs59wuNWOK8q4Bev4SH3zefbZs2YKHhwd//vOf3a9FREQwc+ZMkpOTCQ8Pp7KyksLCQsxmM+vXrycxMbFJ5RAuLiqVRExPPeFRHhze5xqbkZVZS8++errEeKBqYntGUFAQf/jDHzh8+DBbt27l+++/p3v37iQkJOCfOBESJ6IU5LnW20jZjPKfT1G++xx69UOKH4U0aCS00rfrUB8P/hBn5g9xZrLKbGw9WcHmk+V8tjOfz3fm0zvQk4RfpldvyTXFhbbRJskiJiaGvLw8CgoKMBqNJCcn89BDD9XZ58SJE3z++ec89dRT+Pn5uV8fOHAg3333nXtq5z179nDzzTe3RbFb3JEjR+q0zdTnuuuuY8WKFcTFxdGvXz88POrexr/yyiu89957ALz//vti/YoOQu+pYsBQA9HddRxIq2Hf7hpOHLXRq7+e0IimdbWVJIlevXoRExNDamoqu3bt4vjx4/Tv359hw4ahDwpFun4GXD8DJeekK2mkbEH5+mOUbz+hJG4wcr+hSINH1LnjaEmRfjpu6q/jpv5mTpXZSD5VQfLJCr5ILeCL1AJ6mPSMjPRhRKQPYb4XT1WVcG5tkizUajUzZ87k1VdfRZZlxo0bR2RkJPPnzycmJob4+Hi++eYbrFYrb7/9NuC6fXr88cfx9vZm+vTpPPnkkwDccMMNDfaEakhDdwBt1RvqqaeeYseOHXh4ePDMM88AMHHiRO677z4yMjKYMmUKO3furHPM76uhhI7FL0DNiMu9KMhzcHBvDanJ1fgb1fTqrycwuGnftrVaLSNGjCAuLo7t27ezZ88eDhw4wJAhQxg4cCBarRYpvAtSeBeUybdAdibKzi04d29D+fZfKP/5BGL7uLrhDhrZImM46hPlpyOqn46b+pnJLrex7VQlyVkVzEsrZF5aIVF+HgyP8GF4pDfdjR2rO25nIgbl1aO1ksXmzZt59913Wbhwofs1i8XCNddcwzvvvMMnn3zCV199xYwZM8jNzWXDhg28++67eHl5ce+99/LII48wfvz4Fk8Wouts+8StyArZJ2s5tM+KtVrBFKShVz89RnPzvsMVFxeTnJzMiRMnMBgMDBs2jL59+57VVmcymSjak4qSmoyy+2fX0rAAXbojDRqBNHAEhEW2+od2YZWdbVkVbMuq4EBhDbICJk8NwyK8GRbhTb9gA1p1645cv9R1uDYLweWyyy7jjTfeYN68edx2220A1NTUnLXf3//+d4qLixvdIC90TJJKIrKrjrAoD04eq+XoAStb11YSFKqhR199vUu6no/JZGLixInk5uaSnJzMhg0bSE1NZdiwYfTq1cv9/0mSJKSIaKSIaJh8M8rpHJTd21B2/4yy5BuUJd9AYAjSwOFIA4a5Gspb4f9ioJeWib2MTOxlpNzqYGduFduzK1h3vIxVR0vRa1QMCjUQH+5NfJi3mBm3nYnffhuSJIk5c+bwwgsv8K9//QuTyYSnpydPPfVUnf2GDh3aTiUU2oNaLdGth46orh6cyLBx7JCNLUm/JI0+egKaeKcRFhbG9OnTOXXqFNu2bWPt2rWkpKQwdOhQevXqddb+Ukg40jXT4ZrpKKXFKHtSUNK2oaxfibJmKRi8keIGQ/+hSHGDW2WCQ1+9xj2Veq1TZu/panZkV7Izp5Kfs1ztlbEmPfFh3gwJ9yLGqEclqqvalKiGqocYwd15XIxVEw674k4a9loFc7CG2N46TEFNH9inKAonTpxgx44dFBQU4Ovry9ixY4mMjGxwLJFirYEDu13JI30nVJSBpIKYXq6k0S8eIru2anWVoiicKLGxM9eVOI4UWVEAP72aQaFeDA71YlCoF776hhPqxXitW1uHm+6jPYhk0XgiWVyccTvsCieP2Th22IbNquBvVNO9t46QMC1SEyfzUxSFkydPsn37dvLz8/Hy8mLQoEHExcWd1eOu3uNlGU5moOzZgbJvF5zMcG3wMyLFDYK+Q5D6DGi1adXPKLc62JVXRWpuFbvzqqiwOZGAGKOeQaFeDArzoqfZs97JDi/ma91aRLJoBJEsGk8ki4s7bqdTIetELccO2aiukvHyUdGth46IaA80mqYnjfLyctatW0dWVhY6nY64uDgGDhyIl5dX489TVuJKGvtSUQ7shuoq111HdHekvoOQ+gyCrj2QWmkmBACnrHDMYmVXXhVpeVUcLnI1kntqVMQFGxgU6sWAEAPhvh5IktQhrnVLE8miEUSyaDyRLDpG3IqskJdjJ+OgjbISJ1oPiS4xHkR31+FpaPpEgvn5+aSmpnLs2DEkSaJnz54MHDjQPdtzo8vldMKJIygHdqMcSIPjR0CRQecJPeOQeg9A6j0AwqJatcqqstZJ+ulq0k67ksfpStfa9EZPDf1DDIzqHkxXL7lTzV0lkkUjiGTReCJZdKy4FUXBUuTk+GEbp3PsSBKERmiJjtVhNKsb/ED+fcylpaWkpaVx4MABHA4H4eHhDBw4kK5du6JqxqJLSlUlHN6LciDNlTwKT7s2+Poj9ervWsypVz8IDG3V5HG6opa9+dWk5VWRnl9Nuc0JQKiPln7BBvoFexEXbGj3aUhak0gWjSCSReOJZNFx466qdJKZUUvW8VrsdgVfPxVduusI7+KB9hxrg58rZqvVyv79+9mzZw+VlZX4+PgQFxdH3759G/23Ux+luADl4B44uBflcDqU/TIRaIAZqWcc9Ihz/WzF5CErCuUY2HQ4h72nq9lfUE21XQYgzMeDuGBP+gYZiAs2XFJTkYhk0QgiWTSeSBYdP26HQyHnZC2ZGbWUlzpRayA8yoOobh74G+vebTQUsyzLHD9+nL1795KdnY1KpaJ79+7ExcURHh5+QR/oiqJAfg7Kob1weJ8reVSUuTb6GZF69HWNKo/t46q2UrXc+I7fxu2UFY6XWEnPr2Z/fjUHCmvcySPIS0ufIFfy6B3oScQvbR4dkUgWjXAxJovw8HCmTZvGBx98ALhmjB00aBCDBg3iq6++Yv78+ezdu5dXX321znHDhw/H29sbSZIIDAzkvffeIygoqMXKJZLFpRO3oiiUWZxkHqsl91QtTif4+KmI6upBeBcPdHpVk2K2WCykp6dz6NAhbDYbAQEB9OnTh169ejWpQfx85eV0NsqR/XBkP8qRfVD6y6Sjnl6ubrrdeyN17w3RPZq9OiCc/1o7ZYXMUhsHClx3HQcKaij7pdrKR6eml9mT3oGe9Ar0pLtRj07TciPLW5MYwd1BGQwGDh06RE1NDZ6enmzatImQkPrXHPi9//3vfxiNRl577TU++OADXn755VYurdARSZKEv0nDQJOGvoM8yT1Vy6njtexPs3Jgj5WgUA19+uvx9FYatYKf0Whk7NixJCQkkJGRwb59+9i6dSvJyclER0fTp08funTp0uz1XyRJgtBIpNBIGDvBlTyK8lEyDkLGAZSjB1D2paIAqNUQ0RUpphd064nUrSeYg1vkW79aJRFj1BNj1DOxlxFFUcitsHOwsJr9BTUcKqwmJcc1OFCjcs0y3dPs+ctDT5BX89dd7yg6ZbLYt6ua8lLnObc3Z4pyX381cYMbvnO54oorWLt2Lddffz1LlixhypQpbN++vdHvM2LECL788ssmlU3onLRaiS4xOrrE6Kgoc5KVWUt2Zi3rfzyNRgthER6Ed9FiCtQ0OG5Dq9XSu3dvevfujcVi4eDBgxw8eJATJ06g1+uJjY2lV69ehISEXNCHpiRJrqlGAkNg5DgAlKoKOHYI5cxjyxpYt8KVQHz8XImjaw+krj0gOhbJcOF3PJIkEe7rQbivB+Nj/AEoszo4VFjDoaIaDhfV8FNGKSsOlwDgr1fTw+xJD5OeWJMnsSY9Xh6X1nQ9nTJZtKfJkyfzzjvvMH78eA4ePMhNN93UpGSRlJRU75QNgnA+Pn5q+gzwpFc/PXarFwf2FpKTVcupE7Xo9BJhkVrCIj0IaERvKqPRyKhRoxg5ciSnTp3i0KFDHDhwgPT0dHx9fenRowc9evTAZDK1yLdtycvHNdVIf9c0OIrTCTmZKMePwPHDKCcOuwYLnjkgOBwpursrcUR3h8huSDr9BZfDT69heKQPwyNdAw8dssLJUhuHf0keR4qs7MiudO8f5uNBrElPrElPd6OerkY9+g5SfVWfTpksGroDaM0G7j59+pCdnc3SpUu54oorGn3cH/7wB1QqFb179+axxx5rlbIJlz6VSiI8yoDO4EU/h0JBrp2cLDsnj9Vy4mgtek+JkHAtoZFajGYNqvPccahUKqKjo4mOjsZms3H8+HEOHz5MamoqO3fuJCAggNjYWGJjYzEajS1WTSOp1RAVgxQVA5dfA/zSXffkUZTjR1Ayj6IcSoftG10JRFJBaARlPfoiB4cjdekOkdFI+ub38ALXuuRnqq6u7eFaF6TS5iTDYuVIcQ0Zxa4G9I2Z5QCoJIjw9aCb0ZU8uhn1dA3QYdB2jDuQTpks2ttVV13FSy+9xPfff09JSUmjjjnTZiEILUWjkQiL8iAsygO7XSE/x05etp1TJ1y9qrQeEiFhWkIitJiDNecdLa7T6dzVVNXV1WRkZHD06FF27NjBjh078Pf3JyYmhpiYGIKDW6ad4bckL2/o88vI8V8oJcWuKUpOHkM5mUHtnh0oJcW/3oEEhSJFdoOobkiRXSGyq6tH1gWUzVunZmCoFwNDf60KK662c8xiJcNiJaPYyp7T1Ww4Ue7eHuqjpVuAK3F0/eWn0bPp84C1NpEs2sGMGTPw9fWld+/eJCcnt3dxBAGtViIi2oOIaA8cdoWC03ZO59jJy6klK7MWlRrMQRqCw7QEhWoweJ3727DBYKB///7079+fqqoqjh8/TkZGBrt27SI1NRUvLy+6du1Kt27diIiIaHbjeEOkABMEmJAGDgdcPYMKM47AyWMoWcdQTh1HyTwKqVt/TSDevhARjRTRFSJcC0cRGnVBvbBMBi0mg5ZhEb/Om2WpcXDcYnU9SlyJZOupCvd2X52aaH8dXQJ0RPvriPbXE+nn0a69sESyaAdhYWHceeed9W5bsGABP/74o/v58uXL26pYggCARisRFulBWKQHsqxQXOggP9dBfq6dglTX+iveviqCQrQEhmowmTWoz3HX4eXlRb9+/ejXrx9Wq5XMzEx3ddW+ffvQaDREREQQHR1Nly5d6iyp3BokfyP4G5EG/LoMgFJd6VpFMCsTsk+gZGeibFoFtbW/VmMFhkB4lCt5hEUhhUVBcBiSpnkD+IyeGozh3sSH/7rqZ1Wtk8xSGydKrGSW2MgstbH6aCm1TlcqU0kQ4u1BF38Povx1rhUI/XSE+XrUO3FiSxPjLOohBuV1HpfaOIvGaG7MiqJQVSFTkGcnP8+BpdCBLINKBcZADYHBGszBGvz81Q32rnI4HOTk5JCZmcmJEycoL3dVy/j7+9OlSxciIyOJiIho1Iy4jdWUuBXZCQWnIeekK3nknoTcU5Cf55r3ClyBB4W5VhUMjfylC3CEq4G9BRrUwTX+43SlnZOlVjJLbZwqtXGytJbTlbXIv3xyqyUI8/Ug0k9HpJ8HMUY9w3+5i+mQg/LS0tKYO3cusiyTmJjIlClT6mw/cOAA8+bN4+TJkzzyyCOMGDHCvW3GjBlERUUBv67N3RCRLBpPJIvOFXdLxexwKFgKHRSedlB42k5FuetDVKuVMAapMQdqMAVp8PU7f/JQFIXS0lJOnjzJyZMnycnJweFwoFKpCA4OJjIykvDwcEJDQy+oyqol4lZqbXA6ByUvC3JPoeRmweksKMgDWf51R2MghIQjhUS4fgaHQXCEq1qsGfNt/Z7NIZNTXsupMlcCyS6vJavMxulKOz3Nnrx+VRegAw7Kk2WZOXPm8Mwzz2AymXjyySeJj48nIiLCvY/ZbGbWrFn1Vrt4eHjw1ltvtUVRBUFoJI1GIihUS1CoFvDEWiNTXOCgKN9BUaGD/Byraz8tGM0a1yNQg3+Auk61lSRJBAQEEBAQwMCBA3E4HOTl5ZGVlUVWVhYpKSns2LEDtVpNcHAwERERhIeHExISglbbtvM4SR46V4N4VLc6ryt2OxTkukaj52VBXg5Kfg7K1rVgq/m1TUTrAUGhrsb14HDXz6BQ1x2KX0CjE4lOo6LbLz2qfqvWKVNhO/cYsgvRJskiIyODkJAQgoODAUhISCAlJaVOsjgzfcXF1gNAEITG0XuqCO/imlYEoKbalTyKCx1YihwU5LmSh6QCP381AWYNASY1ASYNngbJ/bev0WiIjIwkMjISAJvNRk5ODtnZ2eTm5rqThyRJBAUFERoaSmhoKCEhIfj4tO7iS+ciabUQ3gXCu/DbTzBFUaDUAgW5KPk5rruSgjzIy0bZuxOcjrqJxBzsSiCBIWAOQQoMdrWXmIJciaoBHmoVpiZMV98UbZIsLBYLJpPJ/dxkMnH06NFGH2+323niiSdQq9VMnjyZYcOGnbVPUlISSUlJALz++uuYzeY62/Pz85t0C9taPTQuRjqdDo1Gc9bvrDPojHG3ZcyRUb/+21rjpOC0lYLTNRTkWTl13MaJI66PSr2nGnOQDnOQ/pefOjwNv/4NhoeHu//urVYrp06dcj/27dtHWloaAL6+vkRERLjvPsLCwtD90pOp3a51YCDE9jzrZcXpRC4uwJGXjTMvC+fpHNcjLxvHob1gs/LbNgJVgBl1cCjqoFDUgSGogkJRB4WgDgxFHRhcbzJpyZg7xCfixx9/jNFoJD8/n5deeomoqKiz5lQaP34848ePdz//fT2dzWZDrW7c4JfO1mZhs9lwOBydru4eRJtFWzP4QLQPRMfqkWUd5aVOSoudlFgclFqsZJ+sdu+r95TwC1Dj66/GL0CNn78aTy8VkiRhNBoxGo0MHDgQp9NJUVEReXl5nD59muzsbA4cOOA+T0BAAMHBwXTt2hWDwYDZbHYnkHan0kJ4V9fjty8rClSUQsFplKJ813xZRfnYiwuwH9gDlqS6bSQAvv5gDESK6YXqpruADthmYTQaKS4udj8vLi5u0gCzM/sGBwfTp08fMjMzGz0BnyAIFyeVSsLfqMHfqCEa14e3w65QVuKkrMRBaYmTshIn+XkOznzF1mhcU5f4+qvx9VPj46fGx8/VEH6mmhtcnTby8/MpKCigoKCArKwsDh065N7u5+eH2WwmMDAQk8mE2WzG19f3oqkGlyQJfAPAN8A14+7vKE6nq3qrOB+lqAAshWApRCkuBGtNq5SpTZJFTEwMeXl5FBQUYDQaSU5O5qGHHmrUsZWVleh0OrRaLeXl5Rw+fJjJkye3colbR3h4OHfffTfPP/88AJ988glVVVX87W9/a/b5Gpry/JVXXnEn1t69e/P++++3TDCC0Ao0WglTkKsX1RkOh0JFmZPy0l8eZU5yTtVy0v7rcTq9hI+vGm9f1S8/tYSGdCE6OtqdAHQ6HYcPH6agoIDCwkKKioo4duyY+xxarRaj0YjJZMJkMrnvXs4sD3AxkdRqMAWCKRCpR9u8Z5skC7VazcyZM3n11VeRZZlx48YRGRnJ/PnziYmJIT4+noyMDP7v//6PqqoqUlNTWbBgAW+//TY5OTl89tlnqFQqZFlmypQpdRrGOxKdTseqVat48MEHW2TqjsZMeT5p0qSz1scQhI5Eo5EIMGkIMP36caUoCtYahfIyJxVlTirLZffMuk7Hb48FLx813j4qAoMlNKowYmMiGDhAhdZDwm63U1xcXOdx4sSJOtVYWq3W3VsrICAAf39/96Mlx4Fc7NqszWLw4MEMHjy4zmszZsxw/7t79+588sknZx3Xs2dPZs+e3aJl2bRpE4WFhefc3pwpygMDAxkzZsx591Gr1dxyyy189tlnPPHEE3W2FRcX88QTT5CTkwPAiy++yNChQ5k9ezZeXl7ce++9gGuK83nz5rl7ilzolOeC0BFJkoSnQcLToCI49Nfus2eSSGWFK4FUVTiprJCxFDnIOVV3HjaNFry81Ri8fTF4+dMlPJbePVUYvFQoWCkrK6GkpASLxUJJSQm5ubkcPny4zjm8vLzw8/PD398fPz8//Pz88PX1xc/PD71ef9HdkVyIDtHAfSm5/fbbGT9+PLNmzarz+nPPPcddd93FsGHDyMnJ4eabb2bjxo0Nnq+hKc+XLVvGjh07APjLX/5SJ0ELwqXmt0kkMLjutoAAE6dOFlBVIVNV6aS6UqaqUqa8xEl+jv2s9mKd3gdPgx9eXt0IjFah76NC6+HA4azAaiunorKUsrIyysrKOHnyJFVVVXWO12q1+Pr64uPj4/75238bDIYOlUw6ZbJo6A6gNXtD+fj4cMMNNzBnzhw8PT3dr2/evJkjR464n1dWVp71n68+DU15LqqhBMFFrXa1a/j4qoG6g/kUWcFqVaiukqmukqk587O6vmSiB/RIqiD0nipC/CWiw1RoPZzIVOJwVGKzV2C1VlBdU0FFRTm5ubnU1tbWeU+VSoW3t3edh5eXl/vnmcfF0o3/4ihFJ/OXv/yFCRMm1PmWL8syy5cvR6+vOyJTrVYj/+Yrj81mO+t8zZnyXBCEX0mqX+9ITIFnb1cUhVqbQk21jLXmzE/Z/by81Im1RsbpMAAG4JdBxoC/BwSHS6i1dpCqUKQaHM4q7I4qau1V2GxV5OWeprqmCqfz7NHXOp0Og8HgTh4Gg8H98PT0dP/09PRs1cQikkU7CAgIYOLEiXz33XfcdNNNAIwdO5a5c+dy3333AbBv3z7i4uKIjIx0DzZMT0/n1KlTZ51PTHkuCK1LkiR0egmd/vyjox12BavVlUhsNa5/26wKNquMzarGZvXAVuNPrU1BUVwfwBoVeHmBYlCQFRtINUhqKwo1yEo1TrkGh7OGyooaLMV52GqrcTrrr/nw8PAgLCyMSZMmtfjvQCSLdnLPPfcwd+5c9/OXX36Zp556ivHjx+NwOBg+fDhvvPEG1157Ld9//z3jxo1j0KBBdOvW7axznW/Kc0EQ2o5GK+GtVePtc/4BwIqiYK9VsNkUaq0KNptMrU2h1uZJrc3X9e9axf3TbpNxOHDVgAGybMcpW3951OCUrSBZUbAh2y9sBcBzEVOU16OzjeAWs852rrg7Y8zQ8eOWnQp2+69JxF575iFjt//6XG9Q0bu/qz20w43gFgRBEC6MSi2hU0u00FIZTX//9nlbQRAEoSPpNMniEq1taxHidyMIQkM6TbJQqVSdqh2isc6sSCYIgnA+nabNQq/XY7VasdlsDY6a1Ol09Y5nuNQoioJKpTprbIcgCMLvdZpkIUlSnRHT59PRe00IgiC0NFH/IAiCIDRIJAtBEAShQSJZCIIgCA26ZEdwC4IgCC1H3FnU4/cLE3UGnTFm6Jxxd8aYoXPG3ZIxi2QhCIIgNEgkC0EQBKFBIlnUY/z48e1dhDbXGWOGzhl3Z4wZOmfcLRmzaOAWBEEQGiTuLARBEIQGiWQhCIIgNKjTzA3VGGlpacydOxdZlklMTGTKlCntXaRWUVRUxEcffURpaSmSJDF+/HiuvfZaKisreeeddygsLCQwMJBHH30Ub2/v9i5ui5JlmSeeeAKj0cgTTzxBQUEB7777LhUVFXTr1o0HH3ywVRe9bw9VVVV88sknZGVlIUkS9913H2FhYZf0tV6xYgXr1q1DkiQiIyOZNWsWpaWll9y1/vjjj9m1axd+fn7Mnj0b4Jx/x4qiMHfuXHbv3o1Op2PWrFn1LtN8ToqgKIqiOJ1O5YEHHlBOnz6t2O125e9//7uSlZXV3sVqFRaLRTl27JiiKIpSXV2tPPTQQ0pWVpby9ddfK4sXL1YURVEWL16sfP311+1YytaxfPly5d1331Vee+01RVEUZfbs2cqWLVsURVGUTz/9VFm9enV7Fq9VfPDBB0pSUpKiKIpit9uVysrKS/paFxcXK7NmzVJsNpuiKK5rvH79+kvyWu/fv185duyY8te//tX92rmubWpqqvLqq68qsiwrhw8fVp588skmvZeohvpFRkYGISEhBAcHo9FoSEhIICUlpb2L1SoCAgLc3yg8PT0JDw/HYrGQkpLC2LFjARg7duwlF39xcTG7du0iMTERcE3Rvn//fkaMGAHA5ZdffsnFXF1dzcGDB7niiisA1/ryXl5el/y1lmWZ2tpanE4ntbW1+Pv7X5LXuk+fPmfdEZ7r2u7cuZMxY8YgSRI9evSgqqqKkpKSRr9Xx74Ha0EWiwWTyeR+bjKZOHr0aDuWqG0UFBRw4sQJunfvTllZGQEBAQD4+/tTVlbWzqVrWf/+97+59dZbqampAaCiogKDwYBarQbAaDRisVjas4gtrqCgAF9fXz7++GNOnjxJt27duP322y/pa200Gpk4cSL33XcfHh4eDBgwgG7dul3y1/qMc11bi8WC2Wx272cymbBYLO59GyLuLDoxq9XK7Nmzuf322zEYDHW2SZLU4CJRHUlqaip+fn5Nq6O9BDidTk6cOMFVV13Fm2++iU6nY8mSJXX2udSudWVlJSkpKXz00Ud8+umnWK1W0tLS2rtY7aIlr624s/iF0WikuLjY/by4uBij0diOJWpdDoeD2bNnM3r0aIYPHw6An58fJSUlBAQEUFJSgq+vbzuXsuUcPnyYnTt3snv3bmpra6mpqeHf//431dXVOJ1O1Go1FovlkrvmJpMJk8lEbGwsACNGjGDJkiWX9LVOT08nKCjIHdPw4cM5fPjwJX+tzzjXtTUajXUWdWvqZ5y4s/hFTEwMeXl5FBQU4HA4SE5OJj4+vr2L1SoUReGTTz4hPDyc66+/3v16fHw8GzduBGDjxo0MHTq0vYrY4m6++WY++eQTPvroIx555BHi4uJ46KGH6Nu3L9u2bQNgw4YNl9w19/f3x2QykZubC7g+SCMiIi7pa202mzl69Cg2mw1FUdwxX+rX+oxzXdv4+Hg2bdqEoigcOXIEg8HQ6CooECO469i1axfz5s1DlmXGjRvHtGnT2rtIreLQoUM899xzREVFuW9R//jHPxIbG8s777xDUVHRJdmd8oz9+/ezfPlynnjiCfLz83n33XeprKyka9euPPjgg2i12vYuYovKzMzkk08+weFwEBQUxKxZs1AU5ZK+1gsWLCA5ORm1Wk10dDT33nsvFovlkrvW7777LgcOHKCiogI/Pz9uvPFGhg4dWu+1VRSFOXPmsGfPHjw8PJg1axYxMTGNfi+RLARBEIQGiWooQRAEoUEiWQiCIAgNEslCEARBaJBIFoIgCEKDRLIQBEEQGiSShSBcpAoKCrjxxhtxOp3tXRRBEMlCEARBaJhIFoIgCEKDxNxQgtAEFouFL7/8koMHD6LX67nuuuu49tprWbBgAVlZWahUKnbv3k1oaCj33Xcf0dHRAGRnZ/PFF1+QmZmJ0Wjk5ptvdk83UVtby3//+1+2bdtGVVUVUVFRPPvss+733Lx5M/Pnz6e2tpbrrrvukp1ZQLi4iTsLQWgkWZZ54403iI6O5tNPP+W5557jhx9+cM9ounPnTkaOHMmXX37JqFGjeOutt3A4HDgcDt544w369+/PF198wcyZM3n//ffd8zV99dVXHD9+nFdeeYW5c+dy66231pkp9NChQ7z33ns8++yzfP/992RnZ7dH+EInJ5KFIDTSsWPHKC8v54YbbkCj0RAcHExiYiLJyckAdOvWjREjRqDRaLj++uux2+0cPXqUo0ePYrVamTJlChqNhri4OAYPHsyWLVuQZZn169dz++23YzQaUalU9OzZs86cRX/4wx/w8PAgOjqaLl26cPLkyfb6FQidmKiGEoRGKiwspKSkhNtvv939mizL9O7dG7PZXGfxLJVKhclkcq9EZjabUal+/W4WGBiIxWKhoqICu91OSEjIOd/X39/f/W+dTofVam25oAShkUSyEIRGMpvNBAUF8f7775+1bcGCBXXWQ5FlmeLiYvcU0EVFRciy7E4YRUVFhIaG4uPjg1ar5fTp0+72DUG4GIlqKEFopO7du+Pp6cmSJUuora1FlmVOnTpFRkYGAMePH2f79u04nU5++OEHtFotsbGxxMbGotPpWLZsGQ6Hg/3795OamsqoUaNQqVSMGzeOr776CovFgizLHDlyBLvd3s7RCkJdYopyQWgCi8XCV199xf79+3E4HISFhTFjxgwOHTpUpzdUSEgI9957r3sZ16ysrDq9of74xz8ybNgwwNUb6j//+Q8///wzVquV6Ohonn76aUpLS3nggQf47rvv3GtHv/DCC4wePZrExMR2+x0InZNIFoLQAhYsWMDp06d56KGH2rsogtAqRDWUIAiC0CCRLARBEIQGiWooQRAEoUHizkIQBEFokEgWgiAIQoNEshAEQRAaJJKFIAiC0CCRLARBEIQG/T8yxt8EqrwmxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history2.history['root_mean_squared_error'])\n",
    "plt.plot(history3.history['root_mean_squared_error'])\n",
    "plt.plot(history4.history['root_mean_squared_error'])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['MTRS', 'GMF', 'MLP', 'NeuMF'], loc='lower left')\n",
    "plt.show()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(1000, 64, input_length=input_length))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = input_item\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABobUlEQVR4nO3deXhU1eH/8fedfSb7TPaVJISwhD1sQUEEFUUBccGq/am4VKnW2n61at1atbVa92qlSnFrLVjLDoIBBCGyE9YACZCQfd+TSTJzz++PkZHIlkAWyJzX88yTTOYu5+Qm85l7zr3nKEIIgSRJkiQBmu4ugCRJknTxkKEgSZIkuclQkCRJktxkKEiSJEluMhQkSZIkNxkKkiRJkpsMBanH+/jjj9HpdO1a54UXXqB3796dVCJJunjJUJC6zd13342iKMyYMeOU1xYvXoyiKO1+M+8OW7ZsQavVMmLEiO4uiiRdMBkKUreKjo5m2bJlFBcXt/r5nDlziImJ6aZStc+cOXN46KGHOHLkCOnp6d1dHIQQtLS0dHcxpEuUDAWpWyUkJDB69Gg+/vhj98+OHz/ON998wz333HPK8itWrGD48OEYjUaCg4OZPXs29fX17tdVVeXZZ58lODgYb29vZs6cSWVl5Snb+eabbxg7dixms5mIiAjuueceysvL213+6upq5s+fzy9+8QtmzpzJnDlzTlnmyJEj3HzzzVitViwWC4MGDWLZsmXu13fs2MHkyZPx9fXF29ubkSNHsmXLFuD0zVgbN25EURSys7OBH5vH1q1bx9ChQzEajaSmpnLs2DFmzJhBeHg4FouFgQMH8tlnn51Svvfee4/+/fu7f6c33XSTe9+JiYmnLD9r1iwmTpzY7t+VdGmQoSB1uwceeICPPvqIEyOufPTRR0ycOPGUM4U9e/YwdepUxo0bx+7du/nkk09YtmwZDz74oHuZd999lzfeeIPXXnuNnTt3Mnz4cP7whz+02s7atWuZNm0at912G3v27GHRokVkZ2czY8YM2jvqy+eff07fvn0ZOHAgd999N//6179ahVRRUREpKSlUVVWxZMkS9u7dy4svvohG4/rX279/P+PGjSMgIIC1a9eya9cuHnvsMVRVbVc5VFXld7/7HW+88QYHDx4kOTmZuro6rrzySlauXMnevXt54IEHuOeee1i3bp17veeff57f/e53zJ49m7179/L1118zbNgwAO677z6OHDnC+vXr3cvX1tayYMECHnjggXaVT7qECEnqJnfddZeYOHGiaGxsFFarVaxdu1Y4HA4REREhvvrqKzFv3jyh1Wrdy995551ixIgRrbaxaNEioSiKyM7OFkIIERERIZ5++ulWy9x0002ttjN+/Hjxu9/9rtUyOTk5AhC7du0SQgjx/PPPi/j4+HPWYfDgweKdd95xP09MTBQffvih+/kzzzwjQkJCRF1d3WnXv/POO8WgQYOE0+k87eunK8d3330nAHHs2DEhhBDz5s0TgNiwYcM5yzt16lRx3333CSGEqKurEyaTSbz22mtnXP6GG24Qd9xxh/v5Bx98IAIDA0VTU9M59yVdmuSZgtTtTCYTP//5z/nwww9Zvnw5DoeDG2644ZTlTnyqPtn48eMRQnDgwAFqamrIz88nJSWl1TKXXXZZq+fbtm3jrbfewtvb2/3o378/AJmZmW0u95YtW8jIyOD22293/+yuu+5q1YS0Y8cOUlJS8PLyOu02duzYwcSJE91nDhfipx3dDQ0NPPnkkwwYMACr1Yq3tzcrVqwgJycHcP0+7XY7V1999Rm3+Ytf/IKvvvrK3QT34Ycfctddd2EwGC64vNLF6eK/tEPyCA888ADDhg0jNzeXe+65B71e32n7OtHU8vOf//yU10JDQ9u8nTlz5tDc3ExISIj7Z0IIVFUlPT2dIUOGXHBZNRrNKU1ap+tE1mq1mEymVj97/PHHWbx4MW+88QaJiYl4eXnx29/+lurq6jbv/9prryU4OJjPPvuMcePGsWPHDv71r3+dX2WkS4IMBemi0L9/f0aMGMGmTZtadTqfbMCAAWzYsKHVz9avX4+iKAwYMABfX18iIiJIS0tjypQp7mU2bdrUap3k5GT2799/QfchnOhgfu+99045e/nlL3/JnDlz+Pvf/87w4cP58MMPqa+vP+3ZwvDhw1mzZg2qqp72bCE4OJiSkhKcTidarRaAnTt3tqmMGzZs4I477uDWW28FXGF4+PBhd4j1798fk8nE6tWrGTRo0Gm3odFouP/++/nwww85dOgQ48aNO23ns9SDdHPzleTBTvQpnFBfXy/Ky8vdz3/ap7B7926h1WrFr3/9a5GRkSFWrlwpoqKixJ133ule5o033hBeXl7i008/FYcPHxZ//etfhb+/f6vtrF27Vuh0OvHYY4+JXbt2iaysLLFy5Uoxa9Ys0dDQIIQ4d5/C3/72N+Ht7e1e/mRz5swRPj4+oq6uThQUFIigoCAxceJEsXHjRnH06FGxdOlSsWLFCiGEEHv27BFms1ncdtttYtu2bSIrK0ssWLBApKWlCSGEOHjwoNBoNOLpp592vxYbG3tKn8LJ9TvhpptuEomJiWLLli1i//794t577xW+vr5i/Pjx7mV+//vfCy8vL/G3v/1NHDp0SKSnp4s//elPrbZTUFAgdDqdMBgM4vPPPz/j70TqGWQoSN3mp6HwU6d7s1u+fLkYNmyYMBgMIjAwUDz44IOtOnGdTqd46qmnhM1mExaLRdx0003ijTfeOGU7GzZsEBMnThTe3t7CYrGIvn37ikcffVS0tLQIIc4dCoMHDxa33XbbaV8rLS0VOp3O3eF86NAhMX36dOHr6yvMZrMYNGiQWL58uXv5LVu2iIkTJwqLxSK8vb3FqFGjxJYtW9yvz507V8TGxgqTySQmT54svvjiizaFwvHjx8XVV18tLBaLCA0NFc8995yYNWtWq1BQVVW89dZbok+fPkKv14vg4GBx8803n7Kt6dOnC6vVKux2+xl/J1LPoAghZ16TJOnsRo4cydixY3nzzTe7uyhSJ5N9CpIknVFZWRnLli1j586d/Oc//+nu4khdQIaCJElnFBQUREBAAO+88w5xcXHdXRypC8hQkCTpjGTrsueRN69JkiRJbl12ppCens68efNQVZWJEycyffr0Vq9//PHH7N+/H4Dm5maqq6vPeL26JEmS1Dm6JBRUVWXu3Lk888wz2Gw2nnrqKZKTk4mMjHQvc/fdd7u/X7lyJceOHWvTtgsKCs6rTIGBgZSVlZ3XupcyT6y3J9YZPLPenlhnaH+9w8PDz/halzQfZWVlERoaSkhICDqdjpSUFLZt23bG5Tdt2nTKeDWSJElS5+uSUKioqMBms7mf22w2KioqTrtsaWkpJSUlJCUldUXRJEmSpJNcdFcfbdq0idGjR59x1MjU1FRSU1MBeOWVVwgMDDyv/eh0uvNe91LmifX2xDqDZ9bbE+sMHVvvLgkFq9Xaalar8vJyrFbraZdNS0vj3nvvPeO2Jk2axKRJk9zPz7f9ULY9eg5PrDN4Zr09sc5wCfYpxMfHU1hYSElJCQ6Hg7S0NJKTk09ZLj8/n/r6evr06dMVxZIkSZJ+okvOFLRaLbNmzeLll19GVVUmTJhAVFQU8+fPJz4+3h0QmzZtIiUlBUVRuqJYkiRJ0k90WZ/CsGHD3HO/njBz5sxWz0+M+y5JkiR1D4+8o7m8vJzVq1fLW/glSZJ+wiNDITc3l40bN5KVldXdRZEkSbqoeGQoeBn6YNRb2bBhA01NTd1dHEmSpIuGR4ZCYIgBm89o6uvr2bJlS3cXR5Ik6aLhkaEQYNMREh6O1TeR3bt3U1JS0t1FkiRJuih4ZCgs2FvGkpJSvI1DMRhMrFu3DlVVu7tYkiRJ3c4jQ6F/sIVMZyM6o4HIkJEUFxefdYA+SZIkT+GRodAvyIyfWUepuRmnPZr4+ES2bt1KXl5edxdNkiSpW3lkKGg1CpfF2thQU41WqxAWOBo/Pz9WrVpFQ0NDdxdPkiSp23hkKABcHm+lwuHEFKRQlCuYNGkydrtd3tQmSZJH89hQGBEdgEmncFRnx6lCZbEP48aN4/jx42zdurW7iydJktQtPDYUjDoNw8K92VRSS2SMnuysJuJi+9OvXz+2bNnC0aNHu7uIkiRJXc5jQwFgVKQ3lY0OdOGuUVkP77czYcIEgoODWb16NZWVld1cQkmSpK7l0aGQHOGNVoEdpXXE9jGSl91CQ53ClClT0Gg0LFu2TA6DIUmSR/HoUPA2aBkY6sXmvFriEw3o9QoZexrx8fHhuuuuo6qqilWrVskb2yRJ8hgeHQoAY6K8KaxtIbuumd79jJQUOigtaiEyMpIrrriC7OxsNm3a1N3FlCRJ6hIeHwrje/nhZdCw8EAFsX2MWLw07NvZiOoUDBw4kMGDB7Nr1y727dvX3UWVJEnqdB4fCma9hmsTAticW0tJQwtJw8zU1aoczXT1JVx++eVER0fz7bffkpub282llSRJ6lweHwoAUxID0GoUFmdUEBKuJyRcx+H9dhobVDQaDddeey3+/v4sX76cioqK7i6uJElSp5GhAFjNOq6I9WXN0Wqq7Q4GDDUjVDiwuxEAo9HI1KlT0el0LFmyRA6FIUlSjyVD4Qc39rPS7BQsP1yJl7eW3v2MFBxvobS4BQBfX19uuOEGGhoaWLp0KS0tLd1cYkmSpI4nQ+EHkX5GRkZ6s+JwFXaHSu++Jry8NezZ3ojT4RoLKSQkhMmTJ1NcXMzXX38tL1WVJKnHkaFwkpv626htcrL0YAVancKgZDMNdSqH99vdy8TFxTF+/HiOHTvG+vXr5eB5kiT1KDIUTtI3yMzISG/+d6CCGruDwBA9UbEGjhxqorrS4V5u8ODBDB8+nL1797Jjx45uLLEkSVLHkqHwEz8fEoTdobJgfzkA/Qeb0BsUdm9rRKg/nhWkpKSQmJhIWloaGRkZ3VVcSZKkDiVD4Sei/YxcGefHysOVFNc1YzBqSBpmprrSydHDP46DpCgKEydOJDIykjVr1pCTk9ONpZYkSeoYXRYK6enpPProozzyyCMsWrTotMukpaXx2GOP8Zvf/Ia33367q4p2itsHBaJRFP61uwyA8Cg9IRE6Du61U1vjdC+n0+mYMmUKVquVFStWUFxc3F1FliRJ6hBdEgqqqjJ37lyefvpp3nzzTTZt2nTKfMiFhYUsWrSIF198kTfeeIO77767K4p2WjaLnhsSA1ifXUNWuR1FURg03IJWp7B7a0OrZiSj0ci0adMwm80sWbKEqqqqbiu3JEnSheqSUMjKyiI0NJSQkBB0Oh0pKSls27at1TJr1qzhmmuuwdvbGwA/P7+uKNoZ3TTAhp9Jy5xtRahCYDJrSBpqprK8dTMSgJeXF9OmTUMIwaJFi6ivr++mUkuSJF0YXVfspKKiApvN5n5us9nIzMxstUxBQQEAzz77LKqqcssttzBkyJBTtpWamkpqaioAr7zyCoGBgedVJp1Od9Z1A4FHxsFLqzPZUuzkhqRQbDZBeUkRh/Y1kDggGP8Aw4/LBwZy1113MW/ePJYvX86sWbMwmUznVbbOdK5690SeWGfwzHp7Yp2hY+vdJaHQFqqqUlhYyPPPP09FRQXPP/88f/3rX/Hy8mq13KRJk5g0aZL7eVlZ2XntLzAw8JzrJgdq6B9k5r2Nx0gKUPAxakkcqKUwH9Z9nc/Yid5oNIp7eaPRyLXXXsvSpUv55JNPmDZtGjrdRfMrBtpW757GE+sMnllvT6wztL/e4eHhZ3ytS5qPrFYr5eXl7ufl5eVYrdZTlklOTkan0xEcHExYWBiFhYVdUbwzUhSFX4wIob7Zyee7SwEwmTUMSjZTVeEkK+PUWdliYmK46qqryM/PlxP0SJJ0yemSUIiPj6ewsJCSkhIcDgdpaWkkJye3WmbkyJHs378fgJqaGgoLCwkJCemU8oi8Y9Qv/qJNy/YKMDElMYBVmVVklrsGyAuPMhARrefwfjtVFY5T1klMTGTcuHEcOXKEdevWybueJUm6ZHRJ24ZWq2XWrFm8/PLLqKrKhAkTiIqKYv78+cTHx5OcnMzgwYPZvXs3jz32GBqNhjvvvBMfH59OKY/I2EPdgrlo+g1BsQadc/nbBwWyKaeWdzcX8frkXui1CknDzZSXOti1pYFxV/mg1Smt1hkyZAiNjY1s27YNs9lMSkpKp9RFkiSpIyniEv8Ye6KDuj1EXjbqH36FcvejaMZObNM6W/Jq+dP6fO4YFMitA10dOiVFLWxZX09sgoGkYZZT9yME69atY9++fVx++eUMHTq03WXtaJ7Y5uqJdQbPrLcn1hkuwT6Fi05EDBq/AMhIb/MqoyJ9uCzGh/n7yjle7epLCA7V06u3gWOZzZQWnTqUtqIoXHHFFcTHx/Pdd9/J4TAkSbroeWQoKIqCYfAIRMbudrX3358cglmn8LfNRTh/uIGt/2Az3r4a0rc20Nx0aqeyRqPhmmuuISoqitTUVI4ePdph9ZAkSepoHhkKAIaByVBTBQXH27yOv0nHfckhHCprZNmhSgC0OoVhoy00NQl2b288bcicGA4jKCiIlStXkp+f31HVkCRJ6lCeGwqDXVc/iXY0IQGM7+XLiAgvPksvJfeHZiS/AB19k0wU5bWQe6z59PszGJg2bRq+vr4sXbqU0tLSCyq/JElSZ/DYUNAGhUJwOOLA7natpygKvxwVhkmv4a20Qhw/NCPFJxqxBevYt6uRulrnadc1m81Mnz4dg8HAokWL5DhJkiRddDw2FACU/oPh8H6E49R7Dc4mwKxj9sgQsirs/PeHeRcUjcLQURY0GoWd3zegOk/fV+Hj48P06dPd4yTV1dVdcD0kSZI6imeHQr/B0NQI2YfbvW5KtC/je/myYG+Z+6Y2s0XD4BGuuRcO7rOfcV2r1cq0adNobGxk0aJF2O1nXlaSJKkreXQokDgQFKXdTUgnPJAcgr9ZxxubCrE7XFcehUUaiIk3cORg02kvUz0hJCSE66+/nqqqKpYsWUJLy5mXlSRJ6ioeHQqKlw9ExyMyzi8UvI1aHksJo7C2mY+2/zjBTv8hrstUd21poMl+5rGPoqKiuPbaaykuLmb58uU4nafvi5AkSeoqHh0K8EO/wrFDiIbzmwNhYIgXNw2w8c2RajYdrwFAp1MYPsaLlmbBri0NZ70XIj4+nokTJ3L8+HFWr14tB9CTJKlbyVAYMhqcTsT27857Gz8bFEiCzcR7W4oorXc1A/n6axkwxExpkYOjh04dTfVk/fv357LLLiMzM5Nvv/1WDqAnSVK38fhQILYPRMQgNqw+703oNAq/HRuOU4XXNxW473aO6W0gNEJPxh47VeVnv8Jp2LBhJCcns2/fPr7//vvzLoskSdKF8PhQUBQF5fJrICcLcfzIeW8nzMfAQyNDyCht5N97ytzbHjzSjMmssOP7Blqaz34GMGbMGJKSkti+fTs7d+4877JIkiSdL48PBQBl9BWgNyC+O/+zBYArYv24Kt6P/+4vZ2eB6/4Dg0HDsDFeNDao7N529v6FEwPoJSQksHHjRg4cOHBB5ZEkSWovGQqA4uWNMnwsYst6RNOF3TNwf3IIMX5G3kwrpLzB1b9gDdTRd6CJwrwWco6cfhiMEzQaDVdffTXR0dGsWbOGI0fO/+xFkiSpvWQo/EC5/GpobEBs33hB2zHqNDx+eThNDpW/biz4cRiMvkaCw3Ts39VIdeXZ+xe0Wi1TpkwhJCSElStXkpube0FlkiRJaisZCick9IfQyAtuQgKI8jMye1QoB0ob+SzdNfCdoigMGWnBYFTYkdZAS8vZ+xf0ej1Tp04lICCAZcuWUVxcfNblJUmSOoIMhR+4OpyvhiMHL6jD+YQrYv24ro8/izIq+P54LQBGk6t/oaFeZc85+hcATCYT06ZNw2w2s3jxYioqKi64XJIkSWcjQ+EkymWTwGxBXb6gQ7Y3a1gwfWwm3v6+kPwaV1+CLcjVv1CQ20JO1tn7FwC8vb2ZPn06Go2GRYsWUVtb2yFlkyRJOh0ZCidRLN4oE2+And8j8rIveHt6rYYnLo9Ap1V4ZUMeDS2uYSzc/QvpjVRVnHuEVn9/f6ZNm0ZzczOLFi2ioaHhgssmSZJ0OjIUfkKZNBVMZkQHnS0Eeel5/LJw8mqaeef7IoQQKIprmG2jydW/0Nx87qEtgoKCmDp1KjU1NSxZsoSmprPfJS1JknQ+ZCj8hOLlg3Ll9YgdmxDtmKrzbAaHenHX0CC+z63lqwOufgGDUcPwFC8aG1XSzzE+0gnh4eFcd911lJaWsnz5chztnAdCkiTpXGQonIZy1TQwGDvsbAFgWl8rl8f48Hl6qfvGtgCbjgFDzBQXOMg62LZP/rGxsVx11VXk5eXx9ddfywH0JEnqUDIUTkPx9kWZMAWx7bsOO1tQFIWHR4cR42/kr5sK3B3PvXobCI/Wc3CvnbLits2p0LdvX8aPH8/Ro0dZu3atHEBPkqQOI0PhDJSrbwSTBfXLf3bYNk06DU+Pj0CrKLy8Po/6ZqdrfKRkC97eGnZ830BjQ9s++Q8ePJiRI0dy4MABNm3a1GFllCTJs3VZKKSnp/Poo4/yyCOPsGjRolNe//bbb7n33nt5/PHHefzxx1mzZk1XFe20FB9flOtnwr6diL3bO2y7Id4Gnrw8gqLaZveIqjq9QvJYL5xOwY60+jPO7/xTo0aNYtCgQezcuZMdO3Z0WBklSfJcXRIKqqoyd+5cnn76ad588002bdpEXl7eKculpKTw2muv8dprrzFx4sSuKNpZKVdOgZAI1AVzER3YqTsgxMIvRoSyo6CeT3+449nHT8uQERYqy50c2N3YtvIpCuPHj6dPnz5s2rSJffv2dVgZJUnyTF0SCllZWYSGhhISEoJOpyMlJYVt27Z1xa4viKLTo7l1FhTlI75d3qHbvibBnyk/3PH8TVYVAOHRBuL6GDmW2UxezrlvbANXMFx11VXExMSwbt06srKyOrSckiR5Fl1X7KSiogKbzeZ+brPZyMzMPGW5LVu2kJGRQVhYGHfddReBgYGnLJOamkpqaioAr7zyymmXaQudTtemdcWEyVRtXE3L0vlYr52Bxi/gvPZ3Ok9cY6PUvp+/byumT0Qgw6P8ufxKQX1tPnu3NxIdY8MaaGzTtn7+85/zySefsGrVKoKCgoiPjz/tcm2td0/iiXUGz6y3J9YZOrbeiuiCS1c2b95Meno6Dz74IAAbNmwgMzOTe++9171MbW0tJpMJvV7PN998Q1paGs8///w5t11QUHBeZQoMDKSsrKxNy4rCXNQ//AplxDg09z52Xvs7k/pmJ79bnUNlo4NXr+lFhK8Be6PKhtW1aHUKl1/ljcHQthM6u93OV199RU1NDTNmzCAkJOSUZdpT757CE+sMnllvT6wztL/e4eHhZ3ytS5qPrFYr5eXl7ufl5eVYrdZWy/j4+KDX6wGYOHEiR48e7YqitYkSFoUy+SbE5nWIfR3boetl0PLsFZFoFIUXv82lxu7AZNaQPNY1Mc+uzW27sQ3kAHqSJF24LgmF+Ph4CgsLKSkpweFwkJaWRnJycqtlKisr3d9v376dyMjIrihamylTZkJoJOpn7yPsbesIbqsQbwNPj4+grN7Bnzbk0+xUsQbqSBpqpqTQwaF9bZ/4Rw6gJ0nSheiSUNBqtcyaNYuXX36Zxx57jDFjxhAVFcX8+fPZvt11uefKlSv5zW9+w+OPP87KlSuZPXt2VxStzRS9Hs1dD0NlGWLR5x2+/X5BFh5LCSOjtJG30gpRhSAm3kBUrIHMA00U5rWt4xnkAHqSJJ2/LulT6Exd0adwMvXfcxDfrkDzxCsovfud177PZuGBcj7eVcqN/azcPSwYp1OQtraO2honl0/ywcdP2+ZtFRQUsHDhQmw2GzfeeCNGo9Ej21w9sc7gmfX2xDrDJdin0JMoM34O1iDUf76JsHf8J/Dp/axcm+DPwowKlh2qQKt13dim1Sps21hPSxtGVD3hxAB6ZWVlcgA9SZLaRIZCOykmC5r7fgNlJYgvPuz47SsK9yeHMCrSm4+2l7AppwazxdXx3FCvsnNzA0Jt+8ldbGwskyZNcg+g53Q6O7zMkiT1HDIUzoPSuz/KdTcj0tYgdnT8uENajcJvx4aTGGjmjbRC9hU3YAvSkTTM1fF8sB0dz9B6AL0lS5bIAfQkSTojGQrnSbn+Nojtg/rpe4iKjm/DNOo0PHNFJKHeev60Po/sSjsx8Qai4wxkZTSR38Y7nk8YPHgwo0aNYteuXXz33XcyGCRJOi0ZCudJ0enQ3PsbcDpQP/orohOaZXyMWp6fEIVJp+GFtbkU17UwcJgZa5CW9G0NbZrK82QjR45k1KhRpKenu6/6kiRJOpkMhQughISj/PyXkHkAsfCzTtlHsLeeFyZG4VAFz6/NpbrZSXKKF0ajq+PZ3tj2jmdFUbj22mtJTEzk+++/Z8+ePZ1SZkmSLl0yFC6QZtR4lPGTEav+h0jf0in7iPYz8uyEKKrsDl5Ym0uLIhhxmRctzYLtm+pxtnGobQCNRsOkSZPo1asX3377LYcPH+6UMkuSdGmSodABlJn3QUxv1HlvIUqLOmUfiYFmnhwXSV5NE3/8Ng+Dt4Yho1xDbe/Z1vahMMB1M+F1111HeHg4q1evJjs7u1PKLEnSpUeGQgdQ9AY0v3gCAPX9PyGa2nd1UFsNDfPi/8ZGkFneyJ/W5xEYriMxyUReTgtH2jjH8wk6nY4bbrgBm83GihUrzvsmQEmSehYZCh1ECQpFc//jkH/cdcbQSVf3jIn24Vejw9hT3MCr3xUQ29dAeJSejD12ivLbNsfzCUajkWnTpuHj48OSJUsoKSnplDJLknTpkKHQgZSkYSg33QU70hDLF3TafibE+fHgiBC25dfxZlohA5PN+AVo2bm5nurK9l2RZLFYmD59OkajkcWLF7camFCSJM8jQ6GDKVdPRxl9BWLxvxC7Nnfafq7tE8CsYcFsOl7Lu9uKGD7Wgl6vsLWdVySBa9jy6dOnA7Bw4UI5sqokeTAZCh1MURTXZaqxfVA/eh2RfeoMcx1lWj8rPx8cxIbsGj7aU0LyZV60NAm2bazH6Whf81VAQADTp0+nubmZhQsXypFVJclDyVDoBIrBiObh34OPH+q7LyLKO6+t/uYkGz8bGMjao9V8friUIaMtVFU42bWlfVckAQQFBTF16lTq6upYtGgRdnvndJhLknTxkqHQSRTfADS/eg5aWlDf/gOioa7T9jVzoI1bk2ykHqnmq7xy+g4yUZjXwsG97X9TDw8PZ8qUKVRUVLBkyRKam9s3nIYkSZc2GQqdSAmPRvPQk1BSgPr+nxEtnfMGqygKtw8KZOZAVzB8XVXpHiPp+NH2XaoKEBMTw+TJkykuLpZDbkuSh5Gh0MmUfoNR7v4VHNqL+tEbCLVzhq52BUMQtw20kXq0mnXNVQSG6NizvZHS4vZdqgrQu3dvJk2aRG5urhxyW5I8iAyFLqAZPQHl1nthZxriX3M6dYTSnw0K4o5BgazLriFNU42Xj4btm+qpqWr/m3q/fv3cQ26npqaiqu27qkmSpEuPrrsL4Ck0V01Dra1CrPwKfHxRpt/Zafu6dWAgOq3CJ7tKUcNgcLM3W76r4/JJPu3e1uDBg2lpaSEtLQ29Xs+ECRNQFKUTSi1J0sVAhkIXUm78f1Bbg1i+ANVkRjP5pk7b14z+NgxahQ+3l6AGwcBaL7ZsqCfklvZ/2k9OTqa5uZnt27ej0+m4/PLLZTBIUg8lQ6ELKYoCP58NTXbEV5+gGoxorry+0/Z3faIVo1bD+1uLwA8GVHuxblURQ0bp0Wja96Y+ZswYWlpaSE9PR6/XM2bMmE4qtSRJ3UmGQhdTNFqY9RiipRnxxT9Q9QY0l1/dafu7qrc/Fr2GN9IKUMwgjoNGa2DwCHO7Pu0risK4ceNoaWlh27Zt6PV6kpOTO63ckiR1DxkK3UDR6dA88ATqey8hPnsPVVHQXHZVp+1vbIwvJp2GV77LR2/QwjEwWxQSk8zt2o6iKFx55ZU4nU7S0tLQ6XQMGTKkcwotSVK3kFcfdRNFr0cz+2noNwTx6d9QN37TqfsbHuHNH6+MYoezlmOKncP7m8g50v57GE5M0hMfH8+GDRvYt29fJ5RWkqTu0uZQ2Ldvn3to5crKSv72t7/x/vvvU1VV1Vll6/EUgxHNL5+G/kMQn7yL+t3qTt1fv2AL798yiHRtHQU0sWd7Y7uH2wbXJD2TJ0+mV69erF27loyMjE4orSRJ3aHNoTB37lw0Gtfin376KU6nE0VRmDNnTpvWT09P59FHH+WRRx5h0aJFZ1xu8+bN3HrrrRw5cqStRbukuYLh9zBgqOuMYd3yTt1fXKAXr1wTwz5zPaWihW2b6qkobf8dyydmb4uMjCQ1NVVO6ylJPUSbQ6GiooLAwECcTie7d+/mF7/4Bffff3+b3gxUVWXu3Lk8/fTTvPnmm2zatIm8vLxTlmtsbGTlypUkJCS0rxaXOEVvcAXD4JGIf89B/fqrTt1fsLeel6+J4YhfI1Wqg03ra6mtbv/NbSdmbwsLC2PVqlUeE+SS1JO1ORTMZjNVVVUcOHCAyMhITCYTQJvGxcnKyiI0NJSQkBB0Oh0pKSls27btlOXmz5/PtGnT0Ov17ahCz6DoDWgefBJlxOWuy1UXfd6pdz77GrU8d1UkxcFN1DtU1nxTQ11t+4NBr9czdepUQkJCWLlyJceOHeuE0kqS1FXafPXR5MmTeeqpp3A4HNx9990AHDx4kIiIiHOuW1FRgc1mcz+32WxkZraeZ+Do0aOUlZUxbNgwlixZcsZtpaamkpqaCsArr7xCYGBgW6vQik6nO+91O5P43Z+o+ftfsC9fgEl14nPfYyiajrse4Kf1fvnmIP62+giOLJVVq2u49WcxBPga2r3dWbNm8fHHH7NixQp+9rOf0adPnw4r84W6WI91Z/PEentinaFj693mUJg+fTojR45Eo9EQGhoKgNVq5cEHH7zgQqiqyqeffsrs2bPPueykSZOYNGmS+3lZWdl57TMwMPC81+1s4tb7ULQ6Gld+hb2sBGXWr1F0HXP2dLp635Hsz1IqcGTBp/86ylWT/Qj2af/+rr/+ehYuXMgXX3zB9ddfT0xMTIeU+UJdzMe6M3livT2xztD+eoeHh5/xtXZ9BA0PD3cHwr59+6iqqiI6Ovqc61mtVsrLy93Py8vLsVqt7ud2u53c3Fz+8Ic/8Mtf/pLMzExeffVVj22jVjQaNLfMQrn5bsS271DffQlh79yZ0G5IthLYX4u3qmXZykqyShvbvQ2TycT06dMJCAhg2bJl5ObmdkJJJUnqTG0Oheeff56DBw8CsGjRIt5++23efvtt/ve//51z3fj4eAoLCykpKcHhcJCWltbqbliLxcLcuXN57733eO+990hISOCJJ54gPj7+PKrUc2iumeEadvvgbtTXnkZUVXTq/i4f5EtUkoEgYWD1mmo2ZVe3extms5kbb7wRf39/li5dKoNBki4xbQ6F3NxcdzvxmjVreP7553n55Zf55ptz33Sl1WqZNWsWL7/8Mo899hhjxowhKiqK+fPns3379vMvvQfQjJ2E5uFnobgA9ZUnEIWd+yY7bIAXcQMNRCkmtnzfwH/2lKG2s8P7RDD4+fnJYJCkS0yb+xROXAlTVFQEQGRkJAD19fVtWn/YsGEMGzas1c9mzpx52mVfeOGFthbLIygDh6N5/E+o7/wR9ZUn0Mx+GiVxYKftb0B/C1pVgf1wYH89r1bm86uUMCx6bZu3YbFYuPHGG1m4cCFLly7lhhtuICoqqtPKLElSx2jzmUJiYiL//Oc/+eyzzxgxYgTgCggfn/aP0S+1nxLTG82Tr4KfFfXN5zp9WIzEASbiEg3013jhLIDffZ1DYW37phM9EQx+fn4sWbKE48ePd1JpJUnqKG0OhV/+8pdYLBZiYmK49dZbASgoKOC6667rtMJJrSlBoWie/AskDnQNi/HfjxGdNBuaoij0H2wmJt7AII03YY0Gfvt1Ntvz69q1nRPBcKKPIScnp1PKK0lSx1BEZ94h1QUKCgrOa71L+dI14XAg/vMPxPqvYfBINPf9BsVkadO67a23EIL0rQ3kZbeQaWxgQ30NMwfamDkwEE07ht5ubGxk4cKFVFZWMmXKFHr16tXmdS/UpXysL4Qn1tsT6wzddEmqw+FgwYIFPPzww9xxxx08/PDDLFiwoE13NEsdS9HpUO54COW2B2DvdtQ/P4EoLeqcfSkKg0dYCIvSk9BkYWqglf/sLeelb/OoaWr7HdBms5kZM2ZgtVpZtmwZR48e7ZTySpJ0YdocCp9//jl79+7l/vvv57XXXuP+++9n3759fP75551ZPukMFEVBM/F6NL/+A1RVoL78W8SB9E7Zl0ajMGy0hZAIHUFVBh6IDWF3UQO/WXGMQ2Vtv5/BZDJx4403EhQUxIoVK8jKyuqU8kqSdP7aHAqbN2/miSeeYPDgwYSHhzN48GD+7//+j++//74zyyedg9JvMJrfvw5+AahvvYD69VedMmaSRqMwfIwXwWE61FyFJ5MiUBSFp7/JYenBijbv88QNbifGSjp06FCHl1WSpPPX5lC4xLseejQlOAzNU6+hDE9xDaY35y+dcge0VquQPNaLwBAdRQcc/G5ABMPDvfloRwl/2pDf5uYko9HItGnTCA8PZ9WqVRw4cKDDyypJ0vlpcyiMGTOGv/zlL6Snp5OXl0d6ejqvvfYao0eP7szySW2kmMwoDzyOcvM9sHOzqzkpv+MvAdVqFUZc5gqGjJ12fh4dxH3Dg9lZUMevVxxjf0nbwshgMDB16lSioqJITU1l9+7dHV5WSZLar81XHzkcDr766is2btxIZWUlVquVlJQUbr75ZnS67pvq2ROvPjoXcWgv6j9eA3sjys9noxk9wf1aR9Xb4RBs+66eshIHQ0dZsPuovLYxn5L6Fm5JsjEzKRCt5txXJzkcDr7++muOHj1KSkpKq+FPOkpPPtZn44n19sQ6Q8defXTWUDjT/LtCCJSTLkdMSkpqc2E6mgyF0xNVFagfvgaH96NcfjXKzPtRjMYOrffJwTBkpAVbpJY524r59lgNiYFmfjs2jBDvcw/D7XQ6SU1N5dChQyQnJzNmzJhWf18Xqqcf6zPxxHp7Yp2hY0PhrB/x//73v5/25yf+YU+Ew9/+9rc2F0bqGoq/Fc1vXkIs/hyx8ivEkYNofvEEdOBY8zqdwojLvdi2sZ70rQ0MFmYeSwlneLg3f99axKPLs3lgRAgTYn3P+iav1Wq56qqr0Ol0bN++naamJq644ooODQZJktpG3rzmAcT+Xahz34CmRnzu+w31Qzr2k7jTKdi2sZ7SIgcDh5vp1dtIcV0zb6UVcqC0kTFR3sweGYqv6ezNjEIINm3axM6dO0lMTGTSpElotW0fb+lMPOlYn8wT6+2JdYZunE9BujQpA4aiee5tiO9H7fuvoH7wF0R9bYdt/0Tnc0i4jr07Gjl6uIkQbwMvTYrmrqFBbMuv55Hlx9iSd/Z9KorC2LFjGTNmDIcOHWL58uW0tLR0WDklSTo3GQoeQvG3ovn1H/D+f7+E3VtQ//Ao4tDeDtu+VquQnOJFWKSe/bsayTxgR6tRmNHfxuuTY/A36fjT+nzeSiug7iyXriqKwogRI7jiiivIzs5m8eLFNDU1dVg5JUk6OxkKHkTRaPC68Q7XaKt6A+rrz6B++U9EB30a12gVho2xEBGj5+BeOxl7GhFC0CvAxF8n9+LWJBvrs2t4ZPmxcw6sN2jQICZPnkxRURH//e9/2zxEuyRJF0aGggdSeiWgee4tlHHXIFYvQn35N4jcYx2ybY1GYehIC9FxBrIymti/yxUMeq3CHYODePWaGLwNGl78No830wqoPctZQ58+fZg6dSo1NTV8+eWXVFZWdkgZJUk6MxkKHkoxmtDcORvNI89CbTXqy79FXb4A4Wz7IHdn3LZGYVCymbg+Ro5lNpO+pQFVdV3PkGAz88a1vZg50MZ32TX8ctlRNuXUnPGO+ejoaGbMmEFLSwtffvmle5InSZI6hwwFD6cMGoHmhb+hDBuDWPQ56p8f75A7oRVFof8QE4lJJvJyWti+qR6n0/XGr9dquH1QEK9f24tAi55XNxbw8vp8SutP34wVEhLCLbfcgsFg4H//+x/Z2dkXXD5Jkk5PhoKE4uOL5oHHXfcxlJegvvRr11nDBQ6LrigKfQaYSBpmprjAwZb1dbQ0/3hGEBtg4rVrYpg1LJg9RfU8vOwYSw9W4FRPPWvw9/fnlltuISAggKVLl7J///4LKpskSacnQ0FyU5IvQ/OHv6EM/eGs4U+/RRy/8HkPYhOMDB1toaLMSdq6WuyNP84Wp9UoTOtn5d3rY+kfZOajHSU8viqbzPJTh+T28vLipptuIjo6mjVr1rB582Y5UKMkdTAZClIriq+/66zhoaeguhL15d+gfvUJovnCLguNjDEw8nIv6utUNq2po662dd9FiLeB5yZE8sRl4VQ0Onn86xw+2Fp0yuWrBoOB66+/nv79+7N161ZSU1NxdkA/iCRJLjIUpNNSho1B88f3UVImIr7+CvWFRy54Ep/gMD1jrvCmpUWwaU0dleWtm6cURWFsjC/v3xDLlMQAVmVVMXvpUVKPVKGedEag1WqZOHEio0aNIiMjg8WLF2O32y+obJIkuchQkM5I8fJGc9cjaH77EigK6pvPoX70OqLm/C8NDbDpuGySNzqdwvfr6iguOLVz2aLXcn9yCG9c24twXwPvbi7iydU5rZqUFEVh1KhRXH311RQUFPDll19SXV193uWSJMlFhoJ0TkrfQWiefwfl+pmI7ZtQn52Nuv5rhHp+zTbePloum+SNt6+WrRvryc46fdNUbICJP18VzaNjwiipa+Hxr3N4d3MhVY0/nmH07duXG2+8kYaGBubPn3/eY2FJkuQiQ0FqE8VgRDPtDjTPvwNRcYjP30f98xOIY5nntT2jSUPKBG+CQ13jJR3Y3XjaTmNFUbgyzo/3p8YxvZ+Vb49V8+CSo/xvfzktTleHdUREBLfeeismk4n//e9/ZGRkXFBdJcmTddkoqenp6cybNw9VVZk4cSLTp09v9frq1atZtWoVGo0Gk8nEL37xCyIjI8+5XTlKavt0RL2FEIitGxBf/hNqqlAuvwblxjtRvH3bvS1VFezb2UjOkWbCovQMHWlBqzvzCK75Nc18vKuErXl1hHjruWtoEClRPiiKgt1uZ8WKFeTl5bWal0Eea8/hiXWGLpxkp6Ooqsqjjz7KM888g81m46mnnuLRRx9t9abf0NCAxWIBYPv27axatYrf//7359y2DIX26ch6i8YGxJJ/I9YuA5MFZfodKOMmo7RzuGshBEcPNXFgtx1/q5YRl3lhMp/9JHZ3UT1zd5SQU9VE30Azs4YHkxhoxul08u2337J//35iY2O55pprCA8Pl8faQ3hineESHDo7KyuL0NBQQkJC0Ol0pKSksG3btlbLnAgEALvdLidYuQQoZguamfehee4diI5D/HsO6ou/RmS0b75lRVGI72sieayF2mon36XWUl159v6KwaFevHltL345KpTiumaeWJXDq9/lU1zv5Morr2T8+PFkZ2ezYMECKioqLqSakuRRuiQUKioqsNls7uc2m+20/6hff/01jzzyCP/617+45557uqJoUgdQIqLR/OZFNA89CfZG1Deexfney4ji9p3FhUUaGDvRGwRsWltLUf7ZR2/VahSu7u3P36fGc9tAGzsK6nh42VHmbCsmus8Apk2bRn19PXPmzOH48QsfukOSPEGXNB9t3ryZ9PR0HnzwQQA2bNhAZmYm995772mX37hxI+np6Tz88MOnvJaamkpqaioAr7zyCs3NzedVJp1Oh+MCh3G4FHV2vUVzEw1L51P/308RjmYs196E1y33oPFpe39DQ72DNSsKKStpYugoK4OHB7TpzLG8vpmPt+ayeF8Reo3CrUPDuTbWwpKvFlBaWspVV13F2LFjPeYs1BP/xj2xztD+ehsMZ547vUtC4fDhw3z55ZfuPoKFCxcCcOONN552eVVVueeee/jkk0/OuW3Zp9A+XVVvUV2JWPwvxMZUMJtRptyKMuF6FL2+Tes7HYLd2xvIz2khLErPkJEWdGfpgD5ZQU0z/95Tync5tXgZNNwxJBT18HccO3KEPn36MHHiRPRtLMelzBP/xj2xznAJ9inEx8dTWFhISUkJDoeDtLQ0kpOTWy1TWFjo/n7nzp2EhYV1RdGkTqL4BaD5fw+jef5tiOuL+HIe6rMPoW5eh1DVc66v1SkMHWWh32AThbktbEqtpb6ubfdFhPsa+L/LInjz2l70CzTzj60FfNmQgH/vIWRmZrJgwQI5N4MknUGXXZK6c+dOPvnkE1RVZcKECcyYMYP58+cTHx9PcnIy8+bNY+/evWi1Wry9vZk1axZRUVHn3K48U2if7qq3OJCO+tUncPwIRMaimfFzSBrepqacksIWdn7fAAoMG20hOKx9n/KLWgy8tyGLPUUNRCtVJFbvRqcIrrrqKuLj48+3Shc9T/wb98Q6wyV4SWpnkqHQPt1Zb6GqiO0bEYs+h9Ii6N0fzYz/h5LQ/5zr1tc52baxntpqlb4DTfTuZ2xz38CJOu8rbuDfe0rJKqxgaP0evFqqGTRkKJePTUHbzstoLwWe+DfuiXUGGQqtyFBon4uh3sLRgvjuG8Ty+VBdCUnD0Uy/AyWm91nXczgEe7Y1kH+8hZBwHUNGWTAYzt0C+tM67y2u54v0YhzZu4lsysXgF8hNU68nKKD9N99dzC6GY93VPLHOIEOhFRkK7XMx1Vs0NSHWLkOs+h/U18KQ0Wim/QwlMvbM6whBdlYz+9MbMZk1JKdY8LfqzrqfM9V5X3EDizalY8nbhdBoCE4ay41jBuBt7BlnDRfTse4qnlhnkKHQigyF9rkY6y0aGxBrliBWL4bGehiWguaGmWcNh8oyB9u/r6fZLug/xEyv3oYzNiedq847jhSyYc0qtPYa8i296Dd0BFP7B2E1nz1sLnYX47HubJ5YZ5Ch0IoMhfa5mOst6usQqUsQa5ZAY4PrzOH6mSgxp+8MbmpSSd/SQEmhg7BIPYNHmNGfpjmpLXV2OBwsT/2WnMMHqNH5kuE7mDG9Q5ne30qkr7FD6tfVLuZj3Vk8sc4gQ6GVn4aCEAK73Y6qqmftiDQajTQ1XdhsYpcCIYR7kMFLZXC4H8NhqevMYWAymim3osT3PXXZH8ZNythjx2TRMHy0hYDA1p/w21PnrKwsvklNpcWpcsjSj3x9KCOjfLixn5V+wZZzb+Aicikc647miXUGGQqt/DQUGhsb0ev16HRnP/X3pDsfHQ4HLS0tmM3mS+qfRjTUI9YtR6QuhrpaSByI5tqbof+QUwK/oszBzs0N2BtUEpNM9O5rRNG4lmlvnWtra1m1ahUFBQUYgmP4XulNlUNLYqCJaf2sjI70Qau5+O+KvpSOdUfxxDqDDIVWfhoK9fX1eHl5nXM9TwoF+PH3cin+0wh7I+K71YjVC6GqAmJ6o1wzA2X4GBTNj53CLc2CPTsaKDjegi1Yx5CRFixemvOqs6qqbN++nS1btmDx8sKv3xi+KTFQVNdCsJeOKYkBXBXvj5fh4u2UvhSP9YXyxDqDDIVWfhoKJw/BfTaeFgonfi+X8j+NaGlBfL8WsWohlBRAUCjK1dNRxkxEMbra/YUQ5GU3s3dnI4oCA4dbGDL8/IfOLioqYvXq1VRVVTFkyFB00Uksy6xhf0kjJp1rAqApiQEXZb/DpXysz5cn1hlkKLQiQ6FtekIonCBUJ6RvQf36f3DsMHj7oIy/FuXKKSi+AYDrZrddmxuoLHcSm+BNnwEaDMbzG9WlpaWFjRs3snfvXqxWK1dffTU1Wl+WH65gQ3YtDlUwNMyLKX0CGBbuddE0LfWEY91enlhnkKHQysUYChEREcyYMYN3330XcLXpDx06lKFDhzJlyhQ++ugjADIzM4mPj0ej0TBhwgTi4+N56aWXCA0NpampiTvvvJMHHngAcHWAPvnkk1RXV9Pc3MyoUaN49dVX21ymnhQKJwghICsDdfVC2L0VtFqUkeNRJk1FiYpFVQVZGU0cPmDHYFAYPMJCSPj5D4SXnZ3NmjVraGhoYMSIEYwYMYLaZsGqrCq+zqyiotFBiLeeyQn+TIrzw9fUvZe09qRj3VaeWGeQodDKxRgKCQkJ9OrViyVLlmA2m1m7di1//vOfCQsL49NPP3UvN2rUKFauXInVagVg/vz57Nmzh5dffpmKigrGjRvHqlWriIiI4Pbbb+euu+7immuuASAjI4N+/fq1uUw9MRROJoryEWuWItLWQHOTq1N64g0weAQaxZ91q/KprVaJijUwYIgZveH8Ps3b7XY2bNjAwYMHCQwMZNKkSQQHB+NQBVtya1l+uJL9JY3oNQpjY3yYnOBP30BztwzX3VOP9dl4Yp2hY0Ph0r475xzU/3yIyD12+tcU5bQTxZ+LEhWL5rb7z7nclVdeyZo1a7j++utZtGgR06dPZ8uWLW3ej9VqpVevXpSUlBAREUFJSUmrkWPbEwieQAmNQLnjQcT0OxAbViO+XY76/p/AFoxlyi1cNmY0mTlGsg42UVrUwqDk8ztrMJlMXH311fTu3Zt169Yxf/58hg0bxqhRoxgb48vYGF9yqpr4OrOSdUdr+PZYDTH+Rq7p7c/4WF+8L+KOaUmCLho62xNNmzaNxYsXY7fbycjIYOjQoe1aPz8/n6amJveb//3338+tt97KnXfeyT/+8Q+qq6s7o9iXPMXLB821N6H504doHnwSbEHUffoeylP3krjzH1w2oAq9XmHrd/Xs3FxPU9O5h/E+nbi4OO644w769evHjh07+OKLL8jPzwcgxt/IL0aEMm9Gb345KhSdRuEf24u5539ZvP19ARklDef1gUSSukKPPlM42yf6zu5o7t+/P3l5eSxevJgrr7yyzestWbKELVu2kJWVxUsvvYTJZAJg5syZjB8/nm+//ZZVq1bx+eef880332A0XnxXvVwMFK0WhqegHZ6CX10VlQv/jdjyLb6b1pDSqy9Hh95N1vFwSoscDBhiJiJG3+4mHpPJxKRJk0hISGDdunV89dVXDBgwgLFjx2IymTDrNVzd25+re/uTWd7IN1nVbMiuYe3RGiJ9DUyM92NCrB8Bl/hwGlLPIs8UOtHVV1/NH//4R6ZPn97mdaZOnUpqaiqLFy/mz3/+MyUlJe7XQkNDue2225g3bx46nY5Dhw51Qql7Hn2v3mh+PhvNq/NQbnsAbVM9CQufZOzOF7HYy9i1pYEtG+rbPInPT8XExHDHHXcwbNgwDhw4wGeffcbBgwdbnQ0k2MzMHuU6e3hkdCjeBi2f7Cpl1sIsXl6fx+bcWlqc8uxB6n7yI0onmjlzJr6+vvTr14+0tLR2rTt48GBuuukm5s6dy1NPPcW6deu47LLL0Ov1lJSUUFlZSWhoaCeVvGdSLF4oE69HXDkFMg/gt/5rxqz/HTmhl3NYvY1vi5rp3VdP7yRvtNr2nTXo9Xouu+wy+vTpw7p161i9ejUHDhxgwoQJBAQEuJcz6zVMivdnUrw/edVNpB6p5ttj1WzNq8PXqGVcL1+ujPMjLqDt80VIUkeSodCJwsPDuffee897/dmzZzN58mQeeeQR1q9fz3PPPeduLnrmmWcIDg7uqKJ6FEVRoM8AlD4DUOpqiN28jtC0t8jwu4LDjCL/wHGS+jgIGhbX7jfm4OBgbrnlFvbt20daWhr/+te/GDp0KCNHjjxlXuhIPyN3Dwvm50OC2FVYz9qj1XydWcWyQ5VE+xm4ItaPcb18CfLq+fNJSxcPeUmqh+jpl6SeTVvqLISAo4coSdvPPmcSDeYQQqr30j+sEq+UMSi2oHbvt6GhgU2bNpGRkYG3tzeXXXYZCQkJZw2auiYnG4/XsO5oDQfLGlGAASEWrujly5hon3ZdvSSPteeQ9ymcRIZC28hQaHudHQ2NHN1wlMzKYBCCuJzlxBuy0Y0e5xpvydS+0VILCwtZt24dZWVlhIeHM378eIKCzh0yhbXNrM+uYf2xagpqW9BpFJIjvBgX40tyhDdG3dm7BOWx9hwyFE4iQ6FtZCi0v84N9SoHtlZSWKLF1FxF4qEvCK/cgWbwKJTRV0D/oSjnGI33BFVVOXDgAGlpadjtdgYMGMDo0aPbNHijEILMcjsbcmrYmFNLZaMDk07DyEhvLo/xYWiYF3rt+c0j0dN4Yp1BhkIrMhTaRobC+de5vNTB/l2NVFc68Rdl9D3wKdbCdNeYS8PHoowcD737oWjOfTFfU1MTW7ZsYc+ePWi1WoYPH87QoUNP6W84E6cq2F/SwMacWtKO11DbrOKldwXE2GhfhoRZ3AEhj7XnkKFwEhkKbSND4cLqfGL01YN77dgbBaHetSQWrsRr12poboaAQJTksSgjLodeZ+83AKiqqmLTpk0cOXIELy8vRo8eTb9+/dC0IVhOcKiC9MJ6Nh2vZUtuLfUtroAYEelNSpQPkwZGU1tVeUH1vtR44t83yFBoRYZC28hQ6Jg6OxyCo4ebyMqwozohKlpDgmMvxvR1sG8nOB0QGIIyPAUl+TLX3A9nCYj8/Hw2btxIcXExVquVlJQUYmNj233VU4tTsLuonrTjtWzJq6WuWcWs1zAszIvRUT4kR3hh0ff8ITY88e8bZCi0IkOhbWQodGydm+wqmQfsZB9pRlEgNsFIfLQD/YEtiO2bICMdnE6wBaMMG4MyLAXiEk/bxCSE4MiRI6SlpVFVVUVoaCgpKSlERkaeV9kcqmBvcQPppS18m1lKld2JTgODQlwBMTLSu8feRe2Jf98gQ6GVizUUSktLeeGFF9i5cyd+fn7o9Xpmz56Nn58ft9xyC6+99hq33347APv27eOaa67h2Wef5cEHH+TXv/41mzdvxsfHB4Dbbrvtgu53ABkKnVXnhjonB/fZyc9pQaeDuEQjcX1M6FrqEelbEDt+CAiHA/ytKENGoQwdDX2SUHSt+xGcTicZGRls2bKF+vp6oqKiGD16dKuBENsjMDCQ4pJSDpc1sjmvjs25tRTVtQDQx2ZiZKQ3IyK8ifHvOTfKeeLfN8hRUi96QghmzZrFLbfcwnvvvQdAXl4eq1evxs/Pj759+7J06VJ3KCxevJj+/fu32sYzzzzD9ddf3+Vll9rH4q1l2GgvEvo5ObTPzuH9TRw73ExsHyNxIyagHzvRNdf03u2Ind8j0tYivl0JZi+UgcNhyGiUpGEoZgtarZakpCT69u3L3r172b59O19++SXR0dGMHj36vO5g12oU+gVb6Bds4e6hQRyvbmZLXi1b8+r4fHcZn+8uI9hLz4gIL0ZE+pAUbD7tlUyS5+iyUEhPT2fevHmoqsrEiRNPGQ9o2bJlrFmzBq1Wi6+vLw899FCbruU+m4+2F3Os0n7a15TzHDo7NsDEfckhZ11m48aNGAwG/t//+3/un0VGRjJr1izS0tKIiIigrq6O0tJSAgMDWbduHRMnTmx3WaSLh4+fluSxXlRXOji0387h/XaOHrYT18dIbIIZw6jxMGo8orkJDuxynUXs3gZbNyC0OkhMQhk0EmXwCHSBIQwdOpSkpCT27NnDjh07WLBgAdHR0YwcOfKsn/LORlEUYvyNxPgbuTUpkPKGFrbn17Mtv45vjlSz/HAVJp3CoFAvksO9GRbuJe+m9kBdEgqqqjJ37lyeeeYZbDYbTz31FMnJya3aTHv16sUrr7yC0Whk9erVfP755zz22GNdUbwOd/jwYZKSks66zJQpU1i2bBlJSUkMHDgQg8HQ6vWXXnqJt99+G4B33nlHzp9wifAL0DHyMm+qKx0c3t/E4f1NHDnURK/eRuL6GDGZja6zgyGjXdOKHjnkCog9WxH/+QfiP/+A8GiUgcnoBiUzbPBgBg4cyJ49e9i1axf//e9/iYyMJDk5maioqAtq9rFZ9FyT4M81Cf40OVT2FjewPb+O7fl1bM2rA1zDgA8P92JomBf9gizo2zkmlHTp6ZJQyMrKIjQ0lJAQ1yfslJQUtm3b1ioUTn4TTUhI4Lvvvrvg/Z7tE31XdjQ//fTTbN26FYPBwDPPPAPADTfcwEMPPURWVhbTp09n+/btrdaRzUeXNr8AHSMu01FT5SQrw86RQ00cO9xEZC8D8X2NePtoUTRaSOiPktAfbrkHUVyA2LPN1dSUugSx6n9g9kLbfzDDkoYzaPpU9ucVsGPHDhYtWkRISAjDhw8nPj7+gvsEjDoNyRHeJEd4I4Qgt7qZHQV17CioZ8nBCv53oAKTTmFgiCsghoZ5EebT/uHGpYtfl4RCRUUFNpvN/dxms5GZmXnG5deuXcuQIUNO+1pqaiqpqakAvPLKKwQGBrZ6vbi4GF0b7zJt63Lt1a9fP1auXOne/quvvkp5eTnXXHMNWq0WRVEIDw9Hr9fz3Xff8ac//YmdO3ei0WjQ6XRoNBq0Wm2Hls9oNBIYGIhOpzvld9bTdWedAwMhrjdUVzWzb1cVRw7VcvxoMzHxXiQN8Sc41Nx64QGD4Gf3ojbU07x7G807v6dp5/eoO9LQAsNi4kkeNJKDAb3Zkp3LihUrsNlspKSkMGTIkFY3wV1IvYOCYFhvuB+ob3awM6+arTlVbM6pZNv2YgDCfI2MiPYnOcr18DN3f1OTJ/59Q8fW+6LraN6wYQNHjx7lhRdeOO3rkyZNYtKkSe7nP+1xb2pqQqs99/XYnXmmMGbMGOx2O3PnzuWuu+4CoK6uDiEETqcTIQQOh4Pf/va3lJeXI4RAVVVUVcXhcKCqKk6ns0PL19TURFlZmUdenXGx1DlxoIaY3j4cy2wiJ6uBnCP1BNi0xCUaCY3Qo9H85FN3QpLrcet9aPKzEft34di3E1Z8SZzTQS+9gSN9hpJer2fp0qWkpqYycOBABg0a1OFXmvXzhX4D/bhroB+Ftc2kF9azq7Ce1EOlLNlXjALEBhgZFOrF4FAL/YMtmM4xNlNnuFiOdVe75K4+slqtlJeXu5+Xl5e7J6s/2Z49e1i4cCEvvPBCm2/7vxgpisLcuXN54YUX+Pvf/47NZsNsNvP000+3Wm7EiBHdVEKpu5jMGvoNMpPQz0TusWaOHm5iR1oDJotCbG8j0XEGDMbWb6aKokBkLEpkLFwzA2FvhMz9KPt3kXAgnd77t1DgFcCu0Hi2bm1k+7ZtJPaKYfw1k0/pq+oIYT4GwnwMXNsnAKcqyKqwk15Yz56iepYdqmRRRgU6jWtioYEhFgaGWEgMNJ9zAD/p4tAl9yk4nU4effRRnnvuOaxWK0899RS/+tWviIqKci9z7Ngx3njjDZ5++ul2XZd9sd6ncLGR9ylcnHUWqqC40MHRw02UlzjQaCEi2kCv3gb8rW37zCYqyxEZuyEjnYqsQ+wx+HIwIByHRkuYRjAoJor40Snogjp/UqYmh8qB0kb2FtWzp7iBIxV2VAE6jUJioIkBwRaSQiz07aSQuJiPdWe6JG9e27lzJ5988gmqqjJhwgRmzJjB/PnziY+PJzk5mRdffJHjx4/j7+8PuCr5u9/97pzblaHQNjIULv4611Q5OZbZRP7xZpwO8LdqiYk3EB5tQKdrW4euEAKK8mncv4vMrCPsqm+mRm/C0tJEf3sVA0IC8embhNJnAASFdXpHcX2zk4zSRvYWN7C3uIFjlSdCAuKtZgYEmxkQbKFvkLldc0WcyaVyrDvaJRkKnUWGQtvIULh06tzS7Bp8L/tIE3U1Kjo9RMYYiI4z4BfQ9hbfwMBAiouKyNm1g71795BT14AiIKa2jAEV+URrVLQJ/V1XQPXuD5ExriuiOlF9s5ODpY3sK2ngQEkjWRWNOFRQgGh/I/2DzPQNMtMvyEywV/uvbrrUjnVHkaFwEhkKbSND4dKrsxCCijInOUeaKMxtQVXBL0BLVKyBiBg9BkP7Jtmprq5m3759ZOzbR0NTE14I+tUU07fgCH4tjWAyQ1xflN79UHr3g9iEdk8o1F5NDpXD5Y1klDRyoLSRg6WNNDpUAKxmHf2CzCQGuoIiLsB0zvskLtVjfaFkKJxEhkLbyFC4tOvc3KSSf7yF40ebqalyotFASISeqF4GgkJ1p165xJnr7XQ6OXbsGPv37ycnJweACB8v+qp24nIPYSjIASFA0UBEDEp8omswv7i+EBLeqU1OTlWQU9VExg8BcbCskZJ613hNeo1CnNVEYqCJxEAzfWxmgrx0rcrTE471+ZChcBIZCm0jQ6Hn1LmqwkFedjP5x1tobhIYjAoR0XoiYwz4WbXuN8m21Lu2tpaDBw9y4MABqqur0ev1xPeKoa+XifDKQpSjh+DYYWhscK1g8Ya4PiixfVBiE11zR/j4dmp9KxodHCxt4FCZnUNljRypsNPsdL1t+Zu09Ak0k2Az0cdmZmRCBM11VZ1anouRDIWTyFBoGxkKPa/OqlNQUuQKiOICV/OSl7eG8Gg9EdEGYuND2lxvIQSFhYVkZGSQmZlJc3MzXl5eJCQkkNgngSBHMxxzBYQ4eggKckG4mnkIDEHpleAKiF69IToexdx5zU4tTkF2lZ3DZXYOlzdyuMxOQW2z+/UwHz0JVjO9bSZ6W03EWo09fi4JGQonuRhDISIighkzZvDuu+8C4HA4GDp0KEOHDuXTTz9l/vz57Nmzh5dffrnVeqNGjcLb2xtFUQgKCuLtt98mODi4Q8okQ6Fn17mlWaUwr4X84y2UlThAQIDNQHCYhvAoPd6+bX9TdDgcHDt2jEOHDpGdnY2qqvj5+dGnTx/69OnjuseoyQ45WYjsTDiW6fpaXuLagKK4mpmie0NMPEpMb4iKRbGcez7q81XX7CSr3E5+o4Y9eeVkltspb3D9fytAhK+BeKvJ/YgNMOLVAVc7XSwuuZvXPI3FYuHgwYM0NjZiNpvZsGFDm4c9/vLLL7Farfz5z3/m3Xff5cUXX+zk0ko9gd6gITrOSHScEXujSkFuC2VFgkP77BzaZ8fHT0NYpJ6wSAM+fpqz9gvodDoSEhJISEjAbrdz5MgRDh8+zPbt29m2bRsBAQEkJCTQu3dvbH2S3NsStdWQ7QoKkZOFOLwPtq7H/akzOAwlKg6i43786hfQIfX3NmgZEubFpMBAyuJcQ4dUNTrIqrC7HuV29hU3sD67xr1OqLee2AATcVYjcQGuoLCadR4/nlOPDoV9OxuoqXKe9rXzHTrb119L0rBzn4lceeWVrFmzhuuvv55FixYxffp0tmzZ0ub9jB49mn/+85/tLp8kmcwa4voYGZkSSO7xEgrzWijMa3aP2mrx1hAaric0Uo/VpkU5TSe1e1smEwMGDGDAgAE0NDSQlZVFVlYW27ZtY+vWrfj5+REfH098fDyhoaEoA4e75on4gaiphONHETlHEMddD3Zs+jEofPwgKg4lqhdE9nLdtR0aidIB4375m3XuQf5OqGp0cKTCztFKO0crmzhaYef73Fr3675GLbEBRmIDTPT6YZjxKD+DR80x0aNDoTtNmzaNN998k0mTJpGRkcFtt93WrlBITU2lb9++nVhCyROYLa6AiOtjpMmuUpTfQlF+C9lZTRw93ITeoBASpiMkQk9QiB694cwBYbFYGDRoEIMGDaKhoYGjR49y5MgR0tPT2blzJxaLhdjYWGJjY4mKikKv16P4BkDScJSkk4KioR5yjyHyjkHuUUTuMcSapeBwuMJCq4OwSJSIGIjohRIZA+ExYA284E/x/mYdwyO8GX5SUNQ3O8muauJYpZ1jlU1kVzax4nCluzNbq0C4r8EdEiceQV56ND3wrKJHh8LZPtF3dkdz//79ycvLY/HixVx55ZVtXu+WW25Bo9HQr18/nnjiiU4rn+R5jCYNMfFGYuKNOFoEJUWugCgudJCX04KigDVIR3CYjuBQ/VmbmSwWC0lJSSQlJdHU1ER2djZHjx7l8OHD7N+/H61WS1RUFLGxscTExODr++MVSorFyzWpUOKPw+ULhwOKC1xBkZ+NyMtBHN4PW05qfjJbXHNNhEdDeNQPX6PBz3pBYeFl0DIg2MKA4B/fL5yqoKC2mezKJrKrmsipcl359F3Oj2cVJp2GKD8D0X4/nlFE+RkJtFzaTVA9OhS629VXX80f//hH/vvf/1JZWdmmdU70KUhSZ9LpFcKjDIRHGVBVQWW5k5LCFooLWsjYbSdjtx2TWSEoVE9wqI7AEN0pA/WdYDQaSUxMJDExEafTSV5eHtnZ2Rw7dozs7GzANShmTEwMMTExhIeHnzIsvKLTQUQ0SkQ0MN79c9FQB/nHEfnZUHAckX8cset7+G71SWHh5QqJ0EjqE/oifAIgLApsQed9h7ZWoxDlZyTKz8jlJ/28vtnJ8eomjlc1k1Nl53h1M9sL6lhztNq9jFmnIfKHgIjyNbi/D/bSoz1LU93FQoZCJ5o5cya+vr7069ePtLS07i6OJJ2WRqNgC9JhC9LRb5CZxgaVksIWSoscFOY1k3vMdbmnX4CWoBBXQAQE6k47HpNWq3W/+Y8bN47Kykqys7PJyclh9+7d7Nq1C51OR0REBFFRUURHR2Oz2c74yVqxeP84EdEPhBBQW+0KiYLjUJiLKMxD7NlG3abUH1fW6SEkHEIjUEIjXV9Dfvh6npfMehm09Auy0C+o9frVdge51c3kVjdxvLqJvOpmdhXUsfboj32aOo1ChI+BCD8Dkb4GIk56XEyXzMpQ6ETh4eHce++9p31twYIFfP311+7nS5cu7apiSdJZmS0/NjOpqqCqwklZsYPSohaOHGoi62ATGg0E2LTYgnXYgnUE2HRofzIEhaIoWK1WrFYrw4YNo6Wlhfz8fHJycjh+/DgbN2507c9sJioqisjISCIjI/Hz8ztr84uiKODrD77+KH0HtXrNatBTfmA3ojAPivIQRfmu/oudm0GoP55d+Pq7LpsNiYDgcJSQMAiJgKBQFIOx3b8zP5MOP5OOpJDWYVHX5CS3pon8mmbyqpvJq3E1SW3OrUU96ToXf5OWCF8D4T4/PH74PtRHj6GLO7nlfQoeQt6n4Fl1hs6pt6NFUFHmoKzYQVmJg+pK1ydhjQb8bVr3GUeATYdOf/amktraWnJzc8nNzSUvL4/6+noAvL29iYiIcD/8/f3b3EZ/pjqLlhYoLYSifERxvqv/oqQAivJdZx0nCwh0XT4bFPrj16AwV2B00L0WLU5BUV0z+TU/Pgprm8mvbaba/uPZhQIEWnTuOSxCffSu771dX08MPy5vXjuJDIW2kaHgWXWGrql3S7NKeamT8hIHFWWukBACUMDXT4stSEtAoCskzBbljG/uQggqKyvJy8sjPz+fvLw8GhsbAVendlhYGOHh4YSHhxMYGHjG2RXPp86isQFKClxnFaVFUFLoCozSIqipar2wt49ryPHAEAgKdd3NHRgCgSFgDUJpw6yP51LX7KSwtpmCmmYKa1sorG2msK6ZgtoWapt+DIz7hgdzQ19X/6O8eU2SpIuC3qAhNEJDaIRrpkRHi6Cy3BUQFWVOjh9t5limq0/CZFbwt+kIsGkJsOrws2rd/RInNzUNGjTIHRIFBQXk5+dTUFDAkSNHANcHupCQEMLCwggNDSU0NLRNHwTPRDFbIKa3687rnxD2BigpgtIiRGnhD1+LXHdw79gE6klNUhqN6ywjMATFFgy2YAgMRrGFgC0IAgLbFBreBi0JNjMJNvMpr9U1Oyn6ISjirabzrvPZyDMFDyHPFDyrznBx1FtVBTVVTirLnVSWOaiscNJQ98OYSQr4+mrw/yEg/K1afP20aM4wPHZtbS2FhYXuR1lZGarq2pavry+hoaHExcXh7e1NUFBQp0/pK5xOqCiFsmJEWTGUlUD5D9+Xl0J1hWu02RMUDQRYwRqMYgsCq+vh/j4g8Lybp+SZgiRJlwSNRsHfqsPfqiM2wdWB22RXqapwUlnuoKrCSWF+C8d/uMJJ0bianfwCfnj4a/Hxd51R+Pj44OPjQ58+fQBoaWmhpKSEoqIiioqKKCgo4PDhw67tKAo2m43g4GCCgoIIDg4mMDCwQ4NC0WpdTUhBoZwuxkRLC1SWQlkJorzENTZUeSmiohSRlQFVG8HppNWncpPZdbYREIhiDfzhextKQCBYA8HfBmZLp94HIUNBkqQuZTRpCAnXEBLueoMWQtBYr1JV6aS6wklVpZPCPNfcEQAo4O2twTdAi6+/62zC11+Lyaxzd0a7t200kpGRQXFxMSUlJRw7dowDBw64NqMoBAQEEBQURFBQEIGBgQQFBWE2n9pM0xEUvR6Cw11XN53mdaE6oboKKlxBQUUZVJa5vxf52VDtur+pVXAYzRBgRZl6O5oRl59myxdGhoIkSd1KURQs3los3lrCo1w/E0LQ2OBqeqqudHVgV5Y5KDje4l5Pb1Dw8dPg66fFx0+Lj6+WXnEBxMXFERcX595OXV0dJSUllJaWUlJSQl5eHocOHXJvx8vLC5vNRmBgIDabDZvNhtVqPeUGuw6vt0YLATbXmUD86Ye0EY4WqKqAynJEZRlUlUOl66F4eZ92nQslQ6ETRERE8MADD/D8888D8MEHH1BfX89vf/vb897euYbifumll9wjsfbr14933nmnYyojSd1AURQsXgoWrx87scF1tVNNlUpNtZPaaic1VU7ysps50T2Ytq4Oo0nBx1eLt68Gb18tPr4mIsJjiYuLcze7NDY2UlZWRmlpKeXl5ZSVlZGenu7uo1AUBT8/P6xWqzskrFYrAQEBnR4WrX4POr3ryqbAkNOebXQGGQqdwGg0snLlSh555JEOGbKiLUNxT5069ZT5GSSpp9EbNNiCNdiCf3zrEkJgbxTUVDtRHSaKC2uprW4dFgA6HXj5/BAWPlq8fEKIjw1j0EAtOr2CqqpUVVVRXl7uflRUVHDs2LFWIyr7+voSEBDQ6uHv74+Xl9clPebRCT06FDZs2EBpaelpXzvfobODgoIYN27cWZfRarXccccd/OMf/+DJJ59s9Vp5eTlPPvkk+fn5APzhD39gxIgRvP7663h5efHggw8CrqG3P/nkE6KiotzPL2QobknqqRRFwWxRMFs0BAYGEBblupb/RFjU1Tqpq1Gpq3FSV6tSXuogP6el1TaMJgUvbw1e3iYsPlFEhcfQt48Gi5cGjValurqa8vJyKisrqayspKKigvz8/FZXMOr1evz9/Vs9/Pz88PPzw2Lp3M7hjtSjQ6E73X333UyaNInZs2e3+vlzzz3H/fffz8iRI8nPz+f2229n/fr159zeuYbiXrJkCVu3bgXgvvvuY+bMmR1bIUm6xJwcFkEhrV9zOAQNdSp1tU7q61Tqa1Xqa52UFLXQlN36w6Jer2D2MmDxjsDHK4qQeA3mQRrMFgWnaKC2torKykqqqqqoqqqipKSErKysVh869Xo9vr6+7pA48b2vry8+Pj6dfvlse/ToUDjbJ/rOvk/Bx8eHm2++mblz57a6uuG7775zXzYHUFdX5769/2zONRS3bD6SpLbT6RTXlUz+p95MdiIwGupV6uuc7u/rqp2U/DAX9skMRj/MlgAsXhps0RosfRUMJoEqGmhqrqG+oZqamhqqqlzhkZOTg9PZevIvi8WCj4+POyR++r3BYOiyM40eHQrd7b777mPy5MmtPrWrqsrSpUsxmVrfjajVat2dXABNTU2nbO98huKWJKl9WgdG60/wQgia7IKGeldQNJ742uAKjdLCFn58v9cCAWg0AZjMGmzeCpFBGoxmBUXbhMNZS4ujDntTHY2NNdTW1lJaWsqRI0davReA60zD29sbHx8f99fY2NgOm8O9Vf07fItnkJ6ezrx581BVlYkTJzJ9+vRWrx84cIBPPvmEnJwcfv3rXzN69OiuKlqnCQgI4IYbbuCLL77gtttuA2D8+PHMmzePhx56CIB9+/aRlJREVFQUqamuYX/37t3L8ePHT9meHIpbkrqXoiiYzAomswZr4KmvCyFobhbYG1QaGwSNDa7AsDeoNDaqVJY7sTeqqKoC+P7wcLEYFawhCsYYBY22CZV6nGo9Lc56mpvrabTX0dhYR1lZGQ0NDXh7e1+6oaCqKnPnzuWZZ57BZrPx1FNPkZycTGRkpHuZwMBAZs+e3eOGkP7FL37BvHnz3M9ffPFFnn76aSZNmoTD4WDUqFH85S9/4brrruO///0vEyZMYOjQoe7rrE92tqG4JUnqfoqiYDQqGI0a/AJOv8zJwWFvFNgb1R8egia7K0ya7HqamvxA+LnX0wBeCvgFgD5U4GNu/xDfbdEloZCVlUVoaCghIa7enpSUFLZt29YqFE4k3qXSQ382mZmZ7u+DgoLcA3mBawaqDz744JR1zGYzX3zxxTm3d0JKSgopKSmA6wxCdixL0qWhLcEBIFRBU5MrKJrsrvBoahI0/fDVbOmczukuCYWKigpsNpv7uc1mO+0bXVukpqa6m1leeeUVAgNbn8MVFxe3+eaSrrwJpbsZjUYCAwPR6XSn/M56Ok+sM3hmvT2xztCx9b7k3hUnTZrEpEmT3M9/OjJgU1PTGcdaP5mnjZLa1NREWVnZRTFyZlfzxDqDZ9bbE+sMHTtKapfM82a1WikvL3c/Ly8v77TJ6S/xkcA7jfy9SJLUFl0SCvHx8RQWFlJSUoLD4SAtLY3k5ORO2ZdGo/GoM4C2cDgcaDRdO8+rJEmXpi5pPtJqtcyaNYuXX34ZVVWZMGECUVFRzJ8/n/j4eJKTk8nKyuKvf/0r9fX17NixgwULFvDGG2+0e18mkwm73U5TU9NZO62NRuNp7wXoaYQQaDSaU+6LkCRJOp0eN/NaW8m2R8/hiXUGz6y3J9YZLsE+BUmSJOnSIENBkiRJcpOhIEmSJLld8n0KkiRJUsfx2DOFn05+4yk8sd6eWGfwzHp7Yp2hY+vtsaEgSZIknUqGgiRJkuTmsaFw8vhJnsQT6+2JdQbPrLcn1hk6tt6yo1mSJEly89gzBUmSJOlUMhQkSZIkt0tuPoWOcK75onuCsrIy3nvvPaqqqlAUhUmTJnHddddRV1fHm2++SWlpKUFBQTz22GN4e3t3d3E7lKqqPPnkk1itVp588klKSkp46623qK2tJS4ujkceeaTHTbBUX1/PBx98QG5uLoqi8NBDDxEeHt7jj/WyZctYu3YtiqIQFRXF7Nmzqaqq6lHH+/3332fnzp34+fnx+uuvA5zx/1gIwbx589i1axdGo5HZs2efdmrfsxIexul0iocfflgUFRWJlpYW8X//938iNze3u4vV4SoqKsSRI0eEEEI0NDSIX/3qVyI3N1d89tlnYuHChUIIIRYuXCg+++yzbixl51i6dKl46623xJ///GchhBCvv/662LhxoxBCiDlz5ohVq1Z1Z/E6xbvvvitSU1OFEEK0tLSIurq6Hn+sy8vLxezZs0VTU5MQwnWc161b1+OO9/79+8WRI0fEb37zG/fPznRsd+zYIV5++WWhqqo4dOiQeOqpp9q9P49rPjp5vmidTueeL7qnCQgIcH9CMJvNREREUFFRwbZt2xg/fjwA48eP73F1Ly8vZ+fOnUycOBFwDR2+f/9+Ro8eDcAVV1zR4+rc0NBARkYGV155JeCaVdDLy6vHH2twnRU2NzfjdDppbm7G39+/xx3v/v37n3KGd6Zju337dsaNG4eiKPTp04f6+noqKyvbtb9L95zqPHXkfNGXipKSEo4dO0bv3r2prq4mIMA1W7i/vz/V1dXdXLqO9fHHH3PnnXfS2NgIQG1tLRaLxT1Fq9VqpaKiojuL2OFKSkrw9fXl/fffJycnh7i4OO6+++4ef6ytVis33HADDz30EAaDgcGDBxMXF9fjjzdwxmNbUVHRaq5mm81GRUWFe9m28LgzBU9jt9t5/fXXufvuu7FYLK1eUxTlrBMRXWp27NiBn59f+9tQL3FOp5Njx45x9dVX8+qrr2I0Glm0aFGrZXrasQZXu/q2bdt47733mDNnDna7nfT09O4uVpfr6GPrcWcKXTlfdHdzOBy8/vrrXH755YwaNQoAPz8/KisrCQgIoLKyEl9f324uZcc5dOgQ27dvZ9euXTQ3N9PY2MjHH39MQ0MDTqcTrVZLRUVFjzveNpsNm81GQkICAKNHj2bRokU9+lgD7N27l+DgYHe9Ro0axaFDh3r88YYz/x9brdZWk+2cz/ubx50pdOV80d1JCMEHH3xAREQE119/vfvnycnJrF+/HoD169czYsSI7ipih7v99tv54IMPeO+99/j1r39NUlISv/rVrxgwYACbN28G4Ntvv+1xx9vf3x+bzeaehXDv3r1ERkb26GMNrtnGMjMzaWpqQgjhrndPP95w5v/j5ORkNmzYgBCCw4cPY7FY2tV0BB56R/POnTv55JNP3PNFz5gxo7uL1OEOHjzIc889R3R0tPvU8mc/+xkJCQm8+eablJWV9djLFAH279/P0qVLefLJJykuLuatt96irq6O2NhYHnnkEfR6fXcXsUNlZ2fzwQcf4HA4CA4OZvbs2QghevyxXrBgAWlpaWi1Wnr16sWDDz5IRUVFjzreb731FgcOHKC2thY/Pz9uvfVWRowYcdpjK4Rg7ty57N69G4PBwOzZs4mPj2/X/jwyFCRJkqTT87jmI0mSJOnMZChIkiRJbjIUJEmSJDcZCpIkSZKbDAVJkiTJTYaCJHWzkpISbr31VpxOZ3cXRZJkKEiSJEk/kqEgSZIkuXnc2EeS1BYVFRX885//JCMjA5PJxJQpU7juuutYsGABubm5aDQadu3aRVhYGA899BC9evUCIC8vj48++ojs7GysViu33367e5iF5uZm/vOf/7B582bq6+uJjo7m2Wefde/zu+++Y/78+TQ3NzNlypQeeae9dPGTZwqS9BOqqvKXv/yFXr16MWfOHJ577jlWrFjhHoFz+/btjBkzhn/+85+MHTuW1157DYfDgcPh4C9/+QuDBg3io48+YtasWbzzzjvuMYk+/fRTjh49yksvvcS8efO48847W41uefDgQd5++22effZZ/vvf/5KXl9cd1Zc8nAwFSfqJI0eOUFNTw80334xOpyMkJISJEyeSlpYGQFxcHKNHj0an03H99dfT0tJCZmYmmZmZ2O12pk+fjk6nIykpiWHDhrFx40ZUVWXdunXcfffdWK1WNBoNiYmJrcbkueWWWzAYDPTq1YuYmBhycnK661cgeTDZfCRJP1FaWkplZSV33323+2eqqtKvXz8CAwNbTdKk0Wiw2Wzu2a0CAwPRaH78rBUUFERFRQW1tbW0tLQQGhp6xv36+/u7vzcajdjt9o6rlCS1kQwFSfqJwMBAgoODeeedd055bcGCBa3m41BVlfLycvfwxGVlZaiq6g6GsrIywsLC8PHxQa/XU1RU5O5/kKSLkWw+kqSf6N27N2azmUWLFtHc3Iyqqhw/fpysrCwAjh49ypYtW3A6naxYsQK9Xk9CQgIJCQkYjUaWLFmCw+Fg//797Nixg7Fjx6LRaJgwYQKffvopFRUVqKrK4cOHaWlp6ebaSlJrcuhsSTqNiooKPv30U/bv34/D4SA8PJyZM2dy8ODBVlcfhYaG8uCDD7qnAM3NzW119dHPfvYzRo4cCbiuPvr3v//N999/j91up1evXvz+97+nqqqKhx9+mC+++MI9t/ALL7zA5ZdfzsSJE7vtdyB5JhkKktQOCxYsoKioiF/96lfdXRRJ6hSy+UiSJElyk6EgSZIkucnmI0mSJMlNnilIkiRJbjIUJEmSJDcZCpIkSZKbDAVJkiTJTYaCJEmS5Pb/ATnw4ixOtQHGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history4.history['loss'])\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['MTRS', 'GMF', 'MLP', 'NeuMF'], loc='lower left')\n",
    "plt.show()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n",
    "# The model will take as input an integer matrix of size (batch,\n",
    "# input_length), and the largest integer (i.e. word index) in the input\n",
    "# should be no larger than 999 (vocabulary size).\n",
    "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# dimension.\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "labels = ['MTRS', 'GMF', 'MLP', 'NeuMF']\n",
    "\n",
    "energy = [\n",
    "    history.history['root_mean_squared_error'][99]\n",
    "    , history2.history['root_mean_squared_error'][99]\n",
    "    , history3.history['root_mean_squared_error'][99]\n",
    "    , history4.history['root_mean_squared_error'][99]\n",
    "]\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "\n",
    "plt.bar(x_pos, energy, color='green')\n",
    "plt.xlabel(\"Energy Source\")\n",
    "plt.ylabel(\"Energy Output (GJ)\")\n",
    "plt.title(\"Energy output from various fuel sources\")\n",
    "\n",
    "plt.xticks(x_pos, labels)\n",
    "\n",
    "plt.show()"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14644797146320343,\n",
       " 0.15507391095161438,\n",
       " 0.13011345267295837,\n",
       " 0.13205601274967194]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "category_indices = [0, 1, 2, 2, 1, 0]\n",
    "unique_category_count = 3\n",
    "inputs = tf.one_hot(category_indices, unique_category_count)\n",
    "print(inputs)"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.8"
=======
   "version": "3.5.2"
>>>>>>> 195a9f7c4c3874e20f0c90e65a5a049c51b6e215
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
